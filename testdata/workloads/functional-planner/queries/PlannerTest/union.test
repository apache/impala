# binding predicates of b.month equiv class gets propagated into union
select * from
  (select year, month from functional.alltypes
   union all
   select year, month from functional.alltypes) a
  inner join
  functional.alltypessmall b
  on (a.month = b.month)
where b.month = 1
---- PLAN
04:HASH JOIN [INNER JOIN]
|  hash predicates: month = b.month
|
|--03:SCAN HDFS [functional.alltypessmall b]
|     partitions=1/4 files=1 size=1.57KB
|
00:UNION
|
|--02:SCAN HDFS [functional.alltypes]
|     partitions=2/24 files=2 size=40.32KB
|
01:SCAN HDFS [functional.alltypes]
   partitions=2/24 files=2 size=40.32KB
---- DISTRIBUTEDPLAN
06:EXCHANGE [UNPARTITIONED]
|
04:HASH JOIN [INNER JOIN, BROADCAST]
|  hash predicates: month = b.month
|
|--05:EXCHANGE [BROADCAST]
|  |
|  03:SCAN HDFS [functional.alltypessmall b]
|     partitions=1/4 files=1 size=1.57KB
|
00:UNION
|
|--02:SCAN HDFS [functional.alltypes]
|     partitions=2/24 files=2 size=40.32KB
|
01:SCAN HDFS [functional.alltypes]
   partitions=2/24 files=2 size=40.32KB
====
// Only UNION ALL, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=2
---- PLAN
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
04:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Only UNION ALL with limit inside operands. One of the operands also has an order by.
select * from functional.alltypestiny where year=2009 and month=1 limit 1
union all
select * from functional.alltypestiny where year=2009 and month=1 order by int_col limit 1
union all
select * from functional.alltypestiny where year=2009 and month=2 limit 1
---- PLAN
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|     limit: 1
|
|--03:TOP-N [LIMIT=1]
|  |  order by: int_col ASC
|  |
|  02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
   limit: 1
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
00:UNION
|
|--07:EXCHANGE [UNPARTITIONED]
|  |  limit: 1
|  |
|  04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|     limit: 1
|
|--06:MERGING-EXCHANGE [UNPARTITIONED]
|  |  order by: int_col ASC
|  |  limit: 1
|  |
|  03:TOP-N [LIMIT=1]
|  |  order by: int_col ASC
|  |
|  02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
05:EXCHANGE [UNPARTITIONED]
|  limit: 1
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
   limit: 1
====
// Only UNION DISTINCT, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=2
---- PLAN
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Only UNION ALL, mixed selects with and without from clauses, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union all
select 0,true,0,0,0,0,0,0,'01/01/09','0',cast('2009-01-01 00:00:00' as timestamp),2009,1
union all
select * from functional.alltypestiny where year=2009 and month=1
union all
select 1,false,1,1,1,10,1.1,10.1,'01/01/09','1',cast('2009-01-01 00:01:00' as timestamp),2009,1
---- PLAN
00:UNION
|  constant-operands=2
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
03:EXCHANGE [UNPARTITIONED]
|
00:UNION
|  constant-operands=2
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Only UNION DISTINCT, mixed selects with and without from clauses, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select 0,true,0,0,0,0,0,0,'01/01/09','0',cast('2009-01-01 00:00:00' as timestamp),2009,1
union distinct
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select 1,false,1,1,1,10,1.1,10.1,'01/01/09','1',cast('2009-01-01 00:01:00' as timestamp),2009,1
---- PLAN
03:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|  constant-operands=2
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
06:EXCHANGE [UNPARTITIONED]
|
05:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
04:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
03:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|  constant-operands=2
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Mixed UNION ALL/DISTINCT but effectively only UNION DISTINCT, no nested unions,
// with order by and limit
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=2
union distinct
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3 limit 3
---- PLAN
06:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
05:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
09:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
06:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
08:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
07:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
05:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Mixed UNION ALL/DISTINCT, no nested unions, with order by and limit
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=2
union all
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3,4 limit 3
---- PLAN
07:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC, smallint_col ASC
|
04:UNION
|
|--03:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  00:UNION
|  |
|  |--02:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
05:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
10:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC, smallint_col ASC
|  limit: 3
|
07:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC, smallint_col ASC
|
04:UNION
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
09:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
08:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
03:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Mixed UNION ALL/DISTINCT, no nested unions, with order by and limit
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=2
union all
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3,4 limit 4
---- PLAN
07:TOP-N [LIMIT=4]
|  order by: tinyint_col ASC, smallint_col ASC
|
05:UNION
|
|--04:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  00:UNION
|  |
|  |--03:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  |--02:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
06:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
10:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC, smallint_col ASC
|  limit: 4
|
07:TOP-N [LIMIT=4]
|  order by: tinyint_col ASC, smallint_col ASC
|
05:UNION
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
09:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
08:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: Only UNION ALL, first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
04:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: Only UNION ALL, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
04:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: Only UNION DISTINCT, first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: Only UNION DISTINCT, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL doesn't absorb nested union with DISTINCT,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
07:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
06:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL doesn't absorb nested union with DISTINCT,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
00:UNION
|
|--05:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  02:UNION
|  |
|  |--04:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
07:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
06:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
05:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
02:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
03:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL absorbs the children but not directly the operands
// of a nested union with mixed ALL/DISTINCT, first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
00:UNION
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--05:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  02:UNION
|  |
|  |--04:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
09:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
08:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
07:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
05:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
02:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
03:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL absorbs the children but not directly the operands
// of a nested union with mixed ALL/DISTINCT, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
00:UNION
|
|--06:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  03:UNION
|  |
|  |--05:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
09:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
08:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
07:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
06:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
03:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
04:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL doesn't absorb the children of a nested union
// with mixed ALL/DISTINCT and limit, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2
   union all
   (select * from functional.alltypestiny where year=2009 and month=2)
   limit 10)
---- PLAN
00:UNION
|
|--06:UNION
|  |  limit: 10
|  |
|  |--05:AGGREGATE [FINALIZE]
|  |  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |  |
|  |  02:UNION
|  |  |
|  |  |--04:SCAN HDFS [functional.alltypestiny]
|  |  |     partitions=1/4 files=1 size=115B
|  |  |
|  |  03:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  07:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 7:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
12:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
11:EXCHANGE [RANDOM]
|
10:EXCHANGE [UNPARTITIONED]
|  limit: 10
|
06:UNION
|  limit: 10
|
|--07:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
09:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
08:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
05:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
02:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
03:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL doesn't absorb nested union with order by and limit,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 (select * from functional.alltypestiny where year=2009 and month=2)
 order by 3 limit 3)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
04:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
07:EXCHANGE [RANDOM]
|
06:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
04:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION ALL doesn't absorb nested union with order by and limit,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   (select * from functional.alltypestiny where year=2009 and month=2)
   order by 3 limit 3)
---- PLAN
00:UNION
|
|--05:TOP-N [LIMIT=3]
|  |  order by: tinyint_col ASC
|  |
|  02:UNION
|  |
|  |--04:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
07:EXCHANGE [RANDOM]
|
06:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
05:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
02:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
03:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION DISTINCT absorbs nested union with ALL
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION DISTINCT absorbs nested union with ALL,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION DISTINCT absorbs nested union with mixed ALL/DISTINCT,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
05:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
07:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
06:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
05:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION DISTINCT absorbs nested union with mixed ALL/DISTINCT,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
05:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
08:EXCHANGE [UNPARTITIONED]
|
07:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
06:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
05:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION DISTINCT doesn't absorb nested union with order by and limit,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 (select * from functional.alltypestiny where year=2009 and month=2)
 order by 3 limit 3)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
04:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
11:EXCHANGE [UNPARTITIONED]
|
10:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
09:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
06:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
08:EXCHANGE [RANDOM]
|
07:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
04:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Union unnesting: UNION DISTINCT doesn't absorb nested union with order by and limit
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   (select * from functional.alltypestiny where year=2009 and month=2)
   order by 3 limit 3)
---- PLAN
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:TOP-N [LIMIT=3]
|  |  order by: tinyint_col ASC
|  |
|  02:UNION
|  |
|  |--04:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
11:EXCHANGE [UNPARTITIONED]
|
10:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
09:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
06:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
08:EXCHANGE [RANDOM]
|
07:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
05:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
02:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
03:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Complex union unnesting: Multiple levels of UNION ALL, fully unnestable
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
     (select * from functional.alltypestiny where year=2009 and month=2
      union all
        (select * from functional.alltypestiny where year=2009 and month=2
         union all
         select * from functional.alltypestiny where year=2009 and month=3)))
---- PLAN
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
---- DISTRIBUTEDPLAN
06:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Complex union unnesting: Multiple levels of UNION DISTINCT, fully unnestable
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
     (select * from functional.alltypestiny where year=2009 and month=2
      union distinct
        (select * from functional.alltypestiny where year=2009 and month=2
         union distinct
         select * from functional.alltypestiny where year=2009 and month=3)))
---- PLAN
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
---- DISTRIBUTEDPLAN
09:EXCHANGE [UNPARTITIONED]
|
08:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
07:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
06:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Complex union unnesting: Partially unnestable up to 2nd level
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
     (select * from functional.alltypestiny where year=2009 and month=2
      union all
        (select * from functional.alltypestiny where year=2009 and month=2
         union distinct
         (select * from functional.alltypestiny where year=2009 and month=3)
         order by 3 limit 3)))
---- PLAN
00:UNION
|
|--10:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  02:UNION
|  |
|  |--09:TOP-N [LIMIT=3]
|  |  |  order by: tinyint_col ASC
|  |  |
|  |  08:AGGREGATE [FINALIZE]
|  |  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |  |
|  |  05:UNION
|  |  |
|  |  |--07:SCAN HDFS [functional.alltypestiny]
|  |  |     partitions=1/4 files=1 size=115B
|  |  |
|  |  06:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  |--04:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 7:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
---- DISTRIBUTEDPLAN
17:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
16:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
15:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
10:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
02:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
14:EXCHANGE [RANDOM]
|
13:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
09:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
12:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
11:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
08:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:UNION
|
|--07:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
06:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Complex union unnesting: Partially unnestable up to 1st level
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
     (select * from functional.alltypestiny where year=2009 and month=2
      union all
        (select * from functional.alltypestiny where year=2009 and month=2
         union distinct
         (select * from functional.alltypestiny where year=2009 and month=3)
         order by 3 limit 3)))
---- PLAN
09:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--08:TOP-N [LIMIT=3]
|  |  order by: tinyint_col ASC
|  |
|  07:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  04:UNION
|  |
|  |--06:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
---- DISTRIBUTEDPLAN
16:EXCHANGE [UNPARTITIONED]
|
15:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
14:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
09:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
13:EXCHANGE [RANDOM]
|
12:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
08:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
11:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
10:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
07:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
04:UNION
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
05:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// Complex union unnesting: Multiple nested unions to test all rules in a single query
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
union distinct
  (select * from functional.alltypestiny where year=2009 and month=2
   union all
   (select * from functional.alltypestiny where year=2009 and month=3)
   order by 3 limit 3)
union all
  (select * from functional.alltypestiny where year=2009 and month=3
   union all
   select * from functional.alltypestiny where year=2009 and month=4)
union all
  (select * from functional.alltypestiny where year=2009 and month=4
   union all
   (select * from functional.alltypestiny where year=2009 and month=5)
   order by 3 limit 3)
---- PLAN
09:UNION
|
|--08:AGGREGATE [FINALIZE]
|  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|  |
|  00:UNION
|  |
|  |--07:TOP-N [LIMIT=3]
|  |  |  order by: tinyint_col ASC
|  |  |
|  |  04:UNION
|  |  |
|  |  |--06:SCAN HDFS [functional.alltypestiny]
|  |  |     partitions=1/4 files=1 size=115B
|  |  |
|  |  05:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  |--03:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  |--02:SCAN HDFS [functional.alltypestiny]
|  |     partitions=1/4 files=1 size=115B
|  |
|  01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--15:TOP-N [LIMIT=3]
|  |  order by: tinyint_col ASC
|  |
|  12:UNION
|  |
|  |--14:SCAN HDFS [functional.alltypestiny]
|  |     partitions=0/4 files=0 size=0B
|  |
|  13:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--11:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
10:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
NODE 10:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
NODE 11:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=4/090401.txt 0:115
NODE 13:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=4/090401.txt 0:115
NODE 14:
---- DISTRIBUTEDPLAN
22:EXCHANGE [UNPARTITIONED]
|
09:UNION
|
|--11:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--10:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--21:EXCHANGE [RANDOM]
|  |
|  16:MERGING-EXCHANGE [UNPARTITIONED]
|  |  order by: tinyint_col ASC
|  |  limit: 3
|  |
|  15:TOP-N [LIMIT=3]
|  |  order by: tinyint_col ASC
|  |
|  12:UNION
|  |
|  |--14:SCAN HDFS [functional.alltypestiny]
|  |     partitions=0/4 files=0 size=0B
|  |
|  13:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
20:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
19:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
08:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
18:EXCHANGE [RANDOM]
|
17:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
07:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
04:UNION
|
|--06:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
05:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// UNION ALL in subquery
select x.* from
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=1) x
union all
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3 limit 5
---- PLAN
05:TOP-N [LIMIT=5]
|  order by: tinyint_col ASC
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
06:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 5
|
05:TOP-N [LIMIT=5]
|  order by: tinyint_col ASC
|
00:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// UNION DISTINCT in subquery
select x.* from
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=1) x
union distinct
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3 limit 3
---- PLAN
07:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
04:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
---- DISTRIBUTEDPLAN
12:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: tinyint_col ASC
|  limit: 3
|
07:TOP-N [LIMIT=3]
|  order by: tinyint_col ASC
|
11:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
10:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
06:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
09:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
08:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
04:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
01:UNION
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// UNION ALL in subquery with a WHERE condition in the outer select.
select x.* from
  (select int_col, bool_col, count(*) as count_col
   from functional.alltypestiny where year=2009 and month=1 group by 1, 2
   union all
   select int_col, bool_col, count(*) as count_col
   from functional.alltypestiny where year=2009 and month=1 group by 1, 2) x
where x.int_col < 5 and x.bool_col = false
---- PLAN
00:UNION
|
|--04:AGGREGATE [FINALIZE]
|  |  output: count(*)
|  |  group by: int_col, bool_col
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
|
02:AGGREGATE [FINALIZE]
|  output: count(*)
|  group by: int_col, bool_col
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
   predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
---- DISTRIBUTEDPLAN
09:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--08:AGGREGATE [FINALIZE]
|  |  output: count:merge(*)
|  |  group by: int_col, bool_col
|  |
|  07:EXCHANGE [HASH(int_col,bool_col)]
|  |
|  04:AGGREGATE [STREAMING]
|  |  output: count(*)
|  |  group by: int_col, bool_col
|  |
|  03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
|
06:AGGREGATE [FINALIZE]
|  output: count:merge(*)
|  group by: int_col, bool_col
|
05:EXCHANGE [HASH(int_col,bool_col)]
|
02:AGGREGATE [STREAMING]
|  output: count(*)
|  group by: int_col, bool_col
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
   predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
====
// UNION ALL with only constant selects
select 1, 'a', NULL, 10.f
union all
select 2, 'b', NULL, 20.f
union all
select 3, 'c', NULL, 30.f
---- PLAN
00:UNION
   constant-operands=3
---- DISTRIBUTEDPLAN
00:UNION
   constant-operands=3
====
// UNION DISTINCT with only constant selects
select 1, 'a', NULL, 10.0f
union distinct
select 2, 'b', NULL, 20.0f
union distinct
select 3, 'c', NULL, 30.0f
---- PLAN
01:AGGREGATE [FINALIZE]
|  group by: 1, 'a', null, f
|
00:UNION
   constant-operands=3
---- DISTRIBUTEDPLAN
01:AGGREGATE [FINALIZE]
|  group by: 1, 'a', null, f
|
00:UNION
   constant-operands=3
====
// UNION ALL/DISTINCT with mixed constant selects and non-constant selects
select 1, 'a', NULL, 10.f
union all
select int_col, string_col, bool_col, float_col from functional.alltypestiny
union distinct
select 3, 'c', NULL, 30.f
union all
select int_col, string_col, bool_col, float_col from functional.alltypestiny
---- PLAN
03:UNION
|
|--02:AGGREGATE [FINALIZE]
|  |  group by: 1, 'a', null, f
|  |
|  00:UNION
|  |  constant-operands=2
|  |
|  01:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 files=4 size=460B
|
04:SCAN HDFS [functional.alltypestiny]
   partitions=4/4 files=4 size=460B
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
03:UNION
|
|--04:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 files=4 size=460B
|
06:AGGREGATE [FINALIZE]
|  group by: 1, 'a', null, f
|
05:EXCHANGE [HASH(1,'a',null,f)]
|
02:AGGREGATE [STREAMING]
|  group by: 1, 'a', null, f
|
00:UNION
|  constant-operands=2
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=4/4 files=4 size=460B
====
// UNION ALL/DISTINCT with mixed constant selects and non-constant selects and nested unions
(select 500
 union all
 (select int_col from functional.alltypestiny where year=2009 and month=2
  order by 1 limit 3
  union all
  select 500)
)
union distinct
select int_col from functional.alltypestiny where year=2009 and month=1
union all
select 503
---- PLAN
05:UNION
|  constant-operands=1
|
04:AGGREGATE [FINALIZE]
|  group by: 500
|
00:UNION
|  constant-operands=2
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
02:TOP-N [LIMIT=3]
|  order by: int_col ASC
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
---- DISTRIBUTEDPLAN
10:EXCHANGE [UNPARTITIONED]
|
05:UNION
|  constant-operands=1
|
09:AGGREGATE [FINALIZE]
|  group by: 500
|
08:EXCHANGE [HASH(500)]
|
04:AGGREGATE [STREAMING]
|  group by: 500
|
00:UNION
|  constant-operands=2
|
|--03:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|
07:EXCHANGE [RANDOM]
|
06:MERGING-EXCHANGE [UNPARTITIONED]
|  order by: int_col ASC
|  limit: 3
|
02:TOP-N [LIMIT=3]
|  order by: int_col ASC
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
====
// UNION ALL with only values statements
values(1, 'a', NULL, 10.f)
union all
values(2, 'b', NULL, 20.f)
union all
values(3, 'c', NULL, 30.f)
---- PLAN
00:UNION
   constant-operands=3
---- DISTRIBUTEDPLAN
00:UNION
   constant-operands=3
====
// UNION DISTINCT with only values statements
values(1, 'a', NULL, 10.f)
union distinct
values(2, 'b', NULL, 20.f)
union distinct
values(3, 'c', NULL, 30.f)
---- PLAN
01:AGGREGATE [FINALIZE]
|  group by: 1, 'a', null, f
|
00:UNION
   constant-operands=3
---- DISTRIBUTEDPLAN
01:AGGREGATE [FINALIZE]
|  group by: 1, 'a', null, f
|
00:UNION
   constant-operands=3
====
// UNION ALL/DISTINCT with mixed values statements and non-constant selects
values(1, 'a', NULL, 10.f)
union all
select int_col, string_col, bool_col, float_col from functional.alltypestiny
union distinct
values(3, 'c', NULL, 30.f)
union all
select int_col, string_col, bool_col, float_col from functional.alltypessmall
---- PLAN
03:UNION
|
|--02:AGGREGATE [FINALIZE]
|  |  group by: 1, 'a', null, f
|  |
|  00:UNION
|  |  constant-operands=2
|  |
|  01:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 files=4 size=460B
|
04:SCAN HDFS [functional.alltypessmall]
   partitions=4/4 files=4 size=6.32KB
---- DISTRIBUTEDPLAN
07:EXCHANGE [UNPARTITIONED]
|
03:UNION
|
|--04:SCAN HDFS [functional.alltypessmall]
|     partitions=4/4 files=4 size=6.32KB
|
06:AGGREGATE [FINALIZE]
|  group by: 1, 'a', null, f
|
05:EXCHANGE [HASH(1,'a',null,f)]
|
02:AGGREGATE [STREAMING]
|  group by: 1, 'a', null, f
|
00:UNION
|  constant-operands=2
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=4/4 files=4 size=460B
====
# all union output slots are being materialized even though none is referenced by
# the enclosing scope
select count(*) from (
  select id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col,
      double_col, date_string_col, string_col, timestamp_col, year, month
    from functional.alltypes
  union distinct
  select 0,true,0,0,0,0,cast(0 as float),0,'01/01/09','0',
      cast('2009-01-01 00:00:00' as timestamp),2009,1
  union distinct
  select id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col,
      double_col, date_string_col, string_col, timestamp_col, year, month
    from functional.alltypes
  union distinct
  select 1,false,1,1,1,10,cast(1.1 as float),10.1,'01/01/09','1',
      cast('2009-01-01 00:01:00' as timestamp),2009,1
  union distinct
  select 2,true,2,2,2,20,cast(2.2 as float),20.2,'01/01/09','2',
      cast('2009-01-01 00:02:00.10' as timestamp),2009,1
) x
---- PLAN
04:AGGREGATE [FINALIZE]
|  output: count(*)
|
03:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|  constant-operands=3
|
|--02:SCAN HDFS [functional.alltypes]
|     partitions=24/24 files=24 size=478.45KB
|
01:SCAN HDFS [functional.alltypes]
   partitions=24/24 files=24 size=478.45KB
---- DISTRIBUTEDPLAN
08:AGGREGATE [FINALIZE]
|  output: count:merge(*)
|
07:EXCHANGE [UNPARTITIONED]
|
04:AGGREGATE
|  output: count(*)
|
06:AGGREGATE [FINALIZE]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
05:EXCHANGE [HASH(id,bool_col,tinyint_col,smallint_col,int_col,bigint_col,float_col,double_col,date_string_col,string_col,timestamp_col,year,month)]
|
03:AGGREGATE [STREAMING]
|  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
|
00:UNION
|  constant-operands=3
|
|--02:SCAN HDFS [functional.alltypes]
|     partitions=24/24 files=24 size=478.45KB
|
01:SCAN HDFS [functional.alltypes]
   partitions=24/24 files=24 size=478.45KB
====
# UNION ALL in subquery with a WHERE condition in the outer select;
# Where clause conjuncts are used as scan predicates and for partition pruning.
select x.int_col, x.bool_col, x.month from
  (select * from functional.alltypestiny where year=2009 
   union all
   select * from functional.alltypestiny where year=2009) x
where x.int_col < 5 and x.bool_col = false and x.month = 1
---- PLAN
00:UNION
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
   predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
---- DISTRIBUTEDPLAN
03:EXCHANGE [UNPARTITIONED]
|
00:UNION
|
|--02:SCAN HDFS [functional.alltypestiny]
|     partitions=1/4 files=1 size=115B
|     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=1/4 files=1 size=115B
   predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
====
# Regression test for IMPALA-888. Tests proper materialization of slots in
# the presence of conjuncts that become constant for union operands.
select 1 from
  (select 1 a, 2 b, int_col c, bigint_col d from functional.alltypestiny
   union all
   select tinyint_col, int_col, smallint_col, bigint_col from functional.alltypes
   union all
   select 1, tinyint_col, 3, bigint_col from functional.alltypessmall) t
where a + b < 100 and c > 20 and d > 50
---- PLAN
00:UNION
|
|--02:SCAN HDFS [functional.alltypes]
|     partitions=24/24 files=24 size=478.45KB
|     predicates: functional.alltypes.tinyint_col + functional.alltypes.int_col < 100, functional.alltypes.smallint_col > 20, functional.alltypes.bigint_col > 50
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=4/4 files=4 size=460B
   predicates: functional.alltypestiny.int_col > 20, functional.alltypestiny.bigint_col > 50
====
# Test union where all operands are dropped because of constant conjuncts.
select * from
  (select 1 a, 2 b
   union all
   select 3, 4
   union all
   select 10, 20) t
where a > b
---- PLAN
00:UNION
---- DISTRIBUTEDPLAN
00:UNION
====
# Test union merging only partitioned inputs.
select id, bigint_col from functional.alltypestiny
union all
select sum(int_col), bigint_col from functional.alltypes
  where year=2009 and month=2
  group by bigint_col
union all
select a.id, a.bigint_col
  from functional.alltypestiny a inner join functional.alltypestiny b
  on (a.id = b.id)
union all
select 1000, 2000
---- PLAN
00:UNION
|  constant-operands=1
|
|--06:HASH JOIN [INNER JOIN]
|  |  hash predicates: a.id = b.id
|  |
|  |--05:SCAN HDFS [functional.alltypestiny b]
|  |     partitions=4/4 files=4 size=460B
|  |
|  04:SCAN HDFS [functional.alltypestiny a]
|     partitions=4/4 files=4 size=460B
|
|--03:AGGREGATE [FINALIZE]
|  |  output: sum(int_col)
|  |  group by: bigint_col
|  |
|  02:SCAN HDFS [functional.alltypes]
|     partitions=1/24 files=1 size=18.12KB
|
01:SCAN HDFS [functional.alltypestiny]
   partitions=4/4 files=4 size=460B
---- DISTRIBUTEDPLAN
10:EXCHANGE [UNPARTITIONED]
|
00:UNION
|  constant-operands=1
|
|--01:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 files=4 size=460B
|
|--06:HASH JOIN [INNER JOIN, BROADCAST]
|  |  hash predicates: a.id = b.id
|  |
|  |--09:EXCHANGE [BROADCAST]
|  |  |
|  |  05:SCAN HDFS [functional.alltypestiny b]
|  |     partitions=4/4 files=4 size=460B
|  |
|  04:SCAN HDFS [functional.alltypestiny a]
|     partitions=4/4 files=4 size=460B
|
08:AGGREGATE [FINALIZE]
|  output: sum:merge(int_col)
|  group by: bigint_col
|
07:EXCHANGE [HASH(bigint_col)]
|
03:AGGREGATE [STREAMING]
|  output: sum(int_col)
|  group by: bigint_col
|
02:SCAN HDFS [functional.alltypes]
   partitions=1/24 files=1 size=18.12KB
====
# Test union merging only unpartitioned inputs.
select count(id), sum(bigint_col) from functional.alltypes
union all
select id, bigint_col from functional.alltypessmall order by id limit 10
union all
select 1000, 2000
---- PLAN
00:UNION
|  constant-operands=1
|
|--04:TOP-N [LIMIT=10]
|  |  order by: id ASC
|  |
|  03:SCAN HDFS [functional.alltypessmall]
|     partitions=4/4 files=4 size=6.32KB
|
02:AGGREGATE [FINALIZE]
|  output: count(id), sum(bigint_col)
|
01:SCAN HDFS [functional.alltypes]
   partitions=24/24 files=24 size=478.45KB
---- DISTRIBUTEDPLAN
00:UNION
|  constant-operands=1
|
|--07:MERGING-EXCHANGE [UNPARTITIONED]
|  |  order by: id ASC
|  |  limit: 10
|  |
|  04:TOP-N [LIMIT=10]
|  |  order by: id ASC
|  |
|  03:SCAN HDFS [functional.alltypessmall]
|     partitions=4/4 files=4 size=6.32KB
|
06:AGGREGATE [FINALIZE]
|  output: count:merge(id), sum:merge(bigint_col)
|
05:EXCHANGE [UNPARTITIONED]
|
02:AGGREGATE
|  output: count(id), sum(bigint_col)
|
01:SCAN HDFS [functional.alltypes]
   partitions=24/24 files=24 size=478.45KB
====
# Test union merging mixed unpartitioned and partitioned inputs.
select count(id), sum(bigint_col) from functional.alltypes
union all
select id, bigint_col from functional.alltypessmall order by id limit 10
union all
select id, bigint_col from functional.alltypestiny
union all
select sum(int_col), bigint_col from functional.alltypes
  where year=2009 and month=2
  group by bigint_col
union all
select a.id, a.bigint_col
  from functional.alltypestiny a inner join functional.alltypestiny b
  on (a.id = b.id)
union all
select 1000, 2000
---- PLAN
00:UNION
|  constant-operands=1
|
|--10:HASH JOIN [INNER JOIN]
|  |  hash predicates: a.id = b.id
|  |
|  |--09:SCAN HDFS [functional.alltypestiny b]
|  |     partitions=4/4 files=4 size=460B
|  |
|  08:SCAN HDFS [functional.alltypestiny a]
|     partitions=4/4 files=4 size=460B
|
|--07:AGGREGATE [FINALIZE]
|  |  output: sum(int_col)
|  |  group by: bigint_col
|  |
|  06:SCAN HDFS [functional.alltypes]
|     partitions=1/24 files=1 size=18.12KB
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 files=4 size=460B
|
|--04:TOP-N [LIMIT=10]
|  |  order by: id ASC
|  |
|  03:SCAN HDFS [functional.alltypessmall]
|     partitions=4/4 files=4 size=6.32KB
|
02:AGGREGATE [FINALIZE]
|  output: count(id), sum(bigint_col)
|
01:SCAN HDFS [functional.alltypes]
   partitions=24/24 files=24 size=478.45KB
---- DISTRIBUTEDPLAN
19:EXCHANGE [UNPARTITIONED]
|
00:UNION
|  constant-operands=1
|
|--05:SCAN HDFS [functional.alltypestiny]
|     partitions=4/4 files=4 size=460B
|
|--18:EXCHANGE [RANDOM]
|  |
|  13:MERGING-EXCHANGE [UNPARTITIONED]
|  |  order by: id ASC
|  |  limit: 10
|  |
|  04:TOP-N [LIMIT=10]
|  |  order by: id ASC
|  |
|  03:SCAN HDFS [functional.alltypessmall]
|     partitions=4/4 files=4 size=6.32KB
|
|--17:EXCHANGE [RANDOM]
|  |
|  12:AGGREGATE [FINALIZE]
|  |  output: count:merge(id), sum:merge(bigint_col)
|  |
|  11:EXCHANGE [UNPARTITIONED]
|  |
|  02:AGGREGATE
|  |  output: count(id), sum(bigint_col)
|  |
|  01:SCAN HDFS [functional.alltypes]
|     partitions=24/24 files=24 size=478.45KB
|
|--10:HASH JOIN [INNER JOIN, BROADCAST]
|  |  hash predicates: a.id = b.id
|  |
|  |--16:EXCHANGE [BROADCAST]
|  |  |
|  |  09:SCAN HDFS [functional.alltypestiny b]
|  |     partitions=4/4 files=4 size=460B
|  |
|  08:SCAN HDFS [functional.alltypestiny a]
|     partitions=4/4 files=4 size=460B
|
15:AGGREGATE [FINALIZE]
|  output: sum:merge(int_col)
|  group by: bigint_col
|
14:EXCHANGE [HASH(bigint_col)]
|
07:AGGREGATE [STREAMING]
|  output: sum(int_col)
|  group by: bigint_col
|
06:SCAN HDFS [functional.alltypes]
   partitions=1/24 files=1 size=18.12KB
====
