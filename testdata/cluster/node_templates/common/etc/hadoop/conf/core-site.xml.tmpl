<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>${DEFAULT_FS}</value>
  </property>

  <property>
    <name>dfs.replication</name>
    <value>${HDFS_REPLICATION}</value>
  </property>

 <property>
    <name>io.compression.codecs</name>
    <value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec</value>
  </property>

  <property>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
  </property>

  <property>
    <name>hadoop.proxyuser.${USER}.hosts</name>
    <value>*</value>
  </property>

  <property>
  <!-- Trash is enabled since some tests (in metadata/test_ddl.py) depend on it.
       It is set to 24 hours to avoid checkpointing between the test runs -->
    <name>fs.trash.interval</name>
    <value>1440</value>
  </property>

  <property>
    <name>hadoop.proxyuser.${USER}.groups</name>
    <value>*</value>
  </property>

  <!-- Needed as long as multiple nodes are running on the same address. For Impala
       testing only -->
  <property>
    <name>yarn.scheduler.include-port-in-node-name</name>
    <value>true</value>
  </property>

  <!-- Needed by frontend tests that reference s3n paths. -->
  <property>
    <name>fs.s3n.awsAccessKeyId</name>
    <value>${AWS_ACCESS_KEY_ID}</value>
  </property>

  <property>
    <name>fs.s3n.awsSecretAccessKey</name>
    <value>${AWS_SECRET_ACCESS_KEY}</value>
  </property>

  <!-- Needed when the TARGET_FILESYSTEM is s3 -->
  <property>
    <name>fs.s3a.awsAccessKeyId</name>
    <value>${AWS_ACCESS_KEY_ID}</value>
  </property>

  <property>
    <name>fs.s3a.awsSecretAccessKey</name>
    <value>${AWS_SECRET_ACCESS_KEY}</value>
  </property>

  <!-- Location of the KMS key provider -->
  <property>
    <name>hadoop.security.key.provider.path</name>
    <value>kms://http@127.0.0.1:16000/kms</value>
  </property>

  <!-- BEGIN Kerberos settings -->
  <property>
    <name>hadoop.security.authentication</name>
    <value>kerberos</value>
  </property>

  <property>
    <name>hadoop.security.authorization</name>
    <value>true</value>
  </property>

  <property>
    <name>hadoop.proxyuser.hive.hosts</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.hive.groups</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.llama.hosts</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.llama.groups</name>
    <value>*</value>
  </property>
  <!-- END Kerberos settings -->

</configuration>
