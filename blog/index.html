<!DOCTYPE html>
<html prefix="
    " lang="en">
<head>
<meta name="keywords" content="hadoop, impala, sql, mpp, bi, big data, open source">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta charset="utf-8">
<meta name="description" content="Apache Impala is a modern, open source, distributed SQL query engine for open data and table formats.">
<title>Apache Impala</title>
<link href="assets/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/bootstrap-responsive.min.css" rel="stylesheet" type="text/css">
<!-- order is significant to prevent overwriting of some bootstrap-defined css styles --><link href="assets/css/additional_styles.css" rel="stylesheet" type="text/css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script><script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script><meta content="#5670d4" name="theme-color">
<link rel="canonical" href="https://impala.apache.org/blog/">
<link rel="next" href="index-1.html" type="text/html">
<link rel="prefetch" href="posts/codegen-cache-for-low-latency-queries/" type="text/html">
</head>
<body id="index" class="home">
    <div class="container">
        <div class="masthead">
                <header id="header"><h3 id="brand">

            <span id="blog-title" class="muted">Apache Impala</span>
    </h3>

            <nav id="menu"><div class="navbar">
        <div class="navbar-inner">
            <div class="container">

            <ul class="nav">
<li><a href="https://impala.apache.org/index.html">Home</a></li>
                <li><a href="https://impala.apache.org/downloads.html">Downloads</a></li>
                <li><a href="https://impala.apache.org/overview.html">Overview</a></li>
                <li class="active"><a href="https://impala.apache.org/blog/">Blog</a></li>
                <li><a href="https://cwiki.apache.org/confluence/display/IMPALA/Contributing+to+Impala">Contribute</a></li>
                <li class="dropdown">
                    <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button">
                    Source code</a>
                    <ul class="dropdown-menu">
<li>
                            <a href="https://git-wip-us.apache.org/repos/asf/incubator-impala.git">
                            Official source</a>
                        </li>
                        <li><a href="https://github.com/apache/incubator-impala">GitHub mirror</a></li>
                    </ul>
</li>
                <li><a href="https://impala.apache.org/community.html">Community</a></li>
                <li><a href="https://impala.apache.org/impala-docs.html">Documentation</a></li>
            </ul>
</div>
<!-- container -->
        </div>
<!-- navbar-inner -->
    </div>
<!-- navbar -->
    </nav></header>
</div>
<!-- masthead -->
        <main id="content"><h3>All articles</h3>
<div class="postindex">
    <hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/codegen-cache-for-low-latency-queries/" class="u-url">Codegen cache for low latency queries</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/michael-smith/">Michael Smith</a>
                <a href="authors/yida-wu/">Yida Wu</a>
                <a href="authors/david-rorke/">David Rorke</a>
                <a href="authors/abhishek-rawat/">Abhishek Rawat</a>
            </span></p>
            <p class="dateline"><a href="posts/codegen-cache-for-low-latency-queries/" rel="bookmark"><time class="published dt-published" datetime="2024-10-29T14:00:00-07:00" title="2024-10-29 14:00">2024-10-29 14:00</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Impala is a high-performance engine - written primarily in C++ - for executing low-latency SQL queries. At a high level, Impala generates a distributed query plan (first two phases in yellow), admits the query once sufficient capacity is available, and finally executes the query. For a more in-depth description of these phases please refer to <a href="https://www.cidrdb.org/cidr2015/Papers/CIDR15_Paper28.pdf">Impala: A Modern, Open-Source SQL Engine for Hadoop</a>.</p>
<p><img alt="Query Execution" src="images/query-exec.png" style="display: block; margin: 0 auto;"></p>
<p>During Distributed Execution, each fragment of the query plan is run on one or more Impala executors, with a degree of parallelism determined by the planner. A fragment is a distinct block of work that can be executed on a single node, and often comprises steps such as scanning and filtering rows from files (or other data sources), hashing that data to group or order it, and sending it to other executors via an exchange for distributed aggregation.</p>
<h4>Code Generation</h4>
<p>The steps taken within each fragment comprise the bulk of the work an executor does, and databases use different techniques to optimize that work. The actual operations needed will depend on the types of the specific columns being manipulated, which may be simple scalar types or complex data such as structs and arrays. At the beginning of executing each fragment, Impala leverages the <a href="https://llvm.org">LLVM project</a> to generate machine code specific to the steps and columns in the fragment.</p>
<p>Code generation can dramatically speed up the operations done on each row, but has an initial overhead in generating the code that offsets that benefit. This initial overhead of generating code becomes relevant to sub second and low second queries because codegen time of say 100-250 ms is relevant if the query only takes 2 seconds to finish. Typical examples of such queries are queries on kudu tables that finish in seconds. Historically we recommended users to either <code>set DISABLE_CODEGEN=true</code> or to set a higher value for <code>DISABLE_CODEGEN_ROWS_THRESHOLD</code>, so that for very small queries Impala disables codegen.</p>
<p><code>DISABLE_CODEGEN_ROWS_THRESHOLD</code> currently estimates the number rows being processed on each of the nodes and then decides whether codegen should be disabled. There are scenarios where the planner estimate is incorrect or the query is complex and codegen would have actually helped.</p>
<p>To help mitigate the cost of codegen for short running queries that are run repeatedly we've introduced a new codegen caching feature. With codegen cache enabled, code generation for queries will be cached, and subsequent runs will be faster by not needing to regenerate that code.</p>
<p>Using Cloudera Data Warehouse 1.9.2 with Runtime 2024.0.18.0-206 on AWS EC2 r5d.4xlarge instances, we performed a TPC-DS 1 TB benchmark with 10 executors to evaluate codegen cache performance. Across the whole test suite we saw geometric mean times improve by 4.8%. Since we expect codegen cache to help more with faster queries, we isolate the queries that executed in less than 2s:</p>
<p><img alt="Codegen cache performance" src="images/codegen-cache-perf.png" style="display: block; margin: 0 auto;"></p>
<p>For these queries, we see a geometric mean improvement of 22%, significantly improving the performance of low latency queries by eliminating most of the code generation time.</p>
<h4>The Codegen Cache</h4>
<p><a href="https://docs.cloudera.com/cdw-runtime/cloud/impala-reference/topics/impala-codegencaching.html">Caching Codegen Functions</a> has been added to reduce the cost of code generation when repeating queries or running substantially similar queries by caching the results of code generation. The codegen cache in Impala works at the fragment level, meaning that it caches and reuses the machine code for specific fragments of a query.</p>
<p>When Impala generates code using LLVM and the codegen cache is enabled, it will store the generated objects using <a href="https://blog.llvm.org/2013/08/object-caching-with-kaleidoscope.html">LLVM’s Object Caching</a>. Impala goes through several steps during codegen:</p>
<ol>
<li>Load pre-parsed and partially optimized Impala library functions so that new code generation can reference them.</li>
<li>Define functions representing the operations to be performed using LLVM’s intermediate representation (IR).</li>
<li>Prune unused library functions loaded in step (1).</li>
<li>Run LLVM’s builtin passes to optimize the IR generated through steps 1-3.</li>
<li>Generate machine code from the optimized IR.</li>
</ol>
<p>The most time consuming portion of these are optimization passes and generating machine code. When using the codegen cache, Impala performs steps 1-3, then constructs a key based on a serialization of the IR. It then looks for a match for the key in the codegen cache; if found, the result will be a machine code object that’s ready for immediate use; otherwise steps 4 and 5 are performed to generate machine code, which will then be stored to the codegen cache and used.</p>
<p>The codegen cache stores all objects in-memory. Its capacity is determined by <code>CODEGEN_CACHE_CAPACITY</code>. When the cache is full, it evicts the Least-Recently Used (LRU) object to make space for new entries.</p>
<h5>Example of Caching Codegen Functions</h5>
<p>Consider the following table:</p>
<div class="code"><pre class="code literal-block">create table sales_data (product_id int, category string, sales double);
</pre></div>

<p>We run two similar queries sequentially:</p>
<ol>
<li><code>select category, sum(sales) from sales_data where category = 'a' group by category;</code></li>
<li><code>select category, sum(sales) from sales_data where category = 'b' group by category;</code></li>
</ol>
<p>After running Query 1, the query profile shows the plan as follows, with zero cached functions and a total codegen compilation time of several dozen milliseconds for each fragment.</p>
<div class="code"><pre class="code literal-block"><span class="nl">F02</span><span class="p">:</span><span class="k">PLAN</span><span class="w"> </span><span class="n">FRAGMENT</span><span class="w"> </span><span class="o">[</span><span class="n">UNPARTITIONED</span><span class="o">]</span><span class="w"> </span><span class="n">hosts</span><span class="o">=</span><span class="mi">1</span><span class="w"> </span><span class="n">instances</span><span class="o">=</span><span class="mi">1</span>
<span class="p">...</span>
<span class="mi">04</span><span class="err">:</span><span class="n">EXCHANGE</span><span class="w"> </span><span class="o">[</span><span class="n">UNPARTITIONED</span><span class="o">]</span>
<span class="p">...</span>
<span class="nl">F01</span><span class="p">:</span><span class="k">PLAN</span><span class="w"> </span><span class="n">FRAGMENT</span><span class="w"> </span><span class="o">[</span><span class="n">HASH(category)</span><span class="o">]</span><span class="w"> </span><span class="n">hosts</span><span class="o">=</span><span class="mi">1</span><span class="w"> </span><span class="n">instances</span><span class="o">=</span><span class="mi">1</span>
<span class="mi">03</span><span class="err">:</span><span class="k">AGGREGATE</span><span class="w"> </span><span class="o">[</span><span class="n">FINALIZE</span><span class="o">]</span>
<span class="p">...</span>
<span class="mi">02</span><span class="err">:</span><span class="n">EXCHANGE</span><span class="w"> </span><span class="o">[</span><span class="n">HASH(category)</span><span class="o">]</span>
<span class="p">...</span>
<span class="nl">F00</span><span class="p">:</span><span class="k">PLAN</span><span class="w"> </span><span class="n">FRAGMENT</span><span class="w"> </span><span class="o">[</span><span class="n">RANDOM</span><span class="o">]</span><span class="w"> </span><span class="n">hosts</span><span class="o">=</span><span class="mi">1</span><span class="w"> </span><span class="n">instances</span><span class="o">=</span><span class="mi">1</span>
<span class="mi">01</span><span class="err">:</span><span class="k">AGGREGATE</span><span class="w"> </span><span class="o">[</span><span class="n">STREAMING</span><span class="o">]</span>
<span class="p">...</span>
<span class="mi">00</span><span class="err">:</span><span class="n">SCAN</span><span class="w"> </span><span class="n">HDFS</span><span class="w"> </span><span class="o">[</span><span class="n">default.sales_data, RANDOM</span><span class="o">]</span>
<span class="p">...</span>
<span class="w">        </span><span class="n">Fragment</span><span class="w"> </span><span class="nl">F02</span><span class="p">:</span>
<span class="w">          </span><span class="nl">CodeGen</span><span class="p">:</span>
<span class="w">            </span><span class="p">...</span>
<span class="w">            </span><span class="o">-</span><span class="w"> </span><span class="nl">NumCachedFunctions</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="w">            </span><span class="p">...</span>
<span class="w">            </span><span class="o">-</span><span class="w"> </span><span class="nl">NumOptimizedFunctions</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="w">            </span><span class="p">...</span>
<span class="w">            </span><span class="o">-</span><span class="w"> </span><span class="nl">TotalTime</span><span class="p">:</span><span class="w"> </span><span class="mf">52.000</span><span class="n">ms</span>
<span class="w">        </span><span class="n">Fragment</span><span class="w"> </span><span class="nl">F01</span><span class="p">:</span>
<span class="w">          </span><span class="nl">CodeGen</span><span class="p">:</span>
<span class="w">             </span><span class="p">...</span>
<span class="w">             </span><span class="o">-</span><span class="w"> </span><span class="nl">NumCachedFunctions</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="w">             </span><span class="p">...</span>
<span class="w">             </span><span class="o">-</span><span class="w"> </span><span class="nl">NumOptimizedFunctions</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="w"> </span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="w">             </span><span class="p">...</span>
<span class="w">             </span><span class="o">-</span><span class="w"> </span><span class="nl">TotalTime</span><span class="p">:</span><span class="w"> </span><span class="mf">100.000</span><span class="n">ms</span>
<span class="w">        </span><span class="n">Fragment</span><span class="w"> </span><span class="nl">F00</span><span class="p">:</span>
<span class="w">          </span><span class="nl">CodeGen</span><span class="p">:</span>
<span class="w">             </span><span class="p">...</span>
<span class="w">             </span><span class="o">-</span><span class="w"> </span><span class="nl">NumCachedFunctions</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="w">             </span><span class="p">...</span>
<span class="w">             </span><span class="o">-</span><span class="w"> </span><span class="nl">NumOptimizedFunctions</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="w"> </span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="w">             </span><span class="p">...</span>
<span class="w">             </span><span class="o">-</span><span class="w"> </span><span class="nl">TotalTime</span><span class="p">:</span><span class="w"> </span><span class="mf">116.000</span><span class="n">ms</span>
</pre></div>

<p>After running Query 2, the functions of fragments F02 and F01 are successfully loaded from the codegen cache, because these fragments are identical in both queries,  largely reducing the total codegen compilation time. However, Fragment F00 does not hit the codegen cache because different predicates are used in the two queries, like in our case, <code>category = 'a'</code> vs. <code>category = 'b'</code>. As a result, the codegen functions in the corresponding scan nodes are treated as distinct in the current version.</p>
<div class="code"><pre class="code literal-block">        Fragment F02:
          CodeGen:
            ...
            - NumCachedFunctions: 2 (2)
            ...
            - NumOptimizedFunctions: 2 (2)
            ...
            - TotalTime: 32.000ms
        Fragment F01:
          CodeGen:
            ...
            - NumCachedFunctions: 20 (20)
            ...
            - NumOptimizedFunctions: 20 (20)
            ...
            - TotalTime: 40.000ms
        Fragment F00:
          CodeGen:
            ...
            - NumCachedFunctions: 0 (0)
            ...
            - NumOptimizedFunctions: 20 (20)
            ...
            - TotalTime: 112.000ms
</pre></div>

<p>Note that native UDF won't be supported by the codegen cache, if a fragment contains any native UDF, the codegen of that fragment won't be cached.</p>
<h4>Summary</h4>
<p>Codegen Cache is supported and enabled by default since Impala 4.3. By setting the flag file option <code>CODEGEN_CACHE_CAPACITY</code>, you can adjust its default value of the memory used for codegen cache.</p>
<p>Interested in contributing? We have future work planned here for codegen caching - <a href="https://issues.apache.org/jira/browse/IMPALA-13187">IMPALA-13187</a></p>
<p><em>Reblogged with edit from <a href="https://medium.com/engineering-cloudera/codegen-cache-for-low-latency-queries-47d5fd947fcf">Engineering@Cloudera on Medium</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/healing-iceberg-tables-with-impala/" class="u-url">Healing Iceberg Tables with Impala</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/noemi-pap-takacs/">Noémi Pap-Takács</a>
            </span></p>
            <p class="dateline"><a href="posts/healing-iceberg-tables-with-impala/" rel="bookmark"><time class="published dt-published" datetime="2024-10-10T10:55:00-06:00" title="2024-10-10 10:55">2024-10-10 10:55</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Iceberg handles dynamically changing data at large scale. However, frequent modifications
come at a cost: eventually, tables will become fragmented. This degrades the performance of read
operations over time. To address this challenge, we introduced table maintenance features in Apache
Impala, the high performance, distributed DB engine for big data.</p>
<p>The new OPTIMIZE statement merges small data files and eliminates delete files to uphold table
health. It allows rewriting the table according to the latest schema and partition layout, and also
offers the flexibility of file filtering to optimize recurring maintenance jobs. Additionally, the
DROP PARTITION statement allows selective partition removal based on predicates.</p>
<p>Discover in this session how Impala ensures high performance on top of dynamically changing data.</p>
<p>[<a href="https://impala.apache.org/gh-docs/ccna24-table_maintenance.pdf">slides</a>]</p>
<p><em>Appeared in <a href="https://communityovercode.org/schedule/#sz-tab-45575">Community Over Code NA 2024</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/intelligent-utilization-aware-autoscaling-for-impala-virtual-compute-clusters/" class="u-url">Intelligent Utilization Aware Autoscaling for Impala Virtual Compute Clusters</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/kurt-deschler/">Kurt Deschler</a>
                <a href="authors/gokul-kolady/">Gokul Kolady</a>
                <a href="authors/abhishek-rawat/">Abhishek Rawat</a>
                <a href="authors/david-rorke/">David Rorke</a>
                <a href="authors/andrew-sherman/">Andrew Sherman</a>
                <a href="authors/riza-suminto/">Riza Suminto</a>
            </span></p>
            <p class="dateline"><a href="posts/intelligent-utilization-aware-autoscaling-for-impala-virtual-compute-clusters/" rel="bookmark"><time class="published dt-published" datetime="2024-10-08T14:50:00-06:00" title="2024-10-08 14:50">2024-10-08 14:50</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Sizing Virtual compute clusters for diverse and complex workloads is hard. Queries often require
large clusters to meet SLA requirements which can lead to low utilization and excessive cloud spend.
To solve this problem, we present intelligent autoscaling for Impala virtual warehouses. This
powerful feature dynamically analyzes query execution plans and resource requirements and adjusts
cluster size to follow the workload. Once cluster size limits have been set, the autoscaler works in
the background to maintain the ideal cluster size and is transparent to users. Observability UIs
have also been enhanced to help understand autoscaler behavior and further tune workloads.</p>
<p>We achieved 2 key goals with the design - delivering better ROI for compute cost and ease of use for
admins/users to manage Virtual Clusters.</p>
<p>[<a href="https://impala.apache.org/gh-docs/ccna24-intelligent_utilization_aware_scheduling.pdf">slides</a>]</p>
<p><em>Appeared in <a href="https://communityovercode.org/schedule/#sz-tab-45573">Community Over Code NA 2024</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/impalas-living-on-iceberg/" class="u-url">Impalas living on Iceberg</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/gabor-kaszab/">Gabor Kaszab</a>
            </span></p>
            <p class="dateline"><a href="posts/impalas-living-on-iceberg/" rel="bookmark"><time class="published dt-published" datetime="2024-10-07T16:00:00-06:00" title="2024-10-07 16:00">2024-10-07 16:00</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Impala is a horizontally scalable database engine renowned for its emphasis on query
efficiency. Over recent years, the Impala team has dedicated substantial effort to support Iceberg
tables. Impala can read, write, modify, and optimize Iceberg tables. Additionally, it facilitates
schema and partition evolution through DDL statements.</p>
<p>Attendees can anticipate a comprehensive overview of all Iceberg-related features within Impala,
along with insights into forthcoming developments expected this year. Given Impala's Java/C++ hybrid
architecture — where the frontend, responsible for analysis and planning, is Java-based while
backend executors are coded in C++ — the integration process encountered its own set of challenges.
This presentation will delve into some details of this integration work, shedding light on the
technical nuances.</p>
<p>[<a href="https://impala.apache.org/gh-docs/ccna24-impalas_living_on_iceberg.pdf">slides</a>]</p>
<p><em>Appeared in <a href="https://communityovercode.org/schedule/#sz-tab-45572">Community Over Code NA 2024</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/this-impala-not-only-reads-but-modifies-and-optimizes-iceberg-tables/" class="u-url">This Impala not only reads, but modifies and optimizes Iceberg tables</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/zoltan-borok-nagy/">Zoltán Borók-Nagy</a>
                <a href="authors/peter-rozsa/">Péter Rózsa</a>
                <a href="authors/noemi-pap-takacs/">Noémi Pap-Takács</a>
            </span></p>
            <p class="dateline"><a href="posts/this-impala-not-only-reads-but-modifies-and-optimizes-iceberg-tables/" rel="bookmark"><time class="published dt-published" datetime="2024-07-27T07:09:35-07:00" title="2024-07-27 07:09">2024-07-27 07:09</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Impala is a distributed, massively parallel query engine for big data. Initially, it focused
on fast query execution on top of large datasets that were ingested via long-running batch jobs. The
table schema and the ingested data typically remained unchanged, and row-level modifications were
impractical to say the least.</p>
<p>Today’s expectations for modern data warehouse engines have risen significantly. Users now want to
have RDBMS-like capabilities in their data warehouses. E.g., they often need to comply with
regulations like GDPR or CCPA, i.e. they need to be able to remove or update records belonging to
certain individuals.</p>
<p>Apache Iceberg is a cutting-edge table format that delivers advanced write capabilities for
large-scale data. It allows schema and partition evolution, time-travel, and the focus of this talk:
row-level modifications and table maintenance features. Impala has had support for reading Iceberg
tables and inserting data for a while, but the capability of deleting and updating rows only
recently became available.</p>
<p>Frequent modifications come with a cost: eventually, the table will become full of small data and
so-called delete files. This degrades the performance of read operations over time. The new table
maintenance statement in Impala, OPTIMIZE, merges small data files and eliminates delete files to
keep our table healthy. To make partition-level maintenance easier, DROP PARTITION statement allows
selective partition removal based on predicates.</p>
<p>Join us for this session to discover how Apache Impala evolved to meet emerging requirements without
compromising performance.</p>
<p><em>Appeared in <a href="https://eu.communityovercode.org/sessions/2024/this-impala-not-only-reads-but-modifies-and-optimizes-iceberg-tables/">https://eu.communityovercode.org/sessions/2024/this-impala-not-only-reads-but-modifies-and-optimizes-iceberg-tables/</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/lets-see-how-fast-impala-runs-on-iceberg/" class="u-url">Let’s see how fast Impala runs on Iceberg</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/gabor-kaszab/">Gabor Kaszab</a>
                <a href="authors/zoltan-borok-nagy/">Zoltán Borók-Nagy</a>
            </span></p>
            <p class="dateline"><a href="posts/lets-see-how-fast-impala-runs-on-iceberg/" rel="bookmark"><time class="published dt-published" datetime="2024-07-27T07:07:38-07:00" title="2024-07-27 07:07">2024-07-27 07:07</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Impala is a distributed massively parallel query engine designed for high-performance
querying of large-scale data. There has been a long list of new features recently around supporting
Apache Iceberg tables such as reading, writing, time traveling, and so on. However, in a big data
environment it is also a must to be performant. Since Impala has been designed to be fast, it has
its own way of reading Iceberg tables. Other engines might simply use the Iceberg library to perform
reads, while Impala has a C++ implementation itself optimized for speed.</p>
<p>Nowadays, even big data storage techniques have to offer the possibility not just to store data but
also to alter and delete data on a row level. Apache Iceberg solves this by using delete files that
live alongside the data files. It is the responsibility of the query engines to then apply the
delete files on the data files when querying the data. To efficiently read the data of such tables
we implemented new Iceberg-specific operators in Impala.</p>
<p>In this talk we will go into the implementation details and reveal what is the secret behind
Impala’s great performance in general and also when reading Iceberg tables with position delete
files. We will also show some measurements where we compare Impala’s performance with other
open-source query engines.</p>
<p>By the end of this talk, you should have a high-level understanding of Impala’s and Iceberg’s
architecture, the performance tricks we implemented in Impala specifically for Iceberg, and you will
see how Impala competes with other engines.</p>
<p><em>Appeared in <a href="https://eu.communityovercode.org/sessions/2024/lets-see-how-fast-impala-runs-on-iceberg/">https://eu.communityovercode.org/sessions/2024/lets-see-how-fast-impala-runs-on-iceberg/</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/anatomy-of-reading-apache-parquet-files-from-the-apache-impala-perspective/" class="u-url">Anatomy of reading Apache Parquet files (from the Apache Impala perspective)</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/csaba-ringhofer/">Csaba Ringhofer</a>
                <a href="authors/daniel-becker/">Daniel Becker</a>
            </span></p>
            <p class="dateline"><a href="posts/anatomy-of-reading-apache-parquet-files-from-the-apache-impala-perspective/" rel="bookmark"><time class="published dt-published" datetime="2024-07-27T07:02:43-07:00" title="2024-07-27 07:02">2024-07-27 07:02</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Reading file formats efficiently is a crucial part of big data systems -
in selective scans data is often only big before hitting the first
filter and becomes manageable during the rest of the processing. The
talk describes this early stage of query execution in Apache Impala,
from reading the bytes of Parquet files on the filesystem to applying
predicates and runtime filters on individual rows.</p>
<p>Apache Impala is a distributed massively parallel analytic query engine
written in C++ and Java. It is optimized both for object stores (S3,
ABFS) and on-prem distributed file systems (HDFS, Ozone). Apache Parquet
is one of the most widely used open source column-oriented file formats
in Big Data.</p>
<p>Impala has its own Parquet scanner written in C++ instead of using
existing Parquet libraries like Parquet-mr or Parquet-cpp. This allows
tighter integration with IO and and memory management, enabling features
like:</p>
<ul>
<li>Data caching to memory and local drive</li>
<li>Execution within memory bounds</li>
<li>Efficient parallelism</li>
</ul>
<p>These features all play an important role in giving Impala an edge in
the world of Big Data query engines.</p>
<p><em>Appeared in <a href="https://eu.communityovercode.org/sessions/2024/anatomy-parquet-files/">https://eu.communityovercode.org/sessions/2024/anatomy-parquet-files/</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/efficient-handling-of-geometry-data-in-apache-impala-with-parquet-files/" class="u-url">Efficient handling of geometry data in Apache Impala with Parquet files</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/csaba-ringhofer/">Csaba Ringhofer</a>
                <a href="authors/daniel-becker/">Daniel Becker</a>
            </span></p>
            <p class="dateline"><a href="posts/efficient-handling-of-geometry-data-in-apache-impala-with-parquet-files/" rel="bookmark"><time class="published dt-published" datetime="2023-10-10T08:00:00-03:00" title="2023-10-10 08:00">2023-10-10 08:00</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Impala, a distributed massively parallel analytic query engine written in C++ and Java, has
recently been extended with experimental geospatial support. Although this project is still in its
early stages, we have already gained useful insights into how we can achieve significant performance
improvements in geometry-related queries.</p>
<p>Even without purpose-built geospatial indices, the existing features of Apache Parquet (one of the
most widely used open source column-oriented file formats in Big Data) and partitioning allow the
vast majority of the data to be discarded in queries that filter for a bounding rectangle.</p>
<p>An advantage of relying on existing file and table format features (such as page indices, dictionary
encoding etc.) is that it is independent of database engines and does not require them to be aware
of geospatial concepts. Therefore also Apache Hive, Spark etc. could benefit from this approach.</p>
<p>Our method is based on a two-level division of space into cells. The coarser division is used for
table partitioning and the more fine-grained one for sorting the data within a partition. This can
work with Hive Metastore partitions or the Apache Iceberg table format – the latter further enhances
the efficiency and convenience of these optimisations. This scheme seems to be suitably flexible for
unevenly distributed real-world data and it provides enough filtering capability without causing
issues like inefficient compression or the small file problem.</p>
<p>[<a href="https://impala.apache.org/gh-docs/tue_geospatial_ringhofer-becker-daniel-becker.pdf">slides</a>]</p>
<p><em>Appeared in <a href="https://communityovercode.org/past-sessions/community-over-code-na-2023/">https://communityovercode.org/past-sessions/community-over-code-na-2023/</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/impala-learned-some-new-tricks-while-living-on-iceberg/" class="u-url">Impala learned some new tricks while living on Iceberg</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/zoltan-borok-nagy/">Zoltán Borók-Nagy</a>
            </span></p>
            <p class="dateline"><a href="posts/impala-learned-some-new-tricks-while-living-on-iceberg/" rel="bookmark"><time class="published dt-published" datetime="2023-10-09T08:00:00-03:00" title="2023-10-09 08:00">2023-10-09 08:00</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Apache Impala is a high-performance distributed query engine
specifically designed for lightning fast read operations. Apache Iceberg
is a groundbreaking table format that introduces advanced features such
as partition and schema evolution, data partitioning through transform
functions, time-travel capabilities, and row-level deletes. Recognizing
the significance of Iceberg, the Impala team has invested tremendous
development efforts to provide comprehensive support for its features.
This talk will cover the following key points:</p>
<ul>
<li>A brief overview of how Impala integrates with Iceberg</li>
<li>The limitations of traditional table formats</li>
<li>How Iceberg addresses these existing challenges and unlocks new possibilities</li>
<li>An exploration of Impala’s new features and some insights into their implementation</li>
</ul>
<p>Iceberg has transformed Impala from being solely a query engine
optimized for read operations into a robust data warehouse engine. With
Iceberg, Impala now extends its support to include ACID write operations
and table maintenance functions, enabling it to fulfill the role of a
comprehensive and versatile data warehouse engine. Join us for this
session to gain valuable insights into the integration between Impala
and Iceberg, and discover the new functionalities of Impala.</p>
<p>[<a href="https://impala.apache.org/gh-docs/mon_bigdata_impala_learned_some_new_tricks_while_living_on_iceberg-zoltan-borok-nagy.pdf">slides</a>]</p>
<p><em>Appeared in <a href="https://communityovercode.org/past-sessions/community-over-code-na-2023/">https://communityovercode.org/past-sessions/community-over-code-na-2023/</a></em></p>
    </div>
    </article><hr>
<article class="h-entry post-text"><header><h3 class="p-name entry-title"><a href="posts/impala-blog-coming-soon/" class="u-url">Impala Blog Coming Soon</a></h3>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">
                <a href="authors/impala-dev/">Impala Dev</a>
            </span></p>
            <p class="dateline"><a href="posts/impala-blog-coming-soon/" rel="bookmark"><time class="published dt-published" datetime="2017-01-03T15:45:20-08:00" title="2017-01-03 15:45">2017-01-03 15:45</time></a></p>
        </div>
    </header><div class="p-summary entry-summary">
    <p>Watch this space for the first blog post from the Impala Team.</p>
<p>See also <a href="https://blog.cloudera.com/tag/apache-impala/">posts about Impala on the Cloudera blog</a>.</p>
    </div>
    </article>
</div>
        <nav class="postindexpager"><ul class="pager">
<li class="next">
                <a href="index-1.html" rel="next">Older posts</a>
            </li>
        </ul></nav></main><footer id="footer"><p> </p>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container">

          <ul class="nav">
<li><a href="https://www.apache.org/licenses/">License</a></li>
            <li><a href="https://www.apache.org/foundation/sponsorship.html">Sponsorship</a></li>
            <li><a href="https://www.apache.org/foundation/thanks.html">Thanks</a></li>
            <li><a href="https://www.apache.org/security/">Security</a></li>
            <li><a href="https://www.apache.org/">Apache Software Foundation</a></li>
          </ul>
</div>
<!-- container -->
      </div>
<!-- navbar-inner -->
    </div>
<!-- navbar -->

    <div class="footer">
      <center>
        <a href="https://www.apache.org/events/current-event.html">
          <img src="https://www.apache.org/events/current-event-234x60.png"></a>
      </center>
      <p>Apache Impala, Impala, Apache, the Apache feather logo, and the Apache
        Impala project logo are either registered trademarks or trademarks of The
        Apache Software Foundation in the United States and other countries.
      </p>
    </div>
<!-- footer -->

      <p>Contents © 2016-2024         <a href="mailto:dev@impala.apache.org">Impala Dev</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
  </footer>
</div>
<!-- container -->
</body>
</html>
