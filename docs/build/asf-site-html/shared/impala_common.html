<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="copyright" content="(C) Copyright 2025"><meta name="DC.rights.owner" content="(C) Copyright 2025"><meta name="DC.Type" content="concept"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="common"><link rel="stylesheet" type="text/css" href="../css/commonltr.css"><link rel="stylesheet" type="text/css" href="../css/dita-ot-doc.css"><title>Reusable Text, Paragraphs, List Items, and Other Elements for Impala</title></head><body id="common"><header role="banner"><!--
The DITA Open Toolkit is licensed for use under the the Apache
Software Foundation License v2.0.

A copy of the Apache Software Foundation License 2.0 is
available at http://opensource.org/licenses/apache2.0.php

This statement must be included in any copies of DITA Open
Toolkit code.
--><div class="header">
  <p>Apache Impala</p>
  <hr>
</div></header><nav role="toc"><ul></ul></nav><main role="main"><article role="article" aria-labelledby="ariaid-title1">

  <h1 class="title topictitle1" id="ariaid-title1">Reusable Text, Paragraphs, List Items, and Other Elements for Impala</h1>

  <div class="body conbody">

    <p class="p">
      All the elements in this file with IDs are intended to be conref'ed elsewhere. Practically
      all of the conref'ed elements for the Impala docs are in this file, to avoid questions of
      when it's safe to remove or move something in any of the 'main' files, and avoid having to
      change and conref references as a result.
    </p>

    <p class="p">
      This file defines some dummy subheadings as section elements, just for self-documentation.
      Using sections instead of nested concepts lets all the conref links point to a very simple
      name pattern, '#common/id_within_the_file', rather than a 3-part reference with an
      intervening, variable concept ID.
    </p>

    <section class="section" id="common__concepts"><h2 class="title sectiontitle">Conceptual Content</h2>

      

      <p class="p">
        Overview and conceptual information for Impala as a whole.
      </p>



      <div class="p" id="common__impala_advantages">
        The following are some of the key advantages of Impala:
        <ul class="ul">
          <li class="li">
            Impala integrates with the existing <span class="keyword">Apache Hadoop</span> ecosystem,
            meaning data can be stored, shared, and accessed using the various solutions
            included with <span class="keyword">Apache Hadoop</span>. This also avoids data silos and
            minimizes expensive data movement.
          </li>

          <li class="li">
            Impala provides access to data stored in <span class="keyword">Apache Hadoop</span> without
            requiring the Java skills required for MapReduce jobs. Impala can access data
            directly from the HDFS file system. Impala also provides a SQL front-end to access
            data in the HBase database system, <span class="ph">or in the Amazon Simple Storage
            System (S3)</span>.
          </li>

          <li class="li">
            Impala returns results typically within seconds or a few minutes, rather than the
            many minutes or hours that are often required for Hive queries to complete.
          </li>

          <li class="li">
            Impala is pioneering the use of the Parquet file format, a columnar storage layout
            that is optimized for large-scale queries typical in data warehouse scenarios.
          </li>
        </ul>
      </div>

      <div class="p" id="common__impala_benefits">
        Impala provides:
        <ul class="ul">
          <li class="li">
            Familiar SQL interface that data scientists and analysts already know.
          </li>

          <li class="li">
            Ability to query high volumes of data (<span class="q">"big data"</span>) in Apache Hadoop.
          </li>

          <li class="li">
            Distributed queries in a cluster environment, for convenient scaling and to make use
            of cost-effective commodity hardware.
          </li>

          <li class="li">
            Ability to share data files between different components with no copy or
            export/import step; for example, to write with Pig, transform with Hive and query
            with Impala. Impala can read from and write to Hive tables, enabling simple data
            interchange using Impala for analytics on Hive-produced data.
          </li>

          <li class="li">
            Single system for big data processing and analytics, so customers can avoid costly
            modeling and ETL just for analytics.
          </li>
        </ul>
      </div>

    </section>

    <section class="section" id="common__authz"><h2 class="title sectiontitle">Authorization Content</h2>

      

      <p class="p"> Material related to Sentry and Ranger security, intended to be reused
        between Hive and Impala. Complicated by the fact that most of it will
        probably be multi-paragraph or involve subheads, might need to be
        represented as nested topics at the end of this file. </p>

      <div class="p" id="common__privileges_objects">
        The table below lists the minimum level of privileges and the scope required to execute
        SQL statements in <span class="keyword">Impala 3.0</span> and higher. The following notations
        are used:
        <ul class="ul">
          <li class="li">The <strong class="ph b">SERVER</strong> resource type in Ranger implies all databases,
            all tables, all columns, all UDFs, and all URIs.</li>
          <li class="li">
            <strong class="ph b">ANY</strong> denotes the <code class="ph codeph">SELECT</code>, <code class="ph codeph">INSERT</code>,
            <code class="ph codeph">CREATE</code>, <code class="ph codeph">ALTER</code>, <code class="ph codeph">DROP</code>,
            <strong class="ph b"><em class="ph i">or</em></strong> <code class="ph codeph">REFRESH</code> privilege.
          </li>

          <li class="li">
            <strong class="ph b">ALL</strong> privilege denotes the <code class="ph codeph">SELECT</code>, <code class="ph codeph">INSERT</code>,
            <code class="ph codeph">CREATE</code>, <code class="ph codeph">ALTER</code>, <code class="ph codeph">DROP</code>,
            <strong class="ph b"><em class="ph i">and</em></strong> <code class="ph codeph">REFRESH</code> privileges.
          </li>

          <li class="li">
            The owner of an object effectively has the ALL privilege on the object.
          </li>

          <li class="li">
            The parent levels of the specified scope are implicitly supported where a scope
            refers to the specific level in the object hierarchy that the privilege is granted.
            For example, if a privilege is listed with the <code class="ph codeph">TABLE</code> scope, the
            same privilege granted on <code class="ph codeph">DATABASE</code> and <code class="ph codeph">SERVER</code> will
            allow the user to execute the specified SQL statement.
          </li>
        </ul>
        <table class="table frame-all" id="common__sentry_privileges_objects_tab"><caption></caption><colgroup><col><col><col></colgroup><tbody class="tbody">
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  <strong class="ph b">SQL Statement</strong>
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  <strong class="ph b">Privileges</strong>
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  <strong class="ph b">Object Type / </strong><p class="p"><strong class="ph b">Resource Type</strong></p></td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1"> TABLE</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  WITH SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  EXPLAIN SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  EXPLAIN INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TRUNCATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  LOAD
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  URI
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE DATABASE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SERVER
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE DATABASE LOCATION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SERVER
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  URI
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE TABLE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE TABLE LIKE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE TABLE AS SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  EXPLAIN CREATE TABLE AS SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INSERT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE TABLE LOCATION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  URI
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE VIEW
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER DATABASE SET OWNER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL WITH GRANT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER TABLE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER TABLE SET LOCATION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  URI
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER TABLE RENAME
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER TABLE SET OWNER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL WITH GRANT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER VIEW
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER VIEW RENAME
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER VIEW SET OWNER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL WITH GRANT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  VIEW
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP DATABASE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP TABLE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP VIEW
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE FUNCTION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  CREATE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1"></td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  URI
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP FUNCTION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  COMPUTE STATS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER and SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DROP STATS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INVALIDATE METADATA
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SERVER
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  INVALIDATE METADATA &lt;table&gt;
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH &lt;table&gt;
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH AUTHORIZATION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SERVER
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH FUNCTIONS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  COMMENT ON DATABASE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  COMMENT ON TABLE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  COMMENT ON VIEW
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  COMMENT ON COLUMN
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALTER
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DESCRIBE DATABASE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DESCRIBE &lt;table/view&gt;
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  If the user has the SELECT privilege at the COLUMN level, only the columns the
                  user has access will show.
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  COLUMN
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  USE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ANY
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW DATABASES
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ANY
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW TABLES
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ANY
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW FUNCTIONS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW PARTITIONS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW TABLE STATS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW COLUMN STATS
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW FILES
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW CREATE TABLE
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW CREATE VIEW
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW CREATE FUNCTION
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DATABASE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SHOW RANGE PARTITIONS (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  SELECT, INSERT, <strong class="ph b"><em class="ph i">or</em></strong> REFRESH
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  UPDATE (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  EXPLAIN UPDATE (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  UPSERT (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  WITH UPSERT (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  EXPLAIN UPSERT (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  DELETE (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  EXPLAIN DELETE (Kudu only)
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  ALL
                </td>
                <td class="entry cellrowborder colsep-1 rowsep-1">
                  TABLE
                </td>
              </tr>
            </tbody></table>
      </div>

      <div class="p" id="common__auth_to_local_instructions">
        In <span class="keyword">Impala 2.6</span> and higher, Impala recognizes the
        <code class="ph codeph">auth_to_local</code> setting, specified through the HDFS configuration setting
        <code class="ph codeph">hadoop.security.auth_to_local</code>. This feature is disabled by default, to
        avoid an unexpected change in security-related behavior. To enable it:
        <ul class="ul">
          <li class="li">
            <p class="p">
              Specify <code class="ph codeph">‑‑load_auth_to_local_rules=true</code> in the
              <span class="keyword cmdname">impalad</span> and <span class="keyword cmdname">catalogd</span> configuration settings.
            </p>
          </li>
        </ul>
      </div>

      <div class="note note note_note" id="common__authentication_vs_authorization"><span class="note__title notetitle">Note:</span> 
        Regardless of the authentication mechanism used, Impala always creates HDFS directories
        and data files owned by the same user (typically <code class="ph codeph">impala</code>). To implement
        user-level access to different databases, tables, columns, partitions, and so on, use
        the Sentry authorization feature, as explained in
        <a class="xref" href="../topics/impala_authorization.html#authorization">Impala Authorization</a>.
      </div>



      <p class="p">
        <strong class="ph b"><span class="ph" id="common__title_sentry_debug">Debugging Failed Sentry Authorization Requests</span></strong>
      </p>

      <div class="p" id="common__sentry_debug">
        Sentry logs all facts that lead up to authorization decisions at the debug level. If you
        do not understand why Sentry is denying access, the best way to debug is to temporarily
        turn on debug logging:
        <ul class="ul">
          <li class="li">
            Add <code class="ph codeph">log4j.logger.org.apache.sentry=DEBUG</code> to the
            <span class="ph filepath">log4j.properties</span> file on each host in the cluster, in the
            appropriate configuration directory for each service.
          </li>
        </ul>
        Specifically, look for exceptions and messages such as:
<pre class="pre codeblock"><code>FilePermission server..., RequestPermission server...., result [true|false]</code></pre>
        which indicate each evaluation Sentry makes. The <code class="ph codeph">FilePermission</code> is from
        the policy file, while <code class="ph codeph">RequestPermission</code> is the privilege required for
        the query. A <code class="ph codeph">RequestPermission</code> will iterate over all appropriate
        <code class="ph codeph">FilePermission</code> settings until a match is found. If no matching
        privilege is found, Sentry returns <code class="ph codeph">false</code> indicating <span class="q">"Access
        Denied"</span>.
      </div>

    </section>

    <section class="section" id="common__restrictions"><h2 class="title sectiontitle">Restrictions and Limitations</h2>

      

      <p class="p">
        Potential misunderstandings for people familiar with other database systems. Currently
        not referenced anywhere, because they were only conref'ed from the FAQ page.
      </p>

      <div class="p" id="common__string_concatenation">
        With Impala, you use the built-in <code class="ph codeph">CONCAT()</code> function to concatenate two,
        three, or more strings:
<pre class="pre codeblock"><code>select concat('some prefix: ', col1) from t1;
select concat('abc','mno','xyz');</code></pre>
        Impala does not currently support operators for string concatenation, such as
        <code class="ph codeph">||</code> as seen in some other database systems.
      </div>

      <div class="p" id="common__column_aliases">
        You can specify column aliases with or without the <code class="ph codeph">AS</code> keyword, and with
        no quotation marks, single quotation marks, or double quotation marks. Some kind of
        quotation marks are required if the column alias contains any spaces or other
        problematic characters. The alias text is displayed in the
        <span class="keyword cmdname">impala-shell</span> output as all-lowercase. For example:
<pre class="pre codeblock"><code>[localhost:21000] &gt; select c1 First_Column from t;
[localhost:21000] &gt; select c1 as First_Column from t;
+--------------+
| first_column |
+--------------+
...

[localhost:21000] &gt; select c1 'First Column' from t;
[localhost:21000] &gt; select c1 as 'First Column' from t;
+--------------+
| first column |
+--------------+
...

[localhost:21000] &gt; select c1 "First Column" from t;
[localhost:21000] &gt; select c1 as "First Column" from t;
+--------------+
| first column |
+--------------+
...</code></pre>
        From Impala 3.0, the alias substitution logic in the <code class="ph codeph">GROUP BY</code>,
        <code class="ph codeph">HAVING</code>, and <code class="ph codeph">ORDER BY</code> clauses has become more
        consistent with standard SQL behavior, as follows. Aliases are now only legal at the top
        level, and not in subexpressions. The following statements are allowed:
<pre class="pre codeblock"><code>
  SELECT int_col / 2 AS x
  FROM t
  GROUP BY x;

  SELECT int_col / 2 AS x
  FROM t
  ORDER BY x;

  SELECT NOT bool_col AS nb
  FROM t
  GROUP BY nb
  HAVING nb;
</code></pre>
        And the following statements are NOT allowed:
<pre class="pre codeblock"><code>
  SELECT int_col / 2 AS x
  FROM t
  GROUP BY x / 2;

  SELECT int_col / 2 AS x
  FROM t
  ORDER BY -x;

  SELECT int_col / 2 AS x
  FROM t
  GROUP BY x
  HAVING x &gt; 3;
</code></pre>
      </div>

      <div class="p" id="common__column_ordinals"> You can refer to
          <code class="ph codeph">SELECT</code>-list items by their ordinal position. Impala
        supports ordinals in the <code class="ph codeph">GROUP BY</code>,
          <code class="ph codeph">HAVING</code>, and <code class="ph codeph">ORDER BY</code> clauses. From
        Impala 3.0, ordinals can only be used at the top level. For example, the
        following statements are allowed:
        <pre class="pre codeblock"><code>
  SELECT int_col / 2, sum(x)
  FROM t
  GROUP BY 1;

  SELECT int_col / 2
  FROM t
  ORDER BY 1;

  SELECT NOT bool_col
  FROM t
  GROUP BY 1
  HAVING 1;
</code></pre>
        Numbers in subexpressions are not interpreted as ordinals:
        <pre class="pre codeblock"><code>
  SELECT int_col / 2, sum(x)
  FROM t
  GROUP BY 1 * 2;
The above parses OK, however GROUP BY 1 * 2 has no effect.

  SELECT int_col / 2
  FROM t
  ORDER BY 1 + 2;
The above parses OK, however ORDER BY 1 + 2 has no effect.

  SELECT NOT bool_col
  FROM t
  GROUP BY 1
  HAVING not 1;
The above raises an error at parse-time.
</code></pre>
      </div>

      <p class="p" id="common__temp_tables">
        Currently, Impala does not support temporary tables. Some other database systems have a
        class of <span class="q">"lightweight"</span> tables that are held only in memory and/or that are only
        accessible by one connection and disappear when the session ends. In Impala, creating
        new databases is a relatively lightweight operation, so as an alternative, you could
        create a database with a unique name and use <code class="ph codeph">CREATE TABLE LIKE</code>,
        <code class="ph codeph">CREATE TABLE AS SELECT</code>, and <code class="ph codeph">INSERT</code> statements to
        create a table in that database to hold the result set of a query, to use in subsequent
        queries. When finished, issue a <code class="ph codeph">DROP TABLE</code> statement followed by
        <code class="ph codeph">DROP DATABASE</code>.
      </p>

    </section>

    <section class="section" id="common__standards"><h2 class="title sectiontitle">Blurbs About Standards Compliance</h2>

      

      <p class="p">
        The following blurbs simplify the process of flagging which SQL standard various
        features were first introduced in. The wording and the tagging can be modified by
        editing one central instance of each blurb. Not extensively used yet, just here and
        there in the SQL Language Reference section.
      </p>

      <p class="p" id="common__sql1986">

        <strong class="ph b">Standards compliance:</strong> Introduced in SQL-1986.
      </p>

      <p class="p" id="common__sql1989">

        <strong class="ph b">Standards compliance:</strong> Introduced in SQL-1989.
      </p>

      <p class="p" id="common__sql1992">
        <strong class="ph b">Standards compliance:</strong> Introduced in
        <a class="xref" href="http://en.wikipedia.org/wiki/SQL-92" target="_blank">SQL-1992</a>.
      </p>

      <p class="p" id="common__sql1999">
        <strong class="ph b">Standards compliance:</strong> Introduced in
        <a class="xref" href="http://en.wikipedia.org/wiki/SQL:1999" target="_blank">SQL:1999</a>.
      </p>

      <p class="p" id="common__sql2003">
        <strong class="ph b">Standards compliance:</strong> Introduced in
        <a class="xref" href="http://en.wikipedia.org/wiki/SQL:2003" target="_blank">SQL:2003</a>.
      </p>

      <p class="p" id="common__sql2008">
        <strong class="ph b">Standards compliance:</strong> Introduced in
        <a class="xref" href="http://en.wikipedia.org/wiki/SQL:2008" target="_blank">SQL:2008</a>.
      </p>

      <p class="p" id="common__sql2011">
        <strong class="ph b">Standards compliance:</strong> Introduced in
        <a class="xref" href="http://en.wikipedia.org/wiki/SQL:2011" target="_blank">SQL:2011</a>.
      </p>

      <p class="p" id="common__hiveql">
        <strong class="ph b">Standards compliance:</strong> Extension first introduced in HiveQL.
      </p>

      <p class="p" id="common__impalaql">
        <strong class="ph b">Standards compliance:</strong> Extension first introduced in Impala.
      </p>

    </section>

    <section class="section" id="common__refresh_invalidate"><h2 class="title sectiontitle">Background Info for REFRESH, INVALIDATE METADATA, and General Metadata Discussion</h2>

      

      <p class="p" id="common__invalidate_then_refresh">
        Because <code class="ph codeph">REFRESH <var class="keyword varname">table_name</var></code> only works for tables
        that the current Impala node is already aware of, when you create a new table in the
        Hive shell, enter <code class="ph codeph">INVALIDATE METADATA <var class="keyword varname">new_table</var></code>
        before you can see the new table in <span class="keyword cmdname">impala-shell</span>. Once the table is
        known by Impala, you can issue <code class="ph codeph">REFRESH <var class="keyword varname">table_name</var></code>
        after you add data files for that table.
      </p>

      <div class="p" id="common__refresh_vs_invalidate">
        <code class="ph codeph">INVALIDATE METADATA</code> and <code class="ph codeph">REFRESH</code> are counterparts:
        <ul class="ul">
          <li class="li">
            <code class="ph codeph">INVALIDATE METADATA</code> is an asynchronous operations that simply
            discards the loaded metadata from the catalog and coordinator caches. After that
            operation, the catalog and all the Impala coordinators only know about the existence
            of databases and tables and nothing more. Metadata loading for tables is triggered
            by any subsequent queries.
          </li>

          <li class="li">
            <code class="ph codeph">REFRESH</code> reloads the metadata synchronously.
            <code class="ph codeph">REFRESH</code> is more lightweight than doing a full metadata load after a
            table has been invalidated. <code class="ph codeph">REFRESH</code> cannot detect changes in block
            locations triggered by operations like HDFS balancer, hence causing remote reads
            during query execution with negative performance implications.
          </li>
        </ul>
      </div>

    </section>

    <section class="section" id="common__sql_ref"><h2 class="title sectiontitle">SQL Language Reference Snippets</h2>

      

      <p class="p">
        These reusable chunks were taken from conrefs originally in
        <span class="ph filepath">ciiu_langref_sql.xml</span>. Or they are primarily used in new SQL syntax
        topics underneath that parent topic.
      </p>

      <p class="p" id="common__tablesample_caveat">
        The <code class="ph codeph">TABLESAMPLE</code> clause of the <code class="ph codeph">SELECT</code> statement does
        not apply to a table reference derived from a view, a subquery, or anything other than a
        real base table. This clause only works for tables backed by HDFS or HDFS-like data
        files, therefore it does not apply to Kudu or HBase tables.
      </p>

      <p class="p" id="common__boolean_functions_vs_expressions">
        In <span class="keyword">Impala 2.11</span> and higher, you can use the operators <code class="ph codeph">IS
        [NOT] TRUE</code> and <code class="ph codeph">IS [NOT] FALSE</code> as equivalents for the built-in
        functions <code class="ph codeph">ISTRUE()</code>, <code class="ph codeph">ISNOTTRUE()</code>,
        <code class="ph codeph">ISFALSE()</code>, and <code class="ph codeph">ISNOTFALSE()</code>.
      </p>

      <p class="p" id="common__base64_charset">
        The set of characters that can be generated as output from
        <code class="ph codeph">BASE64ENCODE()</code>, or specified in the argument string to
        <code class="ph codeph">BASE64DECODE()</code>, are the ASCII uppercase and lowercase letters (A-Z,
        a-z), digits (0-9), and the punctuation characters <code class="ph codeph">+</code>,
        <code class="ph codeph">/</code>, and <code class="ph codeph">=</code>.
      </p>

      <p class="p" id="common__base64_error_handling">
        If the argument string to <code class="ph codeph">BASE64DECODE()</code> does not represent a valid
        base64-encoded value, subject to the constraints of the Impala implementation such as
        the allowed character set, the function returns <code class="ph codeph">NULL</code>.
      </p>

      <p class="p" id="common__base64_use_cases">
        The functions <code class="ph codeph">BASE64ENCODE()</code> and <code class="ph codeph">BASE64DECODE()</code> are
        typically used in combination, to store in an Impala table string data that is
        problematic to store or transmit. For example, you could use these functions to store
        string data that uses an encoding other than UTF-8, or to transform the values in
        contexts that require ASCII values, such as for partition key columns. Keep in mind that
        base64-encoded values produce different results for string functions such as
        <code class="ph codeph">LENGTH()</code>, <code class="ph codeph">MAX()</code>, and <code class="ph codeph">MIN()</code> than when
        those functions are called with the unencoded string values.
      </p>

      <p class="p" id="common__base64_alignment">
        All return values produced by <code class="ph codeph">BASE64ENCODE()</code> are a multiple of 4 bytes
        in length. All argument values supplied to <code class="ph codeph">BASE64DECODE()</code> must also be
        a multiple of 4 bytes in length. If a base64-encoded value would otherwise have a
        different length, it can be padded with trailing <code class="ph codeph">=</code> characters to reach
        a length that is a multiple of 4 bytes.
      </p>

      <div class="p" id="common__base64_examples">
        The following examples show how to use <code class="ph codeph">BASE64ENCODE()</code> and
        <code class="ph codeph">BASE64DECODE()</code> together to store and retrieve string values:
<pre class="pre codeblock"><code>
-- An arbitrary string can be encoded in base 64.
-- The length of the output is a multiple of 4 bytes,
-- padded with trailing = characters if necessary.
select base64encode('hello world') as encoded,
  length(base64encode('hello world')) as length;
+------------------+--------+
| encoded          | length |
+------------------+--------+
| aGVsbG8gd29ybGQ= | 16     |
+------------------+--------+

-- Passing an encoded value to base64decode() produces
-- the original value.
select base64decode('aGVsbG8gd29ybGQ=') as decoded;
+-------------+
| decoded     |
+-------------+
| hello world |
+-------------+
</code></pre>
        These examples demonstrate incorrect encoded values that produce <code class="ph codeph">NULL</code>
        return values when decoded:
<pre class="pre codeblock"><code>
-- The input value to base64decode() must be a multiple of 4 bytes.
-- In this case, leaving off the trailing = padding character
-- produces a NULL return value.
select base64decode('aGVsbG8gd29ybGQ') as decoded;
+---------+
| decoded |
+---------+
| NULL    |
+---------+
WARNINGS: UDF WARNING: Invalid base64 string; input length is 15,
  which is not a multiple of 4.

-- The input to base64decode() can only contain certain characters.
-- The $ character in this case causes a NULL return value.
select base64decode('abc$');
+----------------------+
| base64decode('abc$') |
+----------------------+
| NULL                 |
+----------------------+
WARNINGS: UDF WARNING: Could not base64 decode input in space 4; actual output length 0
</code></pre>
        These examples demonstrate <span class="q">"round-tripping"</span> of an original string to an encoded
        string, and back again. This technique is applicable if the original source is in an
        unknown encoding, or if some intermediate processing stage might cause national
        characters to be misrepresented:
<pre class="pre codeblock"><code>
select 'circumflex accents: â, ê, î, ô, û' as original,
  base64encode('circumflex accents: â, ê, î, ô, û') as encoded;
+-----------------------------------+------------------------------------------------------+
| original                          | encoded                                              |
+-----------------------------------+------------------------------------------------------+
| circumflex accents: â, ê, î, ô, û | Y2lyY3VtZmxleCBhY2NlbnRzOiDDoiwgw6osIMOuLCDDtCwgw7s= |
+-----------------------------------+------------------------------------------------------+

select base64encode('circumflex accents: â, ê, î, ô, û') as encoded,
  base64decode(base64encode('circumflex accents: â, ê, î, ô, û')) as decoded;
+------------------------------------------------------+-----------------------------------+
| encoded                                              | decoded                           |
+------------------------------------------------------+-----------------------------------+
| Y2lyY3VtZmxleCBhY2NlbnRzOiDDoiwgw6osIMOuLCDDtCwgw7s= | circumflex accents: â, ê, î, ô, û |
+------------------------------------------------------+-----------------------------------+
</code></pre>
      </div>

<pre class="pre codeblock" id="common__parquet_fallback_schema_resolution_example"><code>
create database schema_evolution;
use schema_evolution;
create table t1 (c1 int, c2 boolean, c3 string, c4 timestamp)
  stored as parquet;
insert into t1 values
  (1, true, 'yes', now()),
  (2, false, 'no', now() + interval 1 day);

select * from t1;
+----+-------+-----+-------------------------------+
| c1 | c2    | c3  | c4                            |
+----+-------+-----+-------------------------------+
| 1  | true  | yes | 2016-06-28 14:53:26.554369000 |
| 2  | false | no  | 2016-06-29 14:53:26.554369000 |
+----+-------+-----+-------------------------------+

desc formatted t1;
...
| Location:   | /user/hive/warehouse/schema_evolution.db/t1 |
...

-- Make T2 have the same data file as in T1, including 2
-- unused columns and column order different than T2 expects.
load data inpath '/user/hive/warehouse/schema_evolution.db/t1'
  into table t2;
+----------------------------------------------------------+
| summary                                                  |
+----------------------------------------------------------+
| Loaded 1 file(s). Total files in destination location: 1 |
+----------------------------------------------------------+

-- 'position' is the default setting.
-- Impala cannot read the Parquet file if the column order does not match.
set PARQUET_FALLBACK_SCHEMA_RESOLUTION=position;
PARQUET_FALLBACK_SCHEMA_RESOLUTION set to position

select * from t2;
WARNINGS:
File 'schema_evolution.db/t2/45331705_data.0.parq'
has an incompatible Parquet schema for column 'schema_evolution.t2.c4'.
Column type: TIMESTAMP, Parquet schema: optional int32 c1 [i:0 d:1 r:0]

File 'schema_evolution.db/t2/45331705_data.0.parq'
has an incompatible Parquet schema for column 'schema_evolution.t2.c4'.
Column type: TIMESTAMP, Parquet schema: optional int32 c1 [i:0 d:1 r:0]

-- With the 'name' setting, Impala can read the Parquet data files
-- despite mismatching column order.
set PARQUET_FALLBACK_SCHEMA_RESOLUTION=name;
PARQUET_FALLBACK_SCHEMA_RESOLUTION set to name

select * from t2;
+-------------------------------+-------+
| c4                            | c2    |
+-------------------------------+-------+
| 2016-06-28 14:53:26.554369000 | true  |
| 2016-06-29 14:53:26.554369000 | false |
+-------------------------------+-------+

</code></pre>

      <div class="note note note_note" id="common__one_but_not_true"><span class="note__title notetitle">Note:</span> 
        In <span class="keyword">Impala 2.5.0</span>, only the value 1 enables the option, and the value
        <code class="ph codeph">true</code> is not recognized. This limitation is tracked by the issue
        <a class="xref" href="https://issues.apache.org/jira/browse/IMPALA-3334" target="_blank">IMPALA-3334</a>, which shows the releases where the
        problem is fixed.
      </div>

      <p class="p" id="common__avro_2gb_strings">
        The Avro specification allows string values up to 2**64 bytes in length. Impala queries
        for Avro tables use 32-bit integers to hold string lengths. In
        <span class="keyword">Impala 2.5</span> and higher, Impala truncates <code class="ph codeph">CHAR</code> and
        <code class="ph codeph">VARCHAR</code> values in Avro tables to (2**31)-1 bytes. If a query encounters
        a <code class="ph codeph">STRING</code> value longer than (2**31)-1 bytes in an Avro table, the query
        fails. In earlier releases, encountering such long values in an Avro table could cause a
        crash.
      </p>

      <div class="p" id="common__set_column_stats_example">
        You specify a case-insensitive symbolic name for the kind of statistics:
        <code class="ph codeph">numDVs</code>, <code class="ph codeph">numNulls</code>, <code class="ph codeph">avgSize</code>,
        <code class="ph codeph">maxSize</code>. The key names and values are both quoted. This operation
        applies to an entire table, not a specific partition. For example:
<pre class="pre codeblock"><code>
create table t1 (x int, s string);
insert into t1 values (1, 'one'), (2, 'two'), (2, 'deux');
show column stats t1;
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| x      | INT    | -1               | -1     | 4        | 4        |
| s      | STRING | -1               | -1     | -1       | -1       |
+--------+--------+------------------+--------+----------+----------+
alter table t1 set column stats x ('numDVs'='2','numNulls'='0');
alter table t1 set column stats s ('numdvs'='3','maxsize'='4');
show column stats t1;
+--------+--------+------------------+--------+----------+----------+
| Column | Type   | #Distinct Values | #Nulls | Max Size | Avg Size |
+--------+--------+------------------+--------+----------+----------+
| x      | INT    | 2                | 0      | 4        | 4        |
| s      | STRING | 3                | -1     | 4        | -1       |
+--------+--------+------------------+--------+----------+----------+
</code></pre>
      </div>

<pre class="pre codeblock" id="common__set_numrows_example"><code>create table analysis_data stored as parquet as select * from raw_data;
Inserted 1000000000 rows in 181.98s
compute stats analysis_data;
insert into analysis_data select * from smaller_table_we_forgot_before;
Inserted 1000000 rows in 15.32s
-- Now there are 1001000000 rows. We can update this single data point in the stats.
alter table analysis_data set tblproperties('numRows'='1001000000', 'STATS_GENERATED_VIA_STATS_TASK'='true');</code></pre>

<pre class="pre codeblock" id="common__set_numrows_partitioned_example"><code>-- If the table originally contained 1 million rows, and we add another partition with 30 thousand rows,
-- change the numRows property for the partition and the overall table.
alter table partitioned_data partition(year=2009, month=4) set tblproperties ('numRows'='30000', 'STATS_GENERATED_VIA_STATS_TASK'='true');
alter table partitioned_data set tblproperties ('numRows'='1030000', 'STATS_GENERATED_VIA_STATS_TASK'='true');</code></pre>

      <p class="p" id="common__int_overflow_behavior">
        Impala does not return column overflows as <code class="ph codeph">NULL</code>, so that customers can
        distinguish between <code class="ph codeph">NULL</code> data and overflow conditions similar to how
        they do so with traditional database systems. Impala returns the largest or smallest
        value in the range for the type. For example, valid values for a
        <code class="ph codeph">tinyint</code> range from -128 to 127. In Impala, a <code class="ph codeph">tinyint</code>
        with a value of -200 returns -128 rather than <code class="ph codeph">NULL</code>. A
        <code class="ph codeph">tinyint</code> with a value of 200 returns 127.
      </p>

      <p class="p" id="common__partition_key_optimization">
        If you frequently run aggregate functions such as <code class="ph codeph">MIN()</code>,
        <code class="ph codeph">MAX()</code>, and <code class="ph codeph">COUNT(DISTINCT)</code> on partition key columns,
        consider enabling the <code class="ph codeph">OPTIMIZE_PARTITION_KEY_SCANS</code> query option, which
        optimizes such queries. This feature is available in <span class="keyword">Impala 2.5</span>
        and higher. See <a class="xref" href="../topics/impala_optimize_partition_key_scans.html">OPTIMIZE_PARTITION_KEY_SCANS Query Option (Impala 2.5 or higher only)</a> for the
        kinds of queries that this option applies to, and slight differences in how partitions
        are evaluated when this query option is enabled.
      </p>

      <p class="p" id="common__live_reporting_details">
        The output from this query option is printed to standard
        error. The output is  displayed only in interactive mode, not when the <code class="ph codeph">-q</code>
        or <code class="ph codeph">-f</code> options are used. 
      </p>

      <p class="p" id="common__live_progress_live_summary_asciinema">To see how the <code class="ph codeph">LIVE_PROGRESS</code> and <code class="ph codeph">LIVE_SUMMARY</code> query
        options work in real time, see
        <a class="xref" href="https://asciinema.org/a/1rv7qippo0fe7h5k1b6k4nexk" target="_blank">this
          animated demo</a>.
      </p>

      <p class="p" id="common__comma_separated_values_blurb">
        Impala backend expects comma separated values to be in quotes when executing the
        <code class="ph codeph">SET</code> statement.
        This is usually the case when running SET statement like
        <code class="ph codeph">SET ENABLED_RUNTIME_FILTER_TYPES="value1,value2"</code> using a JDBC
        driver. When using Impala-shell client, the <code class="ph codeph">SET</code> statement is not
        executed immediately but query options are updated in the client and applied as
        part of the following statement, so no quotes are required for Impala-shell. That
        is, we use SET statement like
        <code class="ph codeph">SET ENABLED_RUNTIME_FILTER_TYPES=value1,value2</code> when
        submitting the query to Impala backend via Impala-shell client.
      </p>

      <p class="p" id="common__runtime_filter_mode_blurb">
        Because the runtime filtering feature is
        enabled by default only for local processing, the other filtering-related query options have
        the greatest effect when used in combination with the setting
          <code class="ph codeph">RUNTIME_FILTER_MODE=GLOBAL</code>. 
      </p>

      <div class="note note note_note" id="common__square_bracket_hint_caveat"><span class="note__title notetitle">Note:</span> 
        The square bracket style of hint is now deprecated and might be removed in a future
        release. For that reason, any newly added hints are not available with the square
        bracket syntax.
      </div>

      <p class="p" id="common__runtime_filtering_option_caveat">
        Because the runtime filtering feature applies mainly to resource-intensive and
        long-running queries, only adjust this query option when tuning long-running queries
        involving some combination of large partitioned tables and joins involving large tables.
      </p>

      <p class="p" id="common__impala_shell_progress_reports_compute_stats_caveat">
        The <code class="ph codeph">LIVE_PROGRESS</code> and <code class="ph codeph">LIVE_SUMMARY</code> query options
        currently do not produce any output during <code class="ph codeph">COMPUTE STATS</code> operations.
      </p>



      <p class="p" id="common__impala_shell_progress_reports_shell_only_blurb">
        The <code class="ph codeph">LIVE_PROGRESS</code> and <code class="ph codeph">LIVE_SUMMARY</code> query options only
        apply inside the <span class="keyword cmdname">impala-shell</span> interpreter. You cannot use them with
        the <code class="ph codeph">SET</code> statement from a JDBC or ODBC application.
      </p>

      <div class="p" id="common__impala_shell_progress_reports_shell_only_caveat">
        Because the <code class="ph codeph">LIVE_PROGRESS</code> and <code class="ph codeph">LIVE_SUMMARY</code> query
        options are available only within the <span class="keyword cmdname">impala-shell</span> interpreter:
        <ul class="ul">
          <li class="li">
            <p class="p">
              You cannot change these query options through the SQL <code class="ph codeph">SET</code>
              statement using the JDBC or ODBC interfaces. The <code class="ph codeph">SET</code> command in
              <span class="keyword cmdname">impala-shell</span> recognizes these names as shell-only options.
            </p>
          </li>

          <li class="li">
            <p class="p">
              Be careful when using <span class="keyword cmdname">impala-shell</span> on a
              pre-<span class="keyword">Impala 2.3</span> system to connect to a system running
              <span class="keyword">Impala 2.3</span> or higher. The older <span class="keyword cmdname">impala-shell</span>
              does not recognize these query option names. Upgrade
              <span class="keyword cmdname">impala-shell</span> on the systems where you intend to use these query
              options.
            </p>
          </li>

          <li class="li">
            <p class="p">
              Likewise, the <span class="keyword cmdname">impala-shell</span> command relies on some information
              only available in <span class="keyword">Impala 2.3</span> and higher to prepare live
              progress reports and query summaries. The <code class="ph codeph">LIVE_PROGRESS</code> and
              <code class="ph codeph">LIVE_SUMMARY</code> query options have no effect when
              <span class="keyword cmdname">impala-shell</span> connects to a cluster running an older version of
              Impala.
            </p>
          </li>
        </ul>
      </div>



<pre class="pre codeblock" id="common__create_drop_db_example"><code>create database first_db;
use first_db;
create table t1 (x int);

create database second_db;
use second_db;
-- Each database has its own namespace for tables.
-- You can reuse the same table names in each database.
create table t1 (s string);

create database temp;

-- You can either USE a database after creating it,
-- or qualify all references to the table name with the name of the database.
-- Here, tables T2 and T3 are both created in the TEMP database.

create table temp.t2 (x int, y int);
use database temp;
create table t3 (s string);

-- You cannot drop a database while it is selected by the USE statement.
drop database temp;
<em class="ph i">ERROR: AnalysisException: Cannot drop current default database: temp</em>

-- The always-available database 'default' is a convenient one to USE
-- before dropping a database you created.
use default;

-- Before dropping a database, first drop all the tables inside it,
<span class="ph">-- or in <span class="keyword">Impala 2.3</span> and higher use the CASCADE clause.</span>
drop database temp;
ERROR: ImpalaRuntimeException: Error making 'dropDatabase' RPC to Hive Metastore:
CAUSED BY: InvalidOperationException: Database temp is not empty
show tables in temp;
+------+
| name |
+------+
| t3   |
+------+

<span class="ph">-- <span class="keyword">Impala 2.3</span> and higher:</span>
<span class="ph">drop database temp cascade;</span>

-- Earlier releases:
drop table temp.t3;
drop database temp;
</code></pre>

      <p class="p" id="common__cast_convenience_fn_example">
        This example shows how to use the <code class="ph codeph">castto*()</code> functions as an equivalent
        to <code class="ph codeph">CAST(<var class="keyword varname">value</var> AS <var class="keyword varname">type</var>)</code>
        expressions.
      </p>

      <p class="p" id="common__cast_convenience_fn_usage">
        <strong class="ph b">Usage notes:</strong> A convenience function to skip the SQL <code class="ph codeph">CAST
        <var class="keyword varname">value</var> AS <var class="keyword varname">type</var></code> syntax, for example when
        programmatically generating SQL statements where a regular function call might be easier
        to construct.
      </p>

      <p class="p" id="common__current_timezone_tip">
        To determine the time zone of the server you are connected to, in
        <span class="keyword">Impala 2.3</span> and higher you can call the
        <code class="ph codeph">timeofday()</code> function, which includes the time zone specifier in its
        return value. Remember that with cloud computing, the server you interact with might be
        in a different time zone than you are, or different sessions might connect to servers in
        different time zones, or a cluster might include servers in more than one time zone.
      </p>

      <p class="p" id="common__timezone_conversion_caveat">
        The way this function deals with time zones when converting to or from
        <code class="ph codeph">TIMESTAMP</code> values is affected by the
        <code class="ph codeph">‑‑use_local_tz_for_unix_timestamp_conversions</code> startup flag
        for the <span class="keyword cmdname">impalad</span> daemon. See
        <a class="xref" href="../topics/impala_timestamp.html#timestamp">TIMESTAMP Data Type</a> for details about how
        Impala handles time zone considerations for the <code class="ph codeph">TIMESTAMP</code> data type.
      </p>

      <div class="p" id="common__s3_drop_table_purge"> For best
        compatibility with the S3 write support in <span class="keyword">Impala 2.6</span> and higher: <ul class="ul">
          <li class="li"> Use native Hadoop techniques to create data files in S3 for
            querying through Impala. </li>
          <li class="li"> Use the <code class="ph codeph">PURGE</code> clause of <code class="ph codeph">DROP
              TABLE</code> when dropping internal (managed) tables. </li>
        </ul> By default, when you drop an internal (managed) table, the data
        files are moved to the HDFS trashcan. This operation is expensive for
        tables that reside on the Amazon S3 object store. Therefore, for S3
        tables, prefer to use <code class="ph codeph">DROP TABLE <var class="keyword varname">table_name</var>
          PURGE</code> rather than the default <code class="ph codeph">DROP TABLE</code>
        statement. The <code class="ph codeph">PURGE</code> clause makes Impala delete the
        data files immediately, skipping the HDFS trashcan. For the
          <code class="ph codeph">PURGE</code> clause to work effectively, you must originally
        create the data files on S3 using one of the tools from the Hadoop
        ecosystem, such as <code class="ph codeph">hadoop fs -cp</code>, or
          <code class="ph codeph">INSERT</code> in Impala or Hive. </div>

      <p class="p" id="common__filter_option_bloom_only">
        This query option affects only Bloom filters, not the min/max filters that are applied
        to Kudu tables. Therefore, it does not affect the performance of queries against Kudu
        tables.
      </p>

      <p class="p" id="common__s3_dml_performance"> Because of differences
        between S3 and traditional filesystems, DML operations for S3 tables can
        take longer than for tables on HDFS. For example, both the <code class="ph codeph">LOAD
          DATA</code> statement and the final stage of the
          <code class="ph codeph">INSERT</code> and <code class="ph codeph">CREATE TABLE AS SELECT</code>
        statements involve moving files from one directory to another. (In the
        case of <code class="ph codeph">INSERT</code> and <code class="ph codeph">CREATE TABLE AS
          SELECT</code>, the files are moved from a temporary staging
        directory to the final destination directory.) Because S3 does not
        support a <span class="q">"rename"</span> operation for existing objects, in these cases
        Impala actually copies the data files from one location to another and
        then removes the original files. In <span class="keyword">Impala 2.6</span>,
        the <code class="ph codeph">S3_SKIP_INSERT_STAGING</code> query option provides a way
        to speed up <code class="ph codeph">INSERT</code> statements for S3 tables and
        partitions, with the tradeoff that a problem during statement execution
        could leave data in an inconsistent state. It does not apply to
          <code class="ph codeph">INSERT OVERWRITE</code> or <code class="ph codeph">LOAD DATA</code>
        statements. See <a class="xref" href="../topics/impala_s3_skip_insert_staging.html#s3_skip_insert_staging">S3_SKIP_INSERT_STAGING Query Option</a> for details. </p>

      <p class="p" id="common__adls_block_splitting">
        Because ADLS does not expose the block sizes of data files the way HDFS does, any Impala
        <code class="ph codeph">INSERT</code> or <code class="ph codeph">CREATE TABLE AS SELECT</code> statements use the
        <code class="ph codeph">PARQUET_FILE_SIZE</code> query option setting to define the size of Parquet
        data files. (Using a large block size is more important for Parquet tables than for
        tables that use other file formats.)
      </p>

      <p class="p" id="common__s3_block_splitting">
        In <span class="keyword">Impala 2.6</span> and higher, Impala queries are optimized for files
        stored in Amazon S3. For Impala tables that use the file formats Parquet, ORC, RCFile,
        SequenceFile, Avro, and uncompressed text, the setting
        <code class="ph codeph">fs.s3a.block.size</code> in the <span class="ph filepath">core-site.xml</span>
        configuration file determines how Impala divides the I/O work of reading the data files.
        This configuration setting is specified in bytes. By default, this value is 33554432 (32
        MB), meaning that Impala parallelizes S3 read operations on the files as if they were
        made up of 32 MB blocks. For example, if your S3 queries primarily access Parquet files
        written by MapReduce or Hive, increase <code class="ph codeph">fs.s3a.block.size</code> to 134217728
        (128 MB) to match the row group size of those files. If most S3 queries involve Parquet
        files written by Impala, increase <code class="ph codeph">fs.s3a.block.size</code> to 268435456 (256
        MB) to match the row group size produced by Impala.
      </p>

      <div class="note important note_important" id="common__s3_production"><span class="note__title importanttitle">Important:</span> 
        <p class="p">
          In <span class="keyword">Impala 2.6</span> and higher, Impala supports both queries
          (<code class="ph codeph">SELECT</code>) and DML (<code class="ph codeph">INSERT</code>, <code class="ph codeph">LOAD
          DATA</code>, <code class="ph codeph">CREATE TABLE AS SELECT</code>) for data residing on Amazon
          S3. With the inclusion of write support,

          the Impala support for S3 is now considered ready for production use.
        </p>
      </div>

      <div class="note important note_important" id="common__s3_caveat"><span class="note__title importanttitle">Important:</span> 
        <p class="p">
          Impala query support for Amazon S3 is included in <span class="keyword">Impala 2.2</span>,
          but is not supported or recommended for production use in this version.
        </p>
      </div>

      <p class="p" id="common__s3_ddl">
        In <span class="keyword">Impala 2.6</span> and higher, Impala DDL statements such as
        <code class="ph codeph">CREATE DATABASE</code>, <code class="ph codeph">CREATE TABLE</code>, <code class="ph codeph">DROP DATABASE
        CASCADE</code>, <code class="ph codeph">DROP TABLE</code>, and <code class="ph codeph">ALTER TABLE [ADD|DROP]
        PARTITION</code> can create or remove folders as needed in the Amazon S3 system. Prior
        to <span class="keyword">Impala 2.6</span>, you had to create folders yourself and point
        Impala database, tables, or partitions at them, and manually remove folders when no
        longer needed. See <a class="xref" href="../topics/impala_s3.html#s3">Using Impala with Amazon S3 Object Store</a> for details about reading
        and writing S3 data with Impala.
      </p>

      <p class="p" id="common__adls_dml">
        In <span class="keyword">Impala 2.9</span> and higher, the Impala DML statements
        (<code class="ph codeph">INSERT</code>, <code class="ph codeph">LOAD DATA</code>, and <code class="ph codeph">CREATE TABLE AS
        SELECT</code>) can write data into a table or partition that resides in the Azure Data
        Lake Store (ADLS). ADLS Gen2 is supported in <span class="keyword">Impala 3.1</span> and higher.
      </p>

      <p class="p">
        In the<code class="ph codeph">CREATE TABLE</code> or <code class="ph codeph">ALTER TABLE</code> statements, specify
        the ADLS location for tables and partitions with the <code class="ph codeph">adl://</code> prefix for
        ADLS Gen1 and <code class="ph codeph">abfs://</code> or <code class="ph codeph">abfss://</code> for ADLS Gen2 in the
        <code class="ph codeph">LOCATION</code> attribute.
      </p>

      <p class="p" id="common__adls_dml_end">
        If you bring data into ADLS using the normal ADLS transfer mechanisms instead of Impala
        DML statements, issue a <code class="ph codeph">REFRESH</code> statement for the table before using
        Impala to query the ADLS data.
      </p>

      <p class="p" id="common__s3_dml"> In <span class="keyword">Impala 2.6</span> and higher, the Impala DML statements (<code class="ph codeph">INSERT</code>,
          <code class="ph codeph">LOAD DATA</code>, and <code class="ph codeph">CREATE TABLE AS
          SELECT</code>) can write data into a table or partition that resides
        in S3. The syntax of the DML statements is the same as for any other
        tables, because the S3 location for tables and partitions is specified
        by an <code class="ph codeph">s3a://</code> prefix in the <code class="ph codeph">LOCATION</code>
        attribute of <code class="ph codeph">CREATE TABLE</code> or <code class="ph codeph">ALTER
          TABLE</code> statements. If you bring data into S3 using the normal
        S3 transfer mechanisms instead of Impala DML statements, issue a
          <code class="ph codeph">REFRESH</code> statement for the table before using Impala
        to query the S3 data. </p>

      <p class="p" id="common__s3_metadata">
        Impala caches metadata for tables where the data resides in the Amazon Simple Storage
        Service (S3), and the <code class="ph codeph">REFRESH</code> and <code class="ph codeph">INVALIDATE METADATA</code>
        statements are supported for the S3 tables. In particular, issue a
        <code class="ph codeph">REFRESH</code> for a table after adding or removing files in the associated S3
        data directory. See <a class="xref" href="../topics/impala_s3.html#s3">Using Impala with Amazon S3 Object Store</a> for details
        about working with S3 tables.
      </p>

      <p class="p" id="common__y2k38">
        In Impala 2.2.0 and higher, built-in functions that accept or return integers
        representing <code class="ph codeph">TIMESTAMP</code> values use the <code class="ph codeph">BIGINT</code> type for
        parameters and return values, rather than <code class="ph codeph">INT</code>. This change lets the
        date and time functions avoid an overflow error that would otherwise occur on January
        19th, 2038 (known as the
        <a class="xref" href="http://en.wikipedia.org/wiki/Year_2038_problem" target="_blank"><span class="q">"Year
        2038 problem"</span> or <span class="q">"Y2K38 problem"</span></a>). This change affects the
        <code class="ph codeph">FROM_UNIXTIME()</code> and <code class="ph codeph">UNIX_TIMESTAMP()</code> functions. You
        might need to change application code that interacts with these functions, change the
        types of columns that store the return values, or add <code class="ph codeph">CAST()</code> calls to
        SQL statements that call these functions.
      </p>

      <p class="p" id="common__timestamp_conversions">
        Impala automatically converts <code class="ph codeph">STRING</code> literals of the correct format
        into <code class="ph codeph">TIMESTAMP</code> values. Timestamp values are accepted in the format
        <code class="ph codeph">'yyyy‑MM‑dd&nbsp;HH:mm:ss.SSSSSS'</code>, and can consist of just the date, or
        just the time, with or without the fractional second portion. For example, you can
        specify <code class="ph codeph">TIMESTAMP</code> values such as <code class="ph codeph">'1966‑07‑30'</code>,
        <code class="ph codeph">'08:30:00'</code>, or <code class="ph codeph">'1985‑09‑25&nbsp;17:45:30.005'</code>.
      </p>

      <p class="p">
        Leading zeroes are not required in the numbers representing the date component, such as
        month and date, or the time component, such as hour, minute, and second. For example,
        Impala accepts both <code class="ph codeph">'2018‑1‑1&nbsp;01:02:03'</code> and
        <code class="ph codeph">'2018‑01‑01&nbsp;1:2:3'</code> as valid.
      </p>

      <p class="p">
        In <code class="ph codeph">STRING</code> to <code class="ph codeph">TIMESTAMP</code> conversions, leading and
        trailing white spaces, such as a space, a tab, a newline, or a carriage return, are
        ignored. For example, Impala treats the following as equivalent:
        '1999‑12‑01&nbsp;01:02:03 ', '&nbsp;1999‑12‑01&nbsp;01:02:03',
        '1999‑12‑01&nbsp;01:02:03\r\n\t'.
      </p>

      <div class="p" id="common__cast_string_to_timestamp">
        When you convert or cast a <code class="ph codeph">STRING</code> literal to
        <code class="ph codeph">TIMESTAMP</code>, you can use the following separators between the date part
        and the time part:
        <ul class="ul">
          <li class="li">
            <p class="p">
              One or more space characters
            </p>

            <p class="p">
              Example: <code class="ph codeph">CAST('2001-01-09&nbsp;01:05:01' AS TIMESTAMP)</code>
            </p>
          </li>

          <li class="li">
            <p class="p">
              The character “T”
            </p>

            <p class="p">
              Example: <code class="ph codeph">CAST('2001-01-09T01:05:01' AS TIMESTAMP)</code>
            </p>
          </li>
        </ul>
      </div>

      <p class="p">
        <span class="ph" id="common__cast_int_to_timestamp"> Casting an integer or floating-point value
        <code class="ph codeph">N</code> to <code class="ph codeph">TIMESTAMP</code> produces a value that is
        <code class="ph codeph">N</code> seconds past the start of the epoch date (January 1, 1970). By
        default, the result value represents a date and time in the UTC time zone. If the
        setting <code class="ph codeph">‑‑use_local_tz_for_unix_timestamp_conversions=true</code>
        is in effect, the resulting <code class="ph codeph">TIMESTAMP</code> represents a date and time in the
        local time zone. </span>
      </p>

      <p class="p" id="common__redaction_yes">
        If these statements in your environment contain sensitive literal values such as credit
        card numbers or tax identifiers, Impala can redact this sensitive information when
        displaying the statements in log files and other administrative contexts. See
        <span class="xref">the documentation for your Apache Hadoop distribution</span> for details.
      </p>

      <p class="p" id="common__cs_or_cis">
        For a particular table, use either <code class="ph codeph">COMPUTE STATS</code> or <code class="ph codeph">COMPUTE
        INCREMENTAL STATS</code>, but never combine the two or alternate between them. If you
        switch from <code class="ph codeph">COMPUTE STATS</code> to <code class="ph codeph">COMPUTE INCREMENTAL STATS</code>
        during the lifetime of a table, or vice versa, drop all statistics by running
        <code class="ph codeph">DROP STATS</code> before making the switch.
      </p>

      <p class="p" id="common__incremental_stats_after_full">
        When you run <code class="ph codeph">COMPUTE INCREMENTAL STATS</code> on a table for the first time,
        the statistics are computed again from scratch regardless of whether the table already
        has statistics. Therefore, expect a one-time resource-intensive operation for scanning
        the entire table when running <code class="ph codeph">COMPUTE INCREMENTAL STATS</code> for the first
        time on a given table.
      </p>

      <p class="p" id="common__incremental_stats_caveats">
        In Impala 3.0 and lower, approximately 400 bytes of metadata per column per partition
        are needed for caching. Tables with a big number of partitions and many columns can add
        up to a significant memory overhead as the metadata must be cached on the
        <span class="keyword cmdname">catalogd</span> host and on every <span class="keyword cmdname">impalad</span> host that is
        eligible to be a coordinator. If this metadata for all tables exceeds 2 GB, you might
        experience service downtime. In Impala 3.1 and higher, the issue was alleviated with an
        improved handling of incremental stats.
      </p>

      <p class="p" id="common__incremental_partition_spec">
        The <code class="ph codeph">PARTITION</code> clause is only allowed in combination with the
        <code class="ph codeph">INCREMENTAL</code> clause. It is optional for <code class="ph codeph">COMPUTE INCREMENTAL
        STATS</code>, and required for <code class="ph codeph">DROP INCREMENTAL STATS</code>. Whenever you
        specify partitions through the <code class="ph codeph">PARTITION
        (<var class="keyword varname">partition_spec</var>)</code> clause in a <code class="ph codeph">COMPUTE INCREMENTAL
        STATS</code> or <code class="ph codeph">DROP INCREMENTAL STATS</code> statement, you must include
        all the partitioning columns in the specification, and specify constant values for all
        the partition key columns.
      </p>

<pre class="pre codeblock" id="common__compute_stats_walkthrough"><code>-- Initially the table has no incremental stats, as indicated
-- 'false' under Incremental stats.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | -1    | 1      | 223.74KB | NOT CACHED   | PARQUET | false
| Children    | -1    | 1      | 230.05KB | NOT CACHED   | PARQUET | false
| Electronics | -1    | 1      | 232.67KB | NOT CACHED   | PARQUET | false
| Home        | -1    | 1      | 232.56KB | NOT CACHED   | PARQUET | false
| Jewelry     | -1    | 1      | 223.72KB | NOT CACHED   | PARQUET | false
| Men         | -1    | 1      | 231.25KB | NOT CACHED   | PARQUET | false
| Music       | -1    | 1      | 237.90KB | NOT CACHED   | PARQUET | false
| Shoes       | -1    | 1      | 234.90KB | NOT CACHED   | PARQUET | false
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | -1    | 1      | 226.27KB | NOT CACHED   | PARQUET | false
| Total       | -1    | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------

-- After the first COMPUTE INCREMENTAL STATS,
-- all partitions have stats. The first
-- COMPUTE INCREMENTAL STATS scans the whole
-- table, discarding any previous stats from
-- a traditional COMPUTE STATS statement.
compute incremental stats item_partitioned;
+-------------------------------------------+
| summary                                   |
+-------------------------------------------+
| Updated 10 partition(s) and 21 column(s). |
+-------------------------------------------+
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 10     | 2.25MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------

-- Add a new partition...
alter table item_partitioned add partition (i_category='Camping');
-- Add or replace files in HDFS outside of Impala,
-- rendering the stats for a partition obsolete.
!import_data_into_sports_partition.sh
refresh item_partitioned;
drop incremental stats item_partitioned partition (i_category='Sports');
-- Now some partitions have incremental stats
-- and some do not.
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Camping     | -1    | 1      | 408.02KB | NOT CACHED   | PARQUET | false
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | -1    | 1      | 227.97KB | NOT CACHED   | PARQUET | false
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 11     | 2.65MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------

-- After another COMPUTE INCREMENTAL STATS,
-- all partitions have incremental stats, and only the 2
-- partitions without incremental stats were scanned.
compute incremental stats item_partitioned;
+------------------------------------------+
| summary                                  |
+------------------------------------------+
| Updated 2 partition(s) and 21 column(s). |
+------------------------------------------+
show table stats item_partitioned;
+-------------+-------+--------+----------+--------------+---------+------------------
| i_category  | #Rows | #Files | Size     | Bytes Cached | Format  | Incremental stats
+-------------+-------+--------+----------+--------------+---------+------------------
| Books       | 1733  | 1      | 223.74KB | NOT CACHED   | PARQUET | true
| Camping     | 5328  | 1      | 408.02KB | NOT CACHED   | PARQUET | true
| Children    | 1786  | 1      | 230.05KB | NOT CACHED   | PARQUET | true
| Electronics | 1812  | 1      | 232.67KB | NOT CACHED   | PARQUET | true
| Home        | 1807  | 1      | 232.56KB | NOT CACHED   | PARQUET | true
| Jewelry     | 1740  | 1      | 223.72KB | NOT CACHED   | PARQUET | true
| Men         | 1811  | 1      | 231.25KB | NOT CACHED   | PARQUET | true
| Music       | 1860  | 1      | 237.90KB | NOT CACHED   | PARQUET | true
| Shoes       | 1835  | 1      | 234.90KB | NOT CACHED   | PARQUET | true
| Sports      | 1783  | 1      | 227.97KB | NOT CACHED   | PARQUET | true
| Women       | 1790  | 1      | 226.27KB | NOT CACHED   | PARQUET | true
| Total       | 17957 | 11     | 2.65MB   | 0B           |         |
+-------------+-------+--------+----------+--------------+---------+------------------
</code></pre>

      <p class="p" id="common__udf_persistence_restriction">
        In <span class="keyword">Impala 2.5</span> and higher, Impala UDFs and UDAs written in C++ are
        persisted in the metastore database. Java UDFs are also persisted, if they were created
        with the new <code class="ph codeph">CREATE FUNCTION</code> syntax for Java UDFs, where the Java
        function argument and return types are omitted. Java-based UDFs created with the old
        <code class="ph codeph">CREATE FUNCTION</code> syntax do not persist across restarts because they are
        held in the memory of the <span class="keyword cmdname">catalogd</span> daemon. Until you re-create such
        Java UDFs using the new <code class="ph codeph">CREATE FUNCTION</code> syntax, you must reload those
        Java-based UDFs by running the original <code class="ph codeph">CREATE FUNCTION</code> statements
        again each time you restart the <span class="keyword cmdname">catalogd</span> daemon. Prior to
        <span class="keyword">Impala 2.5</span> the requirement to reload functions after a restart
        applied to both C++ and Java functions.
      </p>

      <div class="p" id="common__refresh_functions_tip">
        In <span class="keyword">Impala 2.9</span> and higher, you can refresh the user-defined
        functions (UDFs) that Impala recognizes, at the database level, by running the
        <code class="ph codeph">REFRESH FUNCTIONS</code> statement with the database name as an argument.
        Java-based UDFs can be added to the metastore database through Hive <code class="ph codeph">CREATE
        FUNCTION</code> statements, and made visible to Impala by subsequently running
        <code class="ph codeph">REFRESH FUNCTIONS</code>. For example:
<pre class="pre codeblock"><code>CREATE DATABASE shared_udfs;
USE shared_udfs;
...use CREATE FUNCTION statements in Hive to create some Java-based UDFs
   that Impala is not initially aware of...
REFRESH FUNCTIONS shared_udfs;
SELECT udf_created_by_hive(c1) FROM ...
</code></pre>
      </div>

      <p class="p" id="common__current_user_caveat">
        The Hive <code class="ph codeph">current_user()</code> function cannot be called from a Java UDF
        through Impala.
      </p>

      <div class="note note note_note" id="common__add_partition_set_location"><span class="note__title notetitle">Note:</span> 
        If you are creating a partition for the first time and specifying its location, for
        maximum efficiency, use a single <code class="ph codeph">ALTER TABLE</code> statement including both
        the <code class="ph codeph">ADD PARTITION</code> and <code class="ph codeph">LOCATION</code> clauses, rather than
        separate statements with <code class="ph codeph">ADD PARTITION</code> and <code class="ph codeph">SET
        LOCATION</code> clauses.
      </div>

      <p class="p" id="common__insert_hidden_work_directory">
        The <code class="ph codeph">INSERT</code> statement has always left behind a hidden work directory
        inside the data directory of the table. Formerly, this hidden work directory was named
        <span class="ph filepath">.impala_insert_staging</span> . In Impala 2.0.1 and later, this directory
        name is changed to <span class="ph filepath">_impala_insert_staging</span> . (While HDFS tools are
        expected to treat names beginning either with underscore and dot as hidden, in practice
        names beginning with an underscore are more widely supported.) If you have any scripts,
        cleanup jobs, and so on that rely on the name of this work directory, adjust them to use
        the new name.
      </p>

      <p class="p" id="common__check_internal_external_table">
        To see whether a table is internal or external, and its associated HDFS location, issue
        the statement <code class="ph codeph">DESCRIBE FORMATTED <var class="keyword varname">table_name</var></code>. The
        <code class="ph codeph">Table Type</code> field displays <code class="ph codeph">MANAGED_TABLE</code> for internal
        tables and <code class="ph codeph">EXTERNAL_TABLE</code> for external tables. The
        <code class="ph codeph">Location</code> field displays the path of the table directory as an HDFS URI.
      </p>

      <div class="p" id="common__switch_internal_external_table"> You can switch a table from
        internal to external, or from external to internal, by using the
          <code class="ph codeph">ALTER TABLE</code> statement:
        <pre class="pre codeblock"><code>
-- Switch a table from internal to external.
ALTER TABLE <var class="keyword varname">table_name</var> SET TBLPROPERTIES('EXTERNAL'='TRUE');

-- Switch a table from external to internal.
ALTER TABLE <var class="keyword varname">table_name</var> SET TBLPROPERTIES('EXTERNAL'='FALSE');
</code></pre>If
        the Kudu service is integrated with the Hive Metastore, the above
        operations are not supported.</div>



<pre class="pre codeblock" id="common__regexp_rlike_examples"><code>-- Find all customers whose first name starts with 'J', followed by 0 or more of any character.
select c_first_name, c_last_name from customer where c_first_name regexp '^J.*';
select c_first_name, c_last_name from customer where c_first_name rlike '^J.*';

-- Find 'Macdonald', where the first 'a' is optional and the 'D' can be upper- or lowercase.
-- The ^...$ are required, to match the start and end of the value.
select c_first_name, c_last_name from customer where c_last_name regexp '^Ma?c[Dd]onald$';
select c_first_name, c_last_name from customer where c_last_name rlike '^Ma?c[Dd]onald$';

-- Match multiple character sequences, either 'Mac' or 'Mc'.
select c_first_name, c_last_name from customer where c_last_name regexp '^(Mac|Mc)donald$';
select c_first_name, c_last_name from customer where c_last_name rlike '^(Mac|Mc)donald$';

-- Find names starting with 'S', then one or more vowels, then 'r', then any other characters.
-- Matches 'Searcy', 'Sorenson', 'Sauer'.
select c_first_name, c_last_name from customer where c_last_name regexp '^S[aeiou]+r.*$';
select c_first_name, c_last_name from customer where c_last_name rlike '^S[aeiou]+r.*$';

-- Find names that end with 2 or more vowels: letters from the set a,e,i,o,u.
select c_first_name, c_last_name from customer where c_last_name regexp '.*[aeiou]{2,}$';
select c_first_name, c_last_name from customer where c_last_name rlike '.*[aeiou]{2,}$';

-- You can use letter ranges in the [] blocks, for example to find names starting with A, B, or C.
select c_first_name, c_last_name from customer where c_last_name regexp '^[A-C].*';
select c_first_name, c_last_name from customer where c_last_name rlike '^[A-C].*';

-- If you are not sure about case, leading/trailing spaces, and so on, you can process the
-- column using string functions first.
select c_first_name, c_last_name from customer where lower(trim(c_last_name)) regexp '^de.*';
select c_first_name, c_last_name from customer where lower(trim(c_last_name)) rlike '^de.*';
</code></pre>

      <p class="p" id="common__case_insensitive_comparisons_tip">
        In <span class="keyword">Impala 2.5</span> and higher, you can simplify queries that use many
        <code class="ph codeph">UPPER()</code> and <code class="ph codeph">LOWER()</code> calls to do case-insensitive
        comparisons, by using the <code class="ph codeph">ILIKE</code> or <code class="ph codeph">IREGEXP</code> operators
        instead. See <a class="xref" href="../topics/impala_operators.html#ilike">ILIKE Operator</a> and
        <a class="xref" href="../topics/impala_operators.html#iregexp">IREGEXP Operator</a> for details.
      </p>

      <p class="p" id="common__show_security">
        When authorization is enabled, the output of the <code class="ph codeph">SHOW</code> statement only
        shows those objects for which you have the privilege to view. If you believe an object
        exists but you cannot see it in the <code class="ph codeph">SHOW</code> output, check with the system
        administrator if you need to be granted a new privilege for that object. See
        <a class="xref" href="../topics/impala_authorization.html#authorization">Impala Authorization</a> for how to set up
        authorization and add privileges for specific objects.
      </p>

      <p class="p" id="common__infinity_and_nan">
        Infinity and NaN can be specified in text data files as <code class="ph codeph">inf</code> and
        <code class="ph codeph">nan</code> respectively, and Impala interprets them as these special values.
        They can also be produced by certain arithmetic expressions; for example,
        <code class="ph codeph">1/0</code> returns <code class="ph codeph">Infinity</code> and <code class="ph codeph">pow(-1, 0.5)</code>
        returns <code class="ph codeph">NaN</code>. Or you can cast the literal values, such as
        <code class="ph codeph">CAST('nan' AS DOUBLE)</code> or <code class="ph codeph">CAST('inf' AS DOUBLE)</code>.
      </p>

      <p class="p" id="common__user_kerberized">
        In Impala 2.0 and later, <code class="ph codeph">user()</code> returns the full Kerberos principal
        string, such as <code class="ph codeph">user@example.com</code>, in a Kerberized environment.
      </p>

      <div class="p" id="common__vm_overcommit_memory_intro">
        On a kerberized cluster with high memory utilization, <span class="keyword cmdname">kinit</span> commands
        executed after every <code class="ph codeph">'kerberos_reinit_interval'</code> may cause out-of-memory
        errors, because executing the command involves a fork of the Impala process. The error
        looks similar to the following:
<pre class="pre codeblock"><code>
Failed to obtain Kerberos ticket for principal: &lt;varname&gt;principal_details&lt;/varname&gt;
Failed to execute shell cmd: 'kinit -k -t &lt;varname&gt;keytab_details&lt;/varname&gt;',
error was: Error(12): Cannot allocate memory

</code></pre>
      </div>

      <div class="p" id="common__vm_overcommit_memory_start">
        The following command changes the <code class="ph codeph">vm.overcommit_memory</code> setting
        immediately on a running host. However, this setting is reset when the host is
        restarted.
<pre class="pre codeblock"><code>
echo 1 &gt; /proc/sys/vm/overcommit_memory

</code></pre>
      </div>

      <div class="p">
        To change the setting in a persistent way, add the following line to the
        <span class="ph filepath">/etc/sysctl.conf</span> file:
<pre class="pre codeblock"><code>
vm.overcommit_memory=1

</code></pre>
      </div>

      <p class="p" id="common__vm_overcommit_memory_end">
        Then run <code class="ph codeph">sysctl -p</code>. No reboot is needed.
      </p>

      <ul class="ul">
        <li class="li" id="common__grant_revoke_single">
          Currently, each Impala <code class="ph codeph">GRANT</code> or <code class="ph codeph">REVOKE</code> statement can
          only grant or revoke a single privilege to or from a single role.
        </li>
      </ul>

      <p class="p" id="common__blobs_are_strings">
        All data in <code class="ph codeph">CHAR</code> and <code class="ph codeph">VARCHAR</code> columns must be in a
        character encoding that is compatible with UTF-8. If you have binary data from another
        database system (that is, a BLOB type), use a <code class="ph codeph">STRING</code> column to hold it.
      </p>



      <div class="p" id="common__create_drop_view_examples">
        The following example creates a series of views and then drops them. These examples
        illustrate how views are associated with a particular database, and both the view
        definitions and the view names for <code class="ph codeph">CREATE VIEW</code> and <code class="ph codeph">DROP
        VIEW</code> can refer to a view in the current database or a fully qualified view
        name.
<pre class="pre codeblock"><code>
-- Create and drop a view in the current database.
CREATE VIEW few_rows_from_t1 AS SELECT * FROM t1 LIMIT 10;
DROP VIEW few_rows_from_t1;

-- Create and drop a view referencing a table in a different database.
CREATE VIEW table_from_other_db AS SELECT x FROM db1.foo WHERE x IS NOT NULL;
DROP VIEW table_from_other_db;

USE db1;
-- Create a view in a different database.
CREATE VIEW db2.v1 AS SELECT * FROM db2.foo;
-- Switch into the other database and drop the view.
USE db2;
DROP VIEW v1;

USE db1;
-- Create a view in a different database.
CREATE VIEW db2.v1 AS SELECT * FROM db2.foo;
-- Drop a view in the other database.
DROP VIEW db2.v1;
</code></pre>
      </div>

      <p class="p" id="common__char_varchar_cast_from_string">
        For <code class="ph codeph">INSERT</code> operations into <code class="ph codeph">CHAR</code> or
        <code class="ph codeph">VARCHAR</code> columns, you must cast all <code class="ph codeph">STRING</code> literals or
        expressions returning <code class="ph codeph">STRING</code> to to a <code class="ph codeph">CHAR</code> or
        <code class="ph codeph">VARCHAR</code> type with the appropriate length.
      </p>

      <div class="p" id="common__length_demo">
        The following example demonstrates how <code class="ph codeph">length()</code> and
        <code class="ph codeph">char_length()</code> sometimes produce the same result, and sometimes produce
        different results depending on the type of the argument and the presence of trailing
        spaces for <code class="ph codeph">CHAR</code> values. The <code class="ph codeph">S</code> and <code class="ph codeph">C</code>
        values are displayed with enclosing quotation marks to show any trailing spaces.
<pre class="pre codeblock" id="common__length_demo_example"><code>create table length_demo (s string, c char(5));
insert into length_demo values
  ('a',cast('a' as char(5))),
  ('abc',cast('abc' as char(5))),
  ('hello',cast('hello' as char(5)));

select concat('"',s,'"') as s, concat('"',c,'"') as c,
  length(s), length(c),
  char_length(s), char_length(c)
from length_demo;
+---------+---------+-----------+-----------+----------------+----------------+
| s       | c       | length(s) | length(c) | char_length(s) | char_length(c) |
+---------+---------+-----------+-----------+----------------+----------------+
| "a"     | "a    " | 1         | 1         | 1              | 5              |
| "abc"   | "abc  " | 3         | 3         | 3              | 5              |
| "hello" | "hello" | 5         | 5         | 5              | 5              |
+---------+---------+-----------+-----------+----------------+----------------+
</code></pre>
      </div>

      <p class="p" id="common__subquery_no_limit">
        Correlated subqueries used in <code class="ph codeph">EXISTS</code> and <code class="ph codeph">IN</code> operators
        cannot include a <code class="ph codeph">LIMIT</code> clause.
      </p>

      <p class="p" id="common__avro_no_timestamp">
        Currently, Avro tables cannot contain <code class="ph codeph">TIMESTAMP</code> columns. If you need to
        store date and time values in Avro tables, as a workaround you can use a
        <code class="ph codeph">STRING</code> representation of the values, convert the values to
        <code class="ph codeph">BIGINT</code> with the <code class="ph codeph">UNIX_TIMESTAMP()</code> function, or create
        separate numeric columns for individual date and time fields using the
        <code class="ph codeph">EXTRACT()</code> function.
      </p>

      <p class="p" id="common__zero_length_strings">
        <strong class="ph b">Zero-length strings:</strong> For purposes of clauses such as <code class="ph codeph">DISTINCT</code>
        and <code class="ph codeph">GROUP BY</code>, Impala considers zero-length strings
        (<code class="ph codeph">""</code>), <code class="ph codeph">NULL</code>, and space to all be different values.
      </p>

      <p class="p" id="common__spill_to_disk_vs_dynamic_partition_pruning">
        When the spill-to-disk feature is activated for a join node within a query, Impala does
        not produce any runtime filters for that join operation on that host. Other join nodes
        within the query are not affected.
      </p>

<pre class="pre codeblock" id="common__simple_dpp_example"><code>
CREATE TABLE yy (s STRING) PARTITIONED BY (year INT);
INSERT INTO yy PARTITION (year) VALUES ('1999', 1999), ('2000', 2000),
  ('2001', 2001), ('2010', 2010), ('2018', 2018);
COMPUTE STATS yy;

CREATE TABLE yy2 (s STRING, year INT);
INSERT INTO yy2 VALUES ('1999', 1999), ('2000', 2000), ('2001', 2001);
COMPUTE STATS yy2;

-- The following query reads an unknown number of partitions, whose key values
-- are only known at run time. The <strong class="ph b">runtime filters</strong> line shows the
-- information used in query fragment 02 to decide which partitions to skip.

EXPLAIN SELECT s FROM yy WHERE year IN (SELECT year FROM yy2);
+--------------------------------------------------------------------------+
| PLAN-ROOT SINK                                                           |
| |                                                                        |
| 04:EXCHANGE [UNPARTITIONED]                                              |
| |                                                                        |
| 02:HASH JOIN [LEFT SEMI JOIN, BROADCAST]                                 |
| |  hash predicates: year = year                                          |
| |  <strong class="ph b">runtime filters: RF000 &lt;- year</strong>                                   |
| |                                                                        |
| |--03:EXCHANGE [BROADCAST]                                               |
| |  |                                                                     |
| |  01:SCAN HDFS [default.yy2]                                            |
| |     partitions=1/1 files=1 size=620B                                   |
| |                                                                        |
| 00:SCAN HDFS [default.yy]                                                |
|    <strong class="ph b">partitions=5/5</strong> files=5 size=1.71KB                               |
|    runtime filters: RF000 -&gt; year                                        |
+--------------------------------------------------------------------------+

SELECT s FROM yy WHERE year IN (SELECT year FROM yy2); -- Returns 3 rows from yy
PROFILE;
</code></pre>

      <p class="p" id="common__order_by_scratch_dir"> By default, intermediate files used during
        large sort, join, aggregation, or analytic function operations are
        stored in the directory <span class="ph filepath">/tmp/impala-scratch</span>, and
        these intermediate files are removed when the operation finishes. You
        can specify a different location by starting the
          <span class="keyword cmdname">impalad</span> daemon with the
            <code class="ph codeph">‑‑scratch_dirs="<var class="keyword varname">path_to_directory</var>"</code>
        configuration option. </p>

      <div class="p" id="common__order_by_view_restriction">
        An <code class="ph codeph">ORDER BY</code> clause without an additional <code class="ph codeph">LIMIT</code> clause
        is ignored in any view definition. If you need to sort the entire result set from a
        view, use an <code class="ph codeph">ORDER BY</code> clause in the <code class="ph codeph">SELECT</code> statement
        that queries the view. You can still make a simple <span class="q">"top 10"</span> report by combining the
        <code class="ph codeph">ORDER BY</code> and <code class="ph codeph">LIMIT</code> clauses in the same view
        definition:
<pre class="pre codeblock"><code>[localhost:21000] &gt; create table unsorted (x bigint);
[localhost:21000] &gt; insert into unsorted values (1), (9), (3), (7), (5), (8), (4), (6), (2);
[localhost:21000] &gt; create view sorted_view as select x from unsorted order by x;
[localhost:21000] &gt; select x from sorted_view; -- ORDER BY clause in view has no effect.
+---+
| x |
+---+
| 1 |
| 9 |
| 3 |
| 7 |
| 5 |
| 8 |
| 4 |
| 6 |
| 2 |
+---+
[localhost:21000] &gt; select x from sorted_view order by x; -- View query requires ORDER BY at outermost level.
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
| 4 |
| 5 |
| 6 |
| 7 |
| 8 |
| 9 |
+---+
[localhost:21000] &gt; create view top_3_view as select x from unsorted order by x limit 3;
[localhost:21000] &gt; select x from top_3_view; -- ORDER BY and LIMIT together in view definition are preserved.
+---+
| x |
+---+
| 1 |
| 2 |
| 3 |
+---+
</code></pre>
      </div>

      <div class="p" id="common__precision_scale_example">
        The following examples demonstrate how to check the precision and scale of numeric
        literals or other numeric expressions. Impala represents numeric literals in the
        smallest appropriate type. 5 is a <code class="ph codeph">TINYINT</code> value, which ranges from -128
        to 127, therefore 3 decimal digits are needed to represent the entire range, and because
        it is an integer value there are no fractional digits. 1.333 is interpreted as a
        <code class="ph codeph">DECIMAL</code> value, with 4 digits total and 3 digits after the decimal
        point.
<pre class="pre codeblock"><code>[localhost:21000] &gt; select precision(5), scale(5);
+--------------+----------+
| precision(5) | scale(5) |
+--------------+----------+
| 3            | 0        |
+--------------+----------+
[localhost:21000] &gt; select precision(1.333), scale(1.333);
+------------------+--------------+
| precision(1.333) | scale(1.333) |
+------------------+--------------+
| 4                | 3            |
+------------------+--------------+
[localhost:21000] &gt; with t1 as
  ( select cast(12.34 as decimal(20,2)) x union select cast(1 as decimal(8,6)) x )
  select precision(x), scale(x) from t1 limit 1;
+--------------+----------+
| precision(x) | scale(x) |
+--------------+----------+
| 24           | 6        |
+--------------+----------+
</code></pre>
      </div>



      <p class="p" id="common__type_boolean">
        <strong class="ph b">Type:</strong> Boolean; recognized values are 1 and 0, or <code class="ph codeph">true</code> and
        <code class="ph codeph">false</code>; any other value interpreted as <code class="ph codeph">false</code>
      </p>

      <p class="p" id="common__type_string">
        <strong class="ph b">Type:</strong> string
      </p>

      <p class="p" id="common__type_integer">
        <strong class="ph b">Type:</strong> integer
      </p>

      <p class="p" id="common__type_double">
        <strong class="ph b">Type:</strong> double
      </p>

      <p class="p" id="common__default_blurb">
        <strong class="ph b">Default:</strong>
      </p>

      <p class="p" id="common__default_false">
        <strong class="ph b">Default:</strong> <code class="ph codeph">false</code>
      </p>

      <p class="p" id="common__default_0">
        <strong class="ph b">Default:</strong> <code class="ph codeph">0</code>
      </p>

      <p class="p" id="common__default_false_0">
        <strong class="ph b">Default:</strong> <code class="ph codeph">false</code> (shown as 0 in output of <code class="ph codeph">SET</code>
        statement)
      </p>

      <p class="p" id="common__default_true_1">
        <strong class="ph b">Default:</strong> <code class="ph codeph">true</code> (shown as 1 in output of <code class="ph codeph">SET</code>
        statement)
      </p>

      <p class="p" id="common__units_blurb">
        <strong class="ph b">Units:</strong> A numeric argument represents a size in bytes; you can also use a suffix
        of <code class="ph codeph">m</code> or <code class="ph codeph">mb</code> for megabytes, or <code class="ph codeph">g</code> or
        <code class="ph codeph">gb</code> for gigabytes. If you specify a value with unrecognized formats,
        subsequent queries fail with an error.
      </p>

      <p class="p" id="common__odd_return_type_string">
        Currently, the return value is always a <code class="ph codeph">STRING</code>. The return type is
        subject to change in future releases. Always use <code class="ph codeph">CAST()</code> to convert the
        result to whichever data type is appropriate for your computations.
      </p>

      <p class="p" id="common__former_odd_return_type_string">
        <strong class="ph b">Return type:</strong> <code class="ph codeph">DOUBLE</code> in Impala 2.0 and higher;
        <code class="ph codeph">STRING</code> in earlier releases
      </p>

      <p class="p" id="common__for_compatibility_only">
        <strong class="ph b">Usage notes:</strong> Primarily for compatibility with code containing industry extensions
        to SQL.
      </p>

      <p class="p" id="common__return_type_boolean">
        <strong class="ph b">Return type:</strong> <code class="ph codeph">BOOLEAN</code>
      </p>

      <p class="p" id="common__return_type_double">
        <strong class="ph b">Return type:</strong> <code class="ph codeph">DOUBLE</code>
      </p>

      <p class="p" id="common__return_type_same">
        <strong class="ph b">Return type:</strong> Same as the input value
      </p>

      <p class="p" id="common__return_type_same_except_string">
        <strong class="ph b">Return type:</strong> Same as the input value, except for <code class="ph codeph">CHAR</code> and
        <code class="ph codeph">VARCHAR</code> arguments which produce a <code class="ph codeph">STRING</code> result
      </p>

      <div class="p" id="common__builtins_db">
        Impala includes another predefined database, <code class="ph codeph">_impala_builtins</code>, that
        serves as the location for the
        <a class="xref" href="../topics/impala_functions.html#builtins">built-in functions</a>. To see
        the built-in functions, use a statement like the following:
<pre class="pre codeblock"><code>show functions in _impala_builtins;
show functions in _impala_builtins like '*<var class="keyword varname">substring</var>*';
</code></pre>
      </div>

      <p class="p" id="common__sum_double">
        Due to the way arithmetic on <code class="ph codeph">FLOAT</code> and <code class="ph codeph">DOUBLE</code> columns
        uses high-performance hardware instructions, and distributed queries can perform these
        operations in different order for each query, results can vary slightly for aggregate
        function calls such as <code class="ph codeph">SUM()</code> and <code class="ph codeph">AVG()</code> for
        <code class="ph codeph">FLOAT</code> and <code class="ph codeph">DOUBLE</code> columns, particularly on large data
        sets where millions or billions of values are summed or averaged. For perfect
        consistency and repeatability, use the <code class="ph codeph">DECIMAL</code> data type for such
        operations instead of <code class="ph codeph">FLOAT</code> or <code class="ph codeph">DOUBLE</code>.
      </p>

      <p class="p" id="common__float_double_decimal_caveat">
        The inability to exactly represent certain floating-point values means that
        <code class="ph codeph">DECIMAL</code> is sometimes a better choice than <code class="ph codeph">DOUBLE</code> or
        <code class="ph codeph">FLOAT</code> when precision is critical, particularly when transferring data
        from other database systems that use different representations or file formats.
      </p>

      <p class="p" id="common__hive_column_stats_caveat">
        If you run the Hive statement <code class="ph codeph">ANALYZE TABLE COMPUTE STATISTICS FOR
        COLUMNS</code>, Impala can only use the resulting column statistics if the table is
        unpartitioned. Impala cannot use Hive-generated column statistics for a partitioned
        table.
      </p>

      <div class="p" id="common__datetime_function_chaining">
        <code class="ph codeph">UNIX_TIMESTAMP()</code> and <code class="ph codeph">FROM_UNIXTIME()</code> are often used in
        combination to convert a <code class="ph codeph">TIMESTAMP</code> value into a particular string
        format. For example:
<pre class="pre codeblock"><code>SELECT FROM_UNIXTIME(UNIX_TIMESTAMP(NOW() + interval 3 days),
  'yyyy/MM/dd HH:mm') AS yyyy_mm_dd_hh_mm;
+------------------+
| yyyy_mm_dd_hh_mm |
+------------------+
| 2016/06/03 11:38 |
+------------------+
</code></pre>
      </div>

      <p class="p" id="common__insert_sort_blurb">
        <strong class="ph b">Sorting considerations:</strong> Although you can specify an <code class="ph codeph">ORDER BY</code>
        clause in an <code class="ph codeph">INSERT ... SELECT</code> statement, any <code class="ph codeph">ORDER BY</code>
        clause is ignored and the results are not necessarily sorted. An <code class="ph codeph">INSERT ...
        SELECT</code> operation potentially creates many different data files, prepared by
        different executor Impala daemons, and therefore the notion of the data being stored in
        sorted order is impractical.
      </p>

      <p class="p" id="common__create_table_like_view">
        Prior to Impala 1.4.0, it was not possible to use the <code class="ph codeph">CREATE TABLE LIKE
        <var class="keyword varname">view_name</var></code> syntax. In Impala 1.4.0 and higher, you can create
        a table with the same column definitions as a view using the <code class="ph codeph">CREATE TABLE
        LIKE</code> technique. Although <code class="ph codeph">CREATE TABLE LIKE</code> normally inherits
        the file format of the original table, a view has no underlying file format, so
        <code class="ph codeph">CREATE TABLE LIKE <var class="keyword varname">view_name</var></code> produces a text table by
        default. To specify a different file format, include a <code class="ph codeph">STORED AS
        <var class="keyword varname">file_format</var></code> clause at the end of the <code class="ph codeph">CREATE TABLE
        LIKE</code> statement.
      </p>

      <div class="note note note_note" id="common__compute_stats_nulls"><span class="note__title notetitle">Note:</span> 
        Prior to Impala 1.4.0, <code class="ph codeph">COMPUTE STATS</code> counted the number of
        <code class="ph codeph">NULL</code> values in each column and recorded that figure in the metastore
        database. Because Impala does not currently use the <code class="ph codeph">NULL</code> count during
        query planning, Impala 1.4.0 and higher speeds up the <code class="ph codeph">COMPUTE STATS</code>
        statement by skipping this <code class="ph codeph">NULL</code> counting.
      </div>

      <p class="p" id="common__regular_expression_whole_string">
        The regular expression must match the entire value, not just occur somewhere inside it.
        Use <code class="ph codeph">.*</code> at the beginning, the end, or both if you only need to match
        characters anywhere in the middle. Thus, the <code class="ph codeph">^</code> and <code class="ph codeph">$</code>
        atoms are often redundant, although you might already have them in your expression
        strings that you reuse from elsewhere.
      </p>

      <p class="p" id="common__regexp_matching">
        In Impala 1.3.1 and higher, the <code class="ph codeph">REGEXP</code> and <code class="ph codeph">RLIKE</code>
        operators now match a regular expression string that occurs anywhere inside the target
        string, the same as if the regular expression was enclosed on each side by
        <code class="ph codeph">.*</code>. See <a class="xref" href="../topics/impala_operators.html#regexp">REGEXP Operator</a> for
        examples. Previously, these operators only succeeded when the regular expression matched
        the entire target string. This change improves compatibility with the regular expression
        support for popular database systems. There is no change to the behavior of the
        <code class="ph codeph">regexp_extract()</code> and <code class="ph codeph">regexp_replace()</code> built-in
        functions.
      </p>

      <p class="p" id="common__insert_inherit_permissions">
        By default, if an <code class="ph codeph">INSERT</code> statement creates any new subdirectories
        underneath a partitioned table, those subdirectories are assigned default HDFS
        permissions for the <code class="ph codeph">impala</code> user. To make each subdirectory have the
        same permissions as its parent directory in HDFS, specify the
        <code class="ph codeph">‑‑insert_inherit_permissions</code> startup option for the
        <span class="keyword cmdname">impalad</span> daemon.
      </p>

      <p class="p">
        <span class="ph" id="common__union_all_vs_union">Prefer <code class="ph codeph">UNION ALL</code> over
        <code class="ph codeph">UNION</code> when you know the data sets are disjoint or duplicate values are
        not a problem; <code class="ph codeph">UNION ALL</code> is more efficient because it avoids
        materializing and sorting the entire result set to eliminate duplicate values.</span>
      </p>

      <div class="note note note_note" id="common__thorn"><span class="note__title notetitle">Note:</span> 
        The <code class="ph codeph">CREATE TABLE</code> clauses <code class="ph codeph">FIELDS TERMINATED BY</code>,
        <code class="ph codeph">ESCAPED BY</code>, and <code class="ph codeph">LINES TERMINATED BY</code> have special rules
        for the string literal used for their argument, because they all require a single
        character. You can use a regular character surrounded by single or double quotation
        marks, an octal sequence such as <code class="ph codeph">'\054'</code> (representing a comma), or an
        integer in the range '-127'..'128' (with quotation marks but no backslash), which is
        interpreted as a single-byte ASCII character. Negative values are subtracted from 256;
        for example, <code class="ph codeph">FIELDS TERMINATED BY '-2'</code> sets the field delimiter to
        ASCII code 254, the <span class="q">"Icelandic Thorn"</span> character used as a delimiter by some data
        formats.
      </div>



      

      

      <p class="p" id="common__command_line_blurb">
        <strong class="ph b">Command-line equivalent:</strong>
      </p>

      <p class="p" id="common__complex_types_blurb">
        <strong class="ph b">Complex type considerations:</strong>
      </p>

      <p class="p" id="common__complex_types_combo">
        Because complex types are often used in combination, for example an
        <code class="ph codeph">ARRAY</code> of <code class="ph codeph">STRUCT</code> elements, if you are unfamiliar with
        the Impala complex types, start with
        <a class="xref" href="../topics/impala_complex_types.html#complex_types">Complex Types (Impala 2.3 or higher only)</a> for background
        information and usage examples.
      </p>

      <p class="p" id="common__complex_types_short_intro">
        In <span class="keyword">Impala 2.3</span> and higher, Impala supports the complex types
        <code class="ph codeph">ARRAY</code>, <code class="ph codeph">STRUCT</code>, and <code class="ph codeph">MAP</code>. In
        <span class="keyword">Impala 3.2</span> and higher, Impala also supports these
        complex types in ORC. See
        <a class="xref" href="../topics/impala_complex_types.html#complex_types">Complex Types (Impala 2.3 or higher only)</a> for details.
        These Complex types are currently supported only for the Parquet or ORC file formats.
        Because Impala has better performance on Parquet than ORC, if you plan to use complex
        types, become familiar with the performance and storage aspects of Parquet first.
      </p>

      <ul class="ul" id="common__complex_types_restrictions">
        <li class="li">
          <p class="p">
            Columns with this data type can only be used in tables or partitions with the
            Parquet or ORC file format.
          </p>
        </li>

        <li class="li">
          <p class="p">
            Columns with this data type cannot be used as partition key columns in a partitioned
            table.
          </p>
        </li>

        <li class="li">
          <p class="p">
            The <code class="ph codeph">COMPUTE STATS</code> statement does not produce any statistics for
            columns of this data type.
          </p>
        </li>

        <li class="li">
          <p class="p" id="common__complex_types_max_length">
            The maximum length of the column definition for any complex type, including
            declarations for any nested types, is 4000 characters.
          </p>
        </li>

        <li class="li">
          <p class="p">
            See <a class="xref" href="../topics/impala_complex_types.html#complex_types_limits">Limitations and Restrictions for Complex Types</a> for a
            full list of limitations and associated guidelines about complex type columns.
          </p>
        </li>
      </ul>

      <p class="p" id="common__complex_types_partitioning">
        Partitioned tables can contain complex type columns. All the partition key columns must
        be scalar types.
      </p>

      <p class="p" id="common__complex_types_describe">
        You can pass a multi-part qualified name to <code class="ph codeph">DESCRIBE</code> to specify an
        <code class="ph codeph">ARRAY</code>, <code class="ph codeph">STRUCT</code>, or <code class="ph codeph">MAP</code> column and
        visualize its structure as if it were a table. For example, if table <code class="ph codeph">T1</code>
        contains an <code class="ph codeph">ARRAY</code> column <code class="ph codeph">A1</code>, you could issue the
        statement <code class="ph codeph">DESCRIBE t1.a1</code>. If table <code class="ph codeph">T1</code> contained a
        <code class="ph codeph">STRUCT</code> column <code class="ph codeph">S1</code>, and a field <code class="ph codeph">F1</code>
        within the <code class="ph codeph">STRUCT</code> was a <code class="ph codeph">MAP</code>, you could issue the
        statement <code class="ph codeph">DESCRIBE t1.s1.f1</code>. An <code class="ph codeph">ARRAY</code> is shown as a
        two-column table, with <code class="ph codeph">ITEM</code> and <code class="ph codeph">POS</code> columns. A
        <code class="ph codeph">STRUCT</code> is shown as a table with each field representing a column in the
        table. A <code class="ph codeph">MAP</code> is shown as a two-column table, with <code class="ph codeph">KEY</code>
        and <code class="ph codeph">VALUE</code> columns.
      </p>

      <div class="note note note_note" id="common__complex_type_schema_pointer"><span class="note__title notetitle">Note:</span> 
        Many of the complex type examples refer to tables such as <code class="ph codeph">CUSTOMER</code> and
        <code class="ph codeph">REGION</code> adapted from the tables used in the TPC-H benchmark. See
        <a class="xref" href="../topics/impala_complex_types.html#complex_sample_schema">Sample Schema and Data for Experimenting with Impala Complex Types</a> for the table
        definitions.
      </div>

      <p class="p" id="common__complex_types_unsupported_filetype">
        <strong class="ph b">Complex type considerations:</strong> Although you can create tables in this file format
        using the complex types (<code class="ph codeph">ARRAY</code>, <code class="ph codeph">STRUCT</code>, and
        <code class="ph codeph">MAP</code>) available in <span class="keyword">Impala 2.3</span> and higher,
        currently, Impala can query these types only in Parquet tables. <span class="ph">
        The one exception to the preceding rule is <code class="ph codeph">COUNT(*)</code> queries on RCFile
        tables that include complex types. Such queries are allowed in
        <span class="keyword">Impala 2.6</span> and higher. </span>
      </p>

      <p class="p" id="common__complex_types_caveat_no_operator">
        You cannot refer to a column with a complex data type (<code class="ph codeph">ARRAY</code>,
        <code class="ph codeph">STRUCT</code>, or <code class="ph codeph">MAP</code> directly in an operator. You can apply
        operators only to scalar values that make up a complex type (the fields of a
        <code class="ph codeph">STRUCT</code>, the items of an <code class="ph codeph">ARRAY</code>, or the key or value
        portion of a <code class="ph codeph">MAP</code>) as part of a join query that refers to the scalar
        value using the appropriate dot notation or <code class="ph codeph">ITEM</code>, <code class="ph codeph">KEY</code>,
        or <code class="ph codeph">VALUE</code> pseudocolumn names.
      </p>

      <p class="p" id="common__udfs_no_complex_types">
        Currently, Impala UDFs cannot accept arguments or return values of the Impala complex
        types (<code class="ph codeph">STRUCT</code>, <code class="ph codeph">ARRAY</code>, or <code class="ph codeph">MAP</code>).
      </p>

      <p class="p" id="common__complex_types_read_only">
        Impala currently cannot write new data files containing complex type columns. Therefore,
        although the <code class="ph codeph">SELECT</code> statement works for queries involving complex type
        columns, you cannot use a statement form that writes data to complex type columns, such
        as <code class="ph codeph">CREATE TABLE AS SELECT</code> or <code class="ph codeph">INSERT ... SELECT</code>. To
        create data files containing complex type data, use the Hive <code class="ph codeph">INSERT</code>
        statement, or another ETL mechanism such as MapReduce jobs, Spark jobs, Pig, and so on.
      </p>

      <p class="p" id="common__complex_types_views">
        For tables containing complex type columns (<code class="ph codeph">ARRAY</code>,
        <code class="ph codeph">STRUCT</code>, or <code class="ph codeph">MAP</code>), you typically use join queries to
        refer to the complex values. You can use views to hide the join notation, making such
        tables seem like traditional denormalized tables, and making those tables queryable by
        business intelligence tools that do not have built-in support for those complex types.
        See <a class="xref" href="../topics/impala_complex_types.html#complex_types_views">Accessing Complex Type Data in Flattened Form Using Views</a> for details.
      </p>

      <p class="p" id="common__complex_types_views_caveat">
        Because you cannot directly issue <code class="ph codeph">SELECT <var class="keyword varname">col_name</var></code>
        against a column of complex type, you cannot use a view or a <code class="ph codeph">WITH</code>
        clause to <span class="q">"rename"</span> a column by selecting it with a column alias.
      </p>

      <p class="p" id="common__complex_types_aggregation_explanation">
        To access a column with a complex type (<code class="ph codeph">ARRAY</code>, <code class="ph codeph">STRUCT</code>,
        or <code class="ph codeph">MAP</code>) in an aggregation function, you unpack the individual elements
        using join notation in the query, and then apply the function to the final scalar item,
        field, key, or value at the bottom of any nested type hierarchy in the column. See
        <a class="xref" href="../topics/impala_complex_types.html#complex_types">Complex Types (Impala 2.3 or higher only)</a> for details about using
        complex types in Impala.
      </p>

      <div class="p" id="common__complex_types_aggregation_example">
        The following example demonstrates calls to several aggregation functions using values
        from a column containing nested complex types (an <code class="ph codeph">ARRAY</code> of
        <code class="ph codeph">STRUCT</code> items). The array is unpacked inside the query using join
        notation. The array elements are referenced using the <code class="ph codeph">ITEM</code>
        pseudocolumn, and the structure fields inside the array elements are referenced using
        dot notation. Numeric values such as <code class="ph codeph">SUM()</code> and <code class="ph codeph">AVG()</code>
        are computed using the numeric <code class="ph codeph">R_NATIONKEY</code> field, and the
        general-purpose <code class="ph codeph">MAX()</code> and <code class="ph codeph">MIN()</code> values are computed
        from the string <code class="ph codeph">N_NAME</code> field.
<pre class="pre codeblock"><code>describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array&lt;struct&lt;           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | &gt;&gt;                      |         |
+-------------+-------------------------+---------+

select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+

select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
</code></pre>
      </div>

      <p class="p" id="common__hive_blurb">
        <strong class="ph b">Hive considerations:</strong>
      </p>

      <p class="p" id="common__permissions_blurb">
        <strong class="ph b">HDFS permissions:</strong>
      </p>

      <p class="p" id="common__permissions_blurb_no">
        <strong class="ph b">HDFS permissions:</strong> This statement does not touch any HDFS files or directories,
        therefore no HDFS permissions are required.
      </p>

      <p class="p" id="common__security_blurb">
        <strong class="ph b">Security considerations:</strong>
      </p>

      <p class="p" id="common__performance_blurb">
        <strong class="ph b">Performance considerations:</strong>
      </p>

      <p class="p" id="common__conversion_blurb">
        <strong class="ph b">Casting and conversions:</strong>
      </p>

      <p class="p" id="common__related_info">
        <strong class="ph b">Related information:</strong>
      </p>

      <p class="p" id="common__related_tasks">
        <strong class="ph b">Related tasks:</strong>
      </p>

      <p class="p" id="common__related_options">
        <strong class="ph b">Related startup options:</strong>
      </p>

      <p class="p" id="common__restrictions_blurb">
        <strong class="ph b">Restrictions:</strong>
      </p>

      <p class="p" id="common__restrictions_sliding_window">
        <strong class="ph b">Restrictions:</strong> In Impala 2.0 and higher, this function can be used as an analytic
        function, but with restrictions on any window clause. For <code class="ph codeph">MAX()</code> and
        <code class="ph codeph">MIN()</code>, the window clause is only allowed if the start bound is
        <code class="ph codeph">UNBOUNDED PRECEDING</code>.
      </p>



      <p class="p" id="common__restrictions_non_analytic">
        <strong class="ph b">Restrictions:</strong> This function cannot be used as an analytic function; it does not
        currently support the <code class="ph codeph">OVER()</code> clause.
      </p>

      <p class="p" id="common__compatibility_blurb">
        <strong class="ph b">Compatibility:</strong>
      </p>

      <p class="p" id="common__null_blurb">
        <strong class="ph b">NULL considerations:</strong>
      </p>

      <p class="p" id="common__udf_blurb">
        <strong class="ph b">UDF considerations:</strong>
      </p>

      <p class="p" id="common__udf_blurb_no">
        <strong class="ph b">UDF considerations:</strong> This type cannot be used for the argument or return type of a
        user-defined function (UDF) or user-defined aggregate function (UDA).
      </p>

      <p class="p" id="common__view_blurb">
        <strong class="ph b">Considerations for views:</strong>
      </p>

      <p class="p" id="common__null_bad_numeric_cast">
        <strong class="ph b">NULL considerations:</strong> Casting any non-numeric value to this type produces a
        <code class="ph codeph">NULL</code> value.
      </p>

      <p class="p" id="common__null_bad_timestamp_cast">
        <strong class="ph b">NULL considerations:</strong> Casting any unrecognized <code class="ph codeph">STRING</code> value to
        this type produces a <code class="ph codeph">NULL</code> value.
      </p>

      <p class="p" id="common__null_null_arguments">
        <strong class="ph b">NULL considerations:</strong> An expression of this type produces a <code class="ph codeph">NULL</code>
        value if any argument of the expression is <code class="ph codeph">NULL</code>.
      </p>

      <p class="p" id="common__privileges_blurb">
        <strong class="ph b">Required privileges:</strong>
      </p>

      <p class="p" id="common__parquet_blurb">
        <strong class="ph b">Parquet considerations:</strong>
      </p>



      <div class="p" id="common__parquet_tools_blurb">
        To examine the internal structure and data of Parquet files, you can use the
        <span class="keyword cmdname">parquet-tools</span> command. Make sure this command is in your
        <code class="ph codeph">$PATH</code>. (Typically, it is symlinked from <span class="ph filepath">/usr/bin</span>;
        sometimes, depending on your installation setup, you might need to locate it under an
        alternative <code class="ph codeph">bin</code> directory.) The arguments to this command let you
        perform operations such as:
        <ul class="ul">
          <li class="li">
            <code class="ph codeph">cat</code>: Print a file's contents to standard out. In
            <span class="keyword">Impala 2.3</span> and higher, you can use the <code class="ph codeph">-j</code>
            option to output JSON.
          </li>

          <li class="li">
            <code class="ph codeph">head</code>: Print the first few records of a file to standard output.
          </li>

          <li class="li">
            <code class="ph codeph">schema</code>: Print the Parquet schema for the file.
          </li>

          <li class="li">
            <code class="ph codeph">meta</code>: Print the file footer metadata, including key-value
            properties (like Avro schema), compression ratios, encodings, compression used, and
            row group information.
          </li>

          <li class="li">
            <code class="ph codeph">dump</code>: Print all data and metadata.
          </li>
        </ul>
        Use <code class="ph codeph">parquet-tools -h</code> to see usage information for all the arguments.
        Here are some examples showing <span class="keyword cmdname">parquet-tools</span> usage:
<pre class="pre codeblock"><code>
$ # Be careful doing this for a big file! Use parquet-tools head to be safe.
$ parquet-tools cat sample.parq
year = 1992
month = 1
day = 2
dayofweek = 4
dep_time = 748
crs_dep_time = 750
arr_time = 851
crs_arr_time = 846
carrier = US
flight_num = 53
actual_elapsed_time = 63
crs_elapsed_time = 56
arrdelay = 5
depdelay = -2
origin = CMH
dest = IND
distance = 182
cancelled = 0
diverted = 0

year = 1992
month = 1
day = 3
...

</code></pre>
<pre class="pre codeblock"><code>
$ parquet-tools head -n 2 sample.parq
year = 1992
month = 1
day = 2
dayofweek = 4
dep_time = 748
crs_dep_time = 750
arr_time = 851
crs_arr_time = 846
carrier = US
flight_num = 53
actual_elapsed_time = 63
crs_elapsed_time = 56
arrdelay = 5
depdelay = -2
origin = CMH
dest = IND
distance = 182
cancelled = 0
diverted = 0

year = 1992
month = 1
day = 3
...

</code></pre>
<pre class="pre codeblock"><code>
$ parquet-tools schema sample.parq
message schema {
  optional int32 year;
  optional int32 month;
  optional int32 day;
  optional int32 dayofweek;
  optional int32 dep_time;
  optional int32 crs_dep_time;
  optional int32 arr_time;
  optional int32 crs_arr_time;
  optional binary carrier;
  optional int32 flight_num;
...

</code></pre>
<pre class="pre codeblock"><code>
$ parquet-tools meta sample.parq
creator:             impala version 2.2.0-...

file schema:         schema
-------------------------------------------------------------------
year:                OPTIONAL INT32 R:0 D:1
month:               OPTIONAL INT32 R:0 D:1
day:                 OPTIONAL INT32 R:0 D:1
dayofweek:           OPTIONAL INT32 R:0 D:1
dep_time:            OPTIONAL INT32 R:0 D:1
crs_dep_time:        OPTIONAL INT32 R:0 D:1
arr_time:            OPTIONAL INT32 R:0 D:1
crs_arr_time:        OPTIONAL INT32 R:0 D:1
carrier:             OPTIONAL BINARY R:0 D:1
flight_num:          OPTIONAL INT32 R:0 D:1
...

row group 1:         RC:20636601 TS:265103674
-------------------------------------------------------------------
year:                 INT32 SNAPPY DO:4 FPO:35 SZ:10103/49723/4.92 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
month:                INT32 SNAPPY DO:10147 FPO:10210 SZ:11380/35732/3.14 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
day:                  INT32 SNAPPY DO:21572 FPO:21714 SZ:3071658/9868452/3.21 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
dayofweek:            INT32 SNAPPY DO:3093276 FPO:3093319 SZ:2274375/5941876/2.61 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
dep_time:             INT32 SNAPPY DO:5367705 FPO:5373967 SZ:28281281/28573175/1.01 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
crs_dep_time:         INT32 SNAPPY DO:33649039 FPO:33654262 SZ:10220839/11574964/1.13 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
arr_time:             INT32 SNAPPY DO:43869935 FPO:43876489 SZ:28562410/28797767/1.01 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
crs_arr_time:         INT32 SNAPPY DO:72432398 FPO:72438151 SZ:10908972/12164626/1.12 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
carrier:              BINARY SNAPPY DO:83341427 FPO:83341558 SZ:114916/128611/1.12 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
flight_num:           INT32 SNAPPY DO:83456393 FPO:83488603 SZ:10216514/11474301/1.12 VC:20636601 ENC:PLAIN_DICTIONARY,RLE,PLAIN
...

</code></pre>
      </div>

      <p class="p" id="common__parquet_ok">
        <strong class="ph b">Parquet considerations:</strong> This type is fully compatible with Parquet tables.
      </p>

      <p class="p" id="common__analytic_not_allowed_caveat">
        This function cannot be used in an analytic context. That is, the
        <code class="ph codeph">OVER()</code> clause is not allowed at all with this function.
      </p>

      <p class="p" id="common__analytic_partition_pruning_caveat">
        In queries involving both analytic functions and partitioned tables, partition pruning
        only occurs for columns named in the <code class="ph codeph">PARTITION BY</code> clause of the
        analytic function call. For example, if an analytic function query has a clause such as
        <code class="ph codeph">WHERE year=2016</code>, the way to make the query prune all other
        <code class="ph codeph">YEAR</code> partitions is to include <code class="ph codeph">PARTITION BY year</code> in the
        analytic function call; for example, <code class="ph codeph">OVER (PARTITION BY
        year,<var class="keyword varname">other_columns</var>
        <var class="keyword varname">other_analytic_clauses</var>)</code>.

      </p>

      <p class="p" id="common__impala_parquet_encodings_caveat">
        Impala can query Parquet files that use the <code class="ph codeph">PLAIN</code>,
        <code class="ph codeph">PLAIN_DICTIONARY</code>, <code class="ph codeph">BIT_PACKED</code>, <code class="ph codeph">RLE</code>
        and <code class="ph codeph">RLE_DICTIONARY</code> encodings. <code class="ph codeph">RLE_DICTIONARY</code> is supported
        only in <span class="keyword">Impala 4.0</span> and up.
        When creating files outside of Impala for use by Impala, make sure to use one of the
        supported encodings. In particular, for MapReduce jobs,
        <code class="ph codeph">parquet.writer.version</code> must not be defined (especially as
        <code class="ph codeph">PARQUET_2_0</code>) for writing the configurations of Parquet MR jobs. Use the
        default version (or format). The default format, 1.0, includes some enhancements that
        are compatible with older versions. Data using the 2.0 format might not be consumable by
        Impala, due to use of the <code class="ph codeph">RLE_DICTIONARY</code> encoding.
      </p>

      <div class="note note note_note" id="common__restrictions_nonimpala_parquet"><span class="note__title notetitle">Note:</span> 
        <p class="p">
          Currently, Impala always decodes the column data in Parquet files based on the ordinal
          position of the columns, not by looking up the position of each column based on its
          name. Parquet files produced outside of Impala must write column data in the same
          order as the columns are declared in the Impala table. Any optional columns that are
          omitted from the data files must be the rightmost columns in the Impala table
          definition.
        </p>

        <p class="p">
          If you created compressed Parquet files through some tool other than Impala, make sure
          that any compression codecs are supported in Parquet by Impala. For example, Impala
          does not currently support LZO compression in Parquet files. Also doublecheck that you
          used any recommended compatibility settings in the other tool, such as
          <code class="ph codeph">spark.sql.parquet.binaryAsString</code> when writing Parquet files through
          Spark.
        </p>
      </div>

      <p class="p" id="common__text_blurb">
        <strong class="ph b">Text table considerations:</strong>
      </p>

      <p class="p" id="common__text_bulky">
        <strong class="ph b">Text table considerations:</strong> Values of this type are potentially larger in text
        tables than in tables using Parquet or other binary formats.
      </p>

      <p class="p" id="common__schema_evolution_blurb">
        <strong class="ph b">Schema evolution considerations:</strong>
      </p>

      <p class="p" id="common__column_stats_blurb">
        <strong class="ph b">Column statistics considerations:</strong>
      </p>

      <p class="p" id="common__column_stats_constant">
        <strong class="ph b">Column statistics considerations:</strong> Because this type has a fixed size, the maximum
        and average size fields are always filled in for column statistics, even before you run
        the <code class="ph codeph">COMPUTE STATS</code> statement.
      </p>

      <p class="p" id="common__column_stats_variable">
        <strong class="ph b">Column statistics considerations:</strong> Because the values of this type have variable
        size, none of the column statistics fields are filled in until you run the
        <code class="ph codeph">COMPUTE STATS</code> statement.
      </p>

      <p class="p" id="common__usage_notes_blurb">
        <strong class="ph b">Usage notes:</strong>
      </p>

      <p class="p" id="common__how_impala_handles_nan_values">
        Impala does not evaluate NaN (not a number) as equal to any other numeric values,
        including other NaN values. For example, the following statement, which evaluates
        equality between two NaN values, returns <code class="ph codeph">false</code>:
      </p>

      <p class="p" id="common__example_blurb">
        <strong class="ph b">Examples:</strong>
      </p>

      <p class="p" id="common__result_set_blurb">
        <strong class="ph b">Result set:</strong>
      </p>

      <p class="p" id="common__jdbc_blurb">
        <strong class="ph b">JDBC and ODBC considerations:</strong>
      </p>

      <p class="p" id="common__cancel_blurb_no">
        <strong class="ph b">Cancellation:</strong> Cannot be cancelled.
      </p>

      <p class="p" id="common__cancel_blurb_yes">
        <strong class="ph b">Cancellation:</strong> Can be cancelled. To cancel this statement, use Ctrl-C from the
        <span class="keyword cmdname">impala-shell</span> interpreter, the <span class="ph uicontrol">Cancel</span> button
        from the <span class="ph uicontrol">Watch</span> page in Hue, or <span class="ph uicontrol">Cancel</span> from
        the list of in-flight queries (for a particular node) on the
        <span class="ph uicontrol">Queries</span> tab in the Impala web UI (port 25000).
      </p>

      <p class="p" id="common__cancel_blurb_maybe">
        <strong class="ph b">Cancellation:</strong> Certain multi-stage statements (<code class="ph codeph">CREATE TABLE AS
        SELECT</code> and <code class="ph codeph">COMPUTE STATS</code>) can be cancelled during some stages,
        when running <code class="ph codeph">INSERT</code> or <code class="ph codeph">SELECT</code> operations internally.
        To cancel this statement, use Ctrl-C from the <span class="keyword cmdname">impala-shell</span>
        interpreter, the <span class="ph uicontrol">Cancel</span> button from the
        <span class="ph uicontrol">Watch</span> page in Hue, or <span class="ph uicontrol">Cancel</span> from the list
        of in-flight queries (for a particular node) on the <span class="ph uicontrol">Queries</span> tab
        in the Impala web UI (port 25000).
      </p>

      <p class="p" id="common__partitioning_blurb">
        <strong class="ph b">Partitioning:</strong>
      </p>

      <p class="p" id="common__partitioning_good">
        <strong class="ph b">Partitioning:</strong> Prefer to use this type for a partition key column. Impala can
        process the numeric type more efficiently than a <code class="ph codeph">STRING</code> representation
        of the value.
      </p>

      <p class="p" id="common__partitioning_bad">
        <strong class="ph b">Partitioning:</strong> This type can be used for partition key columns. Because of the
        efficiency advantage of numeric values over character-based values, if the partition key
        is a string representation of a number, prefer to use an integer type with sufficient
        range (<code class="ph codeph">INT</code>, <code class="ph codeph">BIGINT</code>, and so on) where practical.
      </p>

      <p class="p" id="common__partitioning_silly">
        <strong class="ph b">Partitioning:</strong> Because this type has so few distinct values, it is typically not a
        sensible choice for a partition key column.
      </p>

      <p class="p" id="common__partitioning_imprecise">
        <strong class="ph b">Partitioning:</strong> Because fractional values of this type are not always represented
        precisely, when this type is used for a partition key column, the underlying HDFS
        directories might not be named exactly as you expect. Prefer to partition on a
        <code class="ph codeph">DECIMAL</code> column instead.
      </p>

      <p class="p" id="common__partitioning_worrisome">
        <strong class="ph b">Partitioning:</strong> Because this type potentially has so many distinct values, it is
        often not a sensible choice for a partition key column. For example, events 1
        millisecond apart would be stored in different partitions. Consider using the
        <code class="ph codeph">TRUNC()</code> function to condense the number of distinct values, and
        partition on a new column with the truncated values.
      </p>

      <p class="p" id="common__hdfs_blurb">
        <strong class="ph b">HDFS considerations:</strong>
      </p>

      <p class="p" id="common__file_format_blurb">
        <strong class="ph b">File format considerations:</strong>
      </p>

      <p class="p" id="common__s3_blurb">
        <strong class="ph b">Amazon S3 considerations:</strong>
      </p>

      <p class="p" id="common__adls_blurb">
        <strong class="ph b">ADLS considerations:</strong>
      </p>

      <p class="p" id="common__isilon_blurb">
        <strong class="ph b">Isilon considerations:</strong>
      </p>

      <div class="p" id="common__isilon_block_size_caveat">
        Because the EMC Isilon storage devices use a global value for the block size rather than
        a configurable value for each file, the <code class="ph codeph">PARQUET_FILE_SIZE</code> query option
        has no effect when Impala inserts data into a table or partition residing on Isilon
        storage. Use the <code class="ph codeph">isi</code> command to set the default block size globally on
        the Isilon device. For example, to set the Isilon default block size to 256 MB, the
        recommended size for Parquet data files for Impala, issue the following command:
<pre class="pre codeblock"><code>isi hdfs settings modify --default-block-size=256MB</code></pre>
      </div>

      <p class="p" id="common__ozone_blurb">
        <strong class="ph b">Ozone considerations:</strong>
      </p>

      <p class="p" id="common__ozone_block_size_caveat">
        Because Apache Ozone storage buckets use a global value for the block size rather than
        a configurable value for each file, the <code class="ph codeph">PARQUET_FILE_SIZE</code> query option
        has no effect when Impala inserts data into a table or partition residing on Ozone
        storage.
      </p>

      <p class="p" id="common__hbase_blurb">
        <strong class="ph b">HBase considerations:</strong>
      </p>

      <p class="p" id="common__hbase_no_load_data">
        The <code class="ph codeph">LOAD DATA</code> statement cannot be used with HBase tables.
      </p>

      <p class="p" id="common__hbase_ok">
        <strong class="ph b">HBase considerations:</strong> This data type is fully compatible with HBase tables.
      </p>

      <p class="p" id="common__hbase_no">
        <strong class="ph b">HBase considerations:</strong> This data type cannot be used with HBase tables.
      </p>

      <p class="p" id="common__iceberg_blurb">
        <strong class="ph b">Iceberg considerations:</strong>
      </p>

      <p class="p" id="common__iceberg_load_data">
        See <a class="xref" href="../topics/impala_iceberg.html#iceberg_load">Loading data into Iceberg tables</a> for details about
        <code class="ph codeph">LOAD DATA</code> with Iceberg.
      </p>

      <p class="p" id="common__internals_blurb">
        <strong class="ph b">Internal details:</strong>
      </p>

      <p class="p" id="common__internals_1_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as a 1-byte value.
      </p>

      <p class="p" id="common__internals_2_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as a 2-byte value.
      </p>

      <p class="p" id="common__internals_4_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as a 4-byte value.
      </p>

      <p class="p" id="common__internals_8_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as an 8-byte value.
      </p>

      <p class="p" id="common__internals_16_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as a 16-byte value.
      </p>

      <p class="p" id="common__internals_max_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as a byte array with the same size as the
        length specification. Values that are shorter than the specified length are padded on
        the right with trailing spaces.
      </p>

      <p class="p" id="common__internals_min_bytes">
        <strong class="ph b">Internal details:</strong> Represented in memory as a byte array with the minimum size
        needed to represent each value.
      </p>

      <p class="p" id="common__added_in_440">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 4.4</span>
      </p>

      <p class="p" id="common__added_in_400">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 4.0</span>
      </p>

      <p class="p" id="common__added_in_30">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 3.0</span>
      </p>

      <p class="p" id="common__added_in_212">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.12</span>
      </p>

      <p class="p" id="common__added_in_2110">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.11.0</span>
      </p>

      <p class="p" id="common__added_in_2100">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.10.0</span>
      </p>

      <p class="p" id="common__added_in_290">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.9.0</span>
      </p>

      <p class="p" id="common__added_in_280">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.8.0</span>
      </p>

      <p class="p" id="common__added_in_270">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.7.0</span>
      </p>

      <p class="p" id="common__added_in_260">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.6.0</span>
      </p>

      <p class="p" id="common__added_in_250">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.5.0</span>
      </p>

      <p class="p" id="common__added_in_230">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.3.0</span>
      </p>

      <p class="p" id="common__added_in_20">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.0.0</span>
      </p>

      <p class="p" id="common__enhanced_in_20">
        <strong class="ph b">Added in:</strong> Available in earlier Impala releases, but new capabilities were added
        in <span class="keyword">Impala 2.0.0</span>
      </p>

      <p class="p" id="common__added_forever">
        <strong class="ph b">Added in:</strong> Available in all versions of Impala.
      </p>

      <p class="p" id="common__added_in_140">
        <strong class="ph b">Added in:</strong> Impala 1.4.0
      </p>

      <p class="p" id="common__added_in_130">
        <strong class="ph b">Added in:</strong> Impala 1.3.0
      </p>

      <p class="p" id="common__added_in_11">
        <strong class="ph b">Added in:</strong> Impala 1.1
      </p>

      <p class="p" id="common__added_in_111">
        <strong class="ph b">Added in:</strong> Impala 1.1.1
      </p>

      <p class="p" id="common__added_in_210">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.10</span>
      </p>

      <p class="p" id="common__added_in_220">
        <strong class="ph b">Added in:</strong> <span class="keyword">Impala 2.2.0</span>
      </p>

      <p class="p" id="common__syntax_blurb">
        <strong class="ph b">Syntax:</strong>
      </p>

      <p class="p" id="common__disk_space_blurb">
        For other tips about managing and reclaiming Impala disk space, see
        <a class="xref" href="../topics/impala_disk_space.html#disk_space">Managing Disk Space for Impala Data</a>.
      </p>

      <p class="p" id="common__join_types">
        Impala supports a wide variety of <code class="ph codeph">JOIN</code> clauses. Left, right, semi,
        full, and outer joins are supported in all Impala versions. The <code class="ph codeph">CROSS
        JOIN</code> operator is available in Impala 1.2.2 and higher. During performance
        tuning, you can override the reordering of join clauses that Impala does internally by
        including the keyword <code class="ph codeph">STRAIGHT_JOIN</code> immediately after the
        <code class="ph codeph">SELECT</code> and any <code class="ph codeph">DISTINCT</code> or <code class="ph codeph">ALL</code>
        keywords.
      </p>

      <p class="p" id="common__straight_join_nested_queries">
        The <code class="ph codeph">STRAIGHT_JOIN</code> hint affects the join order of table references in
        the query block containing the hint. It does not affect the join order of nested
        queries, such as views, inline views, or <code class="ph codeph">WHERE</code>-clause subqueries. To
        use this hint for performance tuning of complex queries, apply the hint to all query
        blocks that need a fixed join order.
      </p>

      <p class="p" id="common__catalog_server_124">
        In Impala 1.2.4 and higher, you can specify a table name with <code class="ph codeph">INVALIDATE
        METADATA</code> after the table is created in Hive, allowing you to make individual
        tables visible to Impala without doing a full reload of the catalog metadata. Impala
        1.2.4 also includes other changes to make the metadata broadcast mechanism faster and
        more responsive, especially during Impala startup. See
        <a class="xref" href="../topics/impala_new_features.html#new_features_124">New Features in Impala 1.2.4</a> for details.
      </p>

      <div class="p" id="common__explain_interpret">
        Read the <code class="ph codeph">EXPLAIN</code> plan from bottom to top:
        <ul class="ul">
          <li class="li">
            The last part of the plan shows the low-level details such as the expected amount of
            data that will be read, where you can judge the effectiveness of your partitioning
            strategy and estimate how long it will take to scan a table based on total data size
            and the size of the cluster.
          </li>

          <li class="li">
            As you work your way up, next you see the operations that will be parallelized and
            performed on each Impala node.
          </li>

          <li class="li">
            At the higher levels, you see how data flows when intermediate result sets are
            combined and transmitted from one node to another.
          </li>

          <li class="li">
            See <a class="xref" href="../topics/impala_explain_level.html#explain_level">EXPLAIN_LEVEL Query Option</a> for details
            about the <code class="ph codeph">EXPLAIN_LEVEL</code> query option, which lets you customize how
            much detail to show in the <code class="ph codeph">EXPLAIN</code> plan depending on whether you
            are doing high-level or low-level tuning, dealing with logical or physical aspects
            of the query.
          </li>
        </ul>
      </div>



      <p class="p" id="common__aggr1">
        Aggregate functions are a special category with different rules. These functions
        calculate a return value across all the items in a result set, so they require a
        <code class="ph codeph">FROM</code> clause in the query:
      </p>

<pre class="pre codeblock" id="common__aggr2"><code>select count(product_id) from product_catalog;
select max(height), avg(height) from census_data where age &gt; 20;
</code></pre>

      <p class="p" id="common__aggr3">
        Aggregate functions also ignore <code class="ph codeph">NULL</code> values rather than returning a
        <code class="ph codeph">NULL</code> result. For example, if some rows have <code class="ph codeph">NULL</code> for a
        particular column, those rows are ignored when computing the <code class="ph codeph">AVG()</code> for
        that column. Likewise, specifying <code class="ph codeph">COUNT(<var class="keyword varname">col_name</var>)</code> in
        a query counts only those rows where <var class="keyword varname">col_name</var> contains a
        non-<code class="ph codeph">NULL</code> value.
      </p>

      <p class="p">
        <span class="ph" id="common__aliases_vs_identifiers"> Aliases follow the same rules as identifiers when it
        comes to case insensitivity. Aliases can be longer than identifiers (up to the maximum
        length of a Java string) and can include additional characters such as spaces and dashes
        when they are quoted using backtick characters. </span>
      </p>

      <p class="p" id="common__views_vs_identifiers">
        Another way to define different names for the same tables or columns is to create views.
        See <a class="xref" href="../topics/impala_views.html#views">Overview of Impala Views</a> for details.
      </p>



      <div class="p" id="common__insert_hints">
        When inserting into partitioned tables, especially using the Parquet file format, you
        can include a hint in the <code class="ph codeph">INSERT</code> statement to fine-tune the overall
        performance of the operation and its resource usage:
        <ul class="ul">
          <li class="li">
            You would only use hints if an <code class="ph codeph">INSERT</code> into a partitioned Parquet
            table was failing due to capacity limits, or if such an <code class="ph codeph">INSERT</code> was
            succeeding but with less-than-optimal performance.
          </li>

          <li class="li">
            To use a hint to influence the join order, put the hint keyword <code class="ph codeph">/* +SHUFFLE
            */</code> or <code class="ph codeph">/* +NOSHUFFLE */</code> (including the square brackets)
            after the <code class="ph codeph">PARTITION</code> clause, immediately before the
            <code class="ph codeph">SELECT</code> keyword.
          </li>

          <li class="li">
            <code class="ph codeph">/* +SHUFFLE */</code> selects an execution plan that reduces the number of
            files being written simultaneously to HDFS, and the number of memory buffers holding
            data for individual partitions. Thus it reduces overall resource usage for the
            <code class="ph codeph">INSERT</code> operation, allowing some <code class="ph codeph">INSERT</code> operations
            to succeed that otherwise would fail. It does involve some data transfer between the
            nodes so that the data files for a particular partition are all constructed on the
            same node.
          </li>

          <li class="li">
            <code class="ph codeph">/* +NOSHUFFLE */</code> selects an execution plan that might be faster
            overall, but might also produce a larger number of small data files or exceed
            capacity limits, causing the <code class="ph codeph">INSERT</code> operation to fail. Use
            <code class="ph codeph">/* +SHUFFLE */</code> in cases where an <code class="ph codeph">INSERT</code> statement
            fails or runs inefficiently due to all nodes attempting to construct data for all
            partitions.
          </li>

          <li class="li">
            Impala automatically uses the <code class="ph codeph">/* +SHUFFLE */</code> method if any
            partition key column in the source table, mentioned in the <code class="ph codeph">INSERT ...
            SELECT</code> query, does not have column statistics. In this case, only the
            <code class="ph codeph">/* +NOSHUFFLE */</code> hint would have any effect.
          </li>

          <li class="li">
            If column statistics are available for all partition key columns in the source table
            mentioned in the <code class="ph codeph">INSERT ... SELECT</code> query, Impala chooses whether to
            use the <code class="ph codeph">/* +SHUFFLE */</code> or <code class="ph codeph">/* +NOSHUFFLE */</code>
            technique based on the estimated number of distinct values in those columns and the
            number of nodes involved in the <code class="ph codeph">INSERT</code> operation. In this case, you
            might need the <code class="ph codeph">/* +SHUFFLE */</code> or the <code class="ph codeph">/* +NOSHUFFLE
            */</code> hint to override the execution plan selected by Impala.
          </li>

          <li class="li">
            In <span class="keyword">Impala 2.8</span> or higher, you can make the
            <code class="ph codeph">INSERT</code> operation organize (<span class="q">"cluster"</span>) the data for each
            partition to avoid buffering data for multiple partitions and reduce the risk of an
            out-of-memory condition. Specify the hint as <code class="ph codeph">/* +CLUSTERED */</code>. This
            technique is primarily useful for inserts into Parquet tables, where the large block
            size requires substantial memory to buffer data for multiple output files at once.
          </li>
        </ul>
      </div>

      <p class="p" id="common__insert_parquet_blocksize">
        Any <code class="ph codeph">INSERT</code> statement for a Parquet table requires enough free space in
        the HDFS filesystem to write one block. Because Parquet data files use a block size of 1
        GB by default, an <code class="ph codeph">INSERT</code> might fail (even for a very small amount of
        data) if your HDFS is running low on space.
      </p>

      <div class="note important note_important" id="common__compute_stats_next"><span class="note__title importanttitle">Important:</span> 
        After adding or replacing data in a table used in performance-critical queries, issue a
        <code class="ph codeph">COMPUTE STATS</code> statement to make sure all statistics are up-to-date.
        Consider updating statistics for a table after any <code class="ph codeph">INSERT</code>, <code class="ph codeph">LOAD
        DATA</code>, or <code class="ph codeph">CREATE TABLE AS SELECT</code> statement in Impala, or after
        loading data through Hive and doing a <code class="ph codeph">REFRESH
        <var class="keyword varname">table_name</var></code> in Impala. This technique is especially important
        for tables that are very large, used in join queries, or both.
      </div>

      <p class="p" id="common__concat_blurb">
        <strong class="ph b">Usage notes:</strong> <code class="ph codeph">concat()</code> and <code class="ph codeph">concat_ws()</code> are
        appropriate for concatenating the values of multiple columns within the same row, while
        <code class="ph codeph">group_concat()</code> joins together values from different rows.
      </p>

      <p class="p" id="common__null_sorting_change">
        In Impala 1.2.1 and higher, all <code class="ph codeph">NULL</code> values come at the end of the
        result set for <code class="ph codeph">ORDER BY ... ASC</code> queries, and at the beginning of the
        result set for <code class="ph codeph">ORDER BY ... DESC</code> queries. In effect,
        <code class="ph codeph">NULL</code> is considered greater than all other values for sorting purposes.
        The original Impala behavior always put <code class="ph codeph">NULL</code> values at the end, even
        for <code class="ph codeph">ORDER BY ... DESC</code> queries. The new behavior in Impala 1.2.1 makes
        Impala more compatible with other popular database systems. In Impala 1.2.1 and higher,
        you can override or specify the sorting behavior for <code class="ph codeph">NULL</code> by adding the
        clause <code class="ph codeph">NULLS FIRST</code> or <code class="ph codeph">NULLS LAST</code> at the end of the
        <code class="ph codeph">ORDER BY</code> clause.
      </p>

      <p class="p" id="common__return_same_type">
        <strong class="ph b">Return type:</strong> same as the initial argument value, except that integer values are
        promoted to <code class="ph codeph">BIGINT</code> and floating-point values are promoted to
        <code class="ph codeph">DOUBLE</code>; use <code class="ph codeph">CAST()</code> when inserting into a smaller
        numeric column
      </p>

      <p class="p" id="common__ddl_blurb">
        <strong class="ph b">Statement type:</strong> DDL
      </p>

      <p class="p" id="common__dml_blurb">
        <strong class="ph b">Statement type:</strong> DML (but still affected by
        <a class="xref" href="../topics/impala_sync_ddl.html#sync_ddl">SYNC_DDL</a> query option)
      </p>

      <p class="p" id="common__dml_blurb_kudu">
        <strong class="ph b">Statement type:</strong> DML
      </p>

      <p class="p" id="common__sync_ddl_blurb">
        If you connect to different Impala nodes within an <span class="keyword cmdname">impala-shell</span>
        session for load-balancing purposes, you can enable the <code class="ph codeph">SYNC_DDL</code> query
        option to make each DDL statement wait before returning, until the new or changed
        metadata has been received by all the Impala nodes. See
        <a class="xref" href="../topics/impala_sync_ddl.html#sync_ddl">SYNC_DDL Query Option</a> for details.
      </p>



      <p class="p" id="common__regexp_boost">
        The Impala regular expression syntax conforms to the POSIX Extended Regular Expression
        syntax used by the Boost library. For details, see
        <a class="xref" href="http://www.boost.org/doc/libs/1_46_0/libs/regex/doc/html/boost_regex/syntax/basic_extended.html" target="_blank">the
        Boost documentation</a>. It has most idioms familiar from regular expressions in
        Perl, Python, and so on. It does not support <code class="ph codeph">.*?</code> for non-greedy
        matches.
      </p>

      <p class="p" id="common__regexp_re2">
        In Impala 2.0 and later, the Impala regular expression syntax conforms to the POSIX
        Extended Regular Expression syntax used by the Google RE2 library. For details, see
        <a class="xref" href="https://code.google.com/p/re2/" target="_blank">the RE2
        documentation</a>. It has most idioms familiar from regular expressions in Perl,
        Python, and so on, including <code class="ph codeph">.*?</code> for non-greedy matches.
      </p>

      <p class="p" id="common__regexp_re2_warning">
        In Impala 2.0 and later, a change in the underlying regular expression library could
        cause changes in the way regular expressions are interpreted by this function. Test any
        queries that use regular expressions and adjust the expression patterns if necessary.
        See <a class="xref" href="../topics/impala_incompatible_changes.html#incompatible_changes_200">Incompatible Changes Introduced in Impala 2.0.0</a>
        for details.
      </p>

      <p class="p" id="common__regexp_escapes">
        Because the <span class="keyword cmdname">impala-shell</span> interpreter uses the <code class="ph codeph">\</code>
        character for escaping, use <code class="ph codeph">\\</code> to represent the regular expression
        escape character in any regular expressions that you submit through
        <span class="keyword cmdname">impala-shell</span> . You might prefer to use the equivalent character class
        names, such as <code class="ph codeph">[[:digit:]]</code> instead of <code class="ph codeph">\d</code> which you
        would have to escape as <code class="ph codeph">\\d</code>.
      </p>

      <p class="p" id="common__set_vs_connect">
        The <code class="ph codeph">SET</code> statement has no effect until the
        <span class="keyword cmdname">impala-shell</span> interpreter is connected to an Impala server. Once you
        are connected, any query options you set remain in effect as you issue a subsequent
        <code class="ph codeph">CONNECT</code> command to connect to a different Impala host.
      </p>



      <p class="p" id="common__order_by_limit">
        Prior to Impala 1.4.0, Impala required any query including an
        <code class="ph codeph"><a class="xref" href="../topics/impala_order_by.html#order_by">ORDER BY</a></code>
        clause to also use a
        <code class="ph codeph"><a class="xref" href="../topics/impala_limit.html#limit">LIMIT</a></code> clause. In
        Impala 1.4.0 and higher, the <code class="ph codeph">LIMIT</code> clause is optional for <code class="ph codeph">ORDER
        BY</code> queries. In cases where sorting a huge result set requires enough memory to
        exceed the Impala memory limit for a particular executor Impala daemon, Impala
        automatically uses a temporary disk work area to perform the sort operation.
      </p>

      <p class="p" id="common__limit_and_offset">
        In Impala 1.2.1 and higher, you can combine a <code class="ph codeph">LIMIT</code> clause with an
        <code class="ph codeph">OFFSET</code> clause to produce a small result set that is different from a
        top-N query, for example, to return items 11 through 20. This technique can be used to
        simulate <span class="q">"paged"</span> results. Because Impala queries typically involve substantial
        amounts of I/O, use this technique only for compatibility in cases where you cannot
        rewrite the application logic. For best performance and scalability, wherever practical,
        query as many items as you expect to need, cache them on the application side, and
        display small groups of results to users using application logic.
      </p>

      <p class="p" id="common__impala_cache_replication_factor">
        In <span class="keyword">Impala 2.2</span> and higher, the optional <code class="ph codeph">WITH
        REPLICATION</code> clause for <code class="ph codeph">CREATE TABLE</code> and <code class="ph codeph">ALTER
        TABLE</code> lets you specify a <dfn class="term">replication factor</dfn>, the number of hosts
        on which to cache the same data blocks. When Impala processes a cached data block, where
        the cache replication factor is greater than 1, Impala randomly selects a host that has
        a cached copy of that data block. This optimization avoids excessive CPU usage on a
        single host when the same cached data block is processed multiple times. Where
        practical, specify a value greater than or equal to the HDFS block replication factor.
      </p>



      <p class="p" id="common__partitions_and_views">
        If a view applies to a partitioned table, any partition pruning considers the clauses on
        both the original query and any additional <code class="ph codeph">WHERE</code> predicates in the
        query that refers to the view. Prior to Impala 1.4, only the <code class="ph codeph">WHERE</code>
        clauses on the original query from the <code class="ph codeph">CREATE VIEW</code> statement were used
        for partition pruning.
      </p>

      <div class="p" id="common__describe_formatted_view">
        To see the definition of a view, issue a <code class="ph codeph">DESCRIBE FORMATTED</code> statement,
        which shows the query from the original <code class="ph codeph">CREATE VIEW</code> statement:
<pre class="pre codeblock"><code>[localhost:21000] &gt; create view v1 as select * from t1;
[localhost:21000] &gt; describe formatted v1;
Query finished, fetching results ...
+------------------------------+------------------------------+------------+
| name                         | type                         | comment    |
+------------------------------+------------------------------+------------+
| # col_name                   | data_type                    | comment    |
|                              | NULL                         | NULL       |
| x                            | int                          | None       |
| y                            | int                          | None       |
| s                            | string                       | None       |
|                              | NULL                         | NULL       |
| # Detailed Table Information | NULL                         | NULL       |
| Database:                    | views                        | NULL       |
| Owner:                       | doc_demo                     | NULL       |
| CreateTime:                  | Mon Jul 08 15:56:27 EDT 2013 | NULL       |
| LastAccessTime:              | UNKNOWN                      | NULL       |
| Protect Mode:                | None                         | NULL       |
| Retention:                   | 0                            | NULL       |
<strong class="ph b">| Table Type:                  | VIRTUAL_VIEW                 | NULL       |</strong>
| Table Parameters:            | NULL                         | NULL       |
|                              | transient_lastDdlTime        | 1373313387 |
|                              | NULL                         | NULL       |
| # Storage Information        | NULL                         | NULL       |
| SerDe Library:               | null                         | NULL       |
| InputFormat:                 | null                         | NULL       |
| OutputFormat:                | null                         | NULL       |
| Compressed:                  | No                           | NULL       |
| Num Buckets:                 | 0                            | NULL       |
| Bucket Columns:              | []                           | NULL       |
| Sort Columns:                | []                           | NULL       |
|                              | NULL                         | NULL       |
| # View Information           | NULL                         | NULL       |
<strong class="ph b">| View Original Text:          | SELECT * FROM t1             | NULL       |
| View Expanded Text:          | SELECT * FROM t1             | NULL       |</strong>
+------------------------------+------------------------------+------------+
</code></pre>
      </div>

      <div class="note note note_note" id="common__insert_values_warning"><span class="note__title notetitle">Note:</span> 
        The <code class="ph codeph">INSERT ... VALUES</code> technique is not suitable for loading large
        quantities of data into HDFS-based tables, because the insert operations cannot be
        parallelized, and each one produces a separate data file. Use it for setting up small
        dimension tables or tiny amounts of data for experimenting with SQL syntax, or with
        HBase tables. Do not use it for large ETL jobs or benchmark tests for load operations.
        Do not run scripts with thousands of <code class="ph codeph">INSERT ... VALUES</code> statements that
        insert a single row each time. If you do run <code class="ph codeph">INSERT ... VALUES</code>
        operations to load data into a staging table as one stage in an ETL pipeline, include
        multiple row values if possible within each <code class="ph codeph">VALUES</code> clause, and use a
        separate database to make cleanup easier if the operation does produce many tiny files.
      </div>

    </section>

    <section class="section" id="common__hbase_conrefs"><h2 class="title sectiontitle">HBase</h2>

      

      <p class="p">
        HBase-related reusable snippets.
      </p>

      <div class="note note note_note" id="common__invalidate_metadata_hbase"><span class="note__title notetitle">Note:</span> 
        After you create a table in Hive, such as the HBase mapping table in this example, issue
        an <code class="ph codeph">INVALIDATE METADATA <var class="keyword varname">table_name</var></code> statement the next
        time you connect to Impala, make Impala aware of the new table. (Prior to Impala 1.2.4,
        you could not specify the table name if Impala was not aware of the table yet; in Impala
        1.2.4 and higher, specifying the table name avoids reloading the metadata for other
        tables that are not changed.)
      </div>

    </section>

    <section class="section" id="common__intro_conrefs"><h2 class="title sectiontitle">Introduction, Concepts, and Architecture</h2>

      

      <p class="p">
        Snippets from conceptual, architecture, benefits, and feature introduction sections.
        Some of these, particularly around the front matter, were conref'ed in ways that were
        hard to follow. So now we pull individual paragraphs and lists from here, for clarity.
      </p>

      <p class="p" id="common__impala_mission_statement">
        The Apache Impala project provides high-performance, low-latency SQL queries on data
        stored in popular Apache Hadoop file formats. The fast response for queries enables
        interactive exploration and fine-tuning of analytic queries, rather than long batch jobs
        traditionally associated with SQL-on-Hadoop technologies. (You will often see the term
        <span class="q">"interactive"</span> applied to these kinds of fast queries with human-scale response
        times.)
      </p>

      <p class="p" id="common__impala_hive_compatibility">
        Impala integrates with the Apache Hive metastore database, to share databases and tables
        between both components. The high level of integration with Hive, and compatibility with
        the HiveQL syntax, lets you use either Impala or Hive to create tables, issue queries,
        load data, and so on.
      </p>

      <div class="p" id="common__impala_overview_diagram">
        The following graphic illustrates how Impala is positioned in the broader
        <span class="keyword"></span> environment:
        <br><img class="image" src="../images/impala_arch.jpeg" alt="Architecture diagram showing how Impala relates to other Hadoop components such as HDFS, the Hive metastore database, and client programs such as JDBC and ODBC applications and the Hue web UI."><br>
      </div>

      <div class="p" id="common__component_list">
        The Impala solution is composed of the following components:
        <ul class="ul">
          <li class="li">
            Clients - Entities including Hue, ODBC clients, JDBC clients, and the Impala Shell
            can all interact with Impala. These interfaces are typically used to issue queries
            or complete administrative tasks such as connecting to Impala.
          </li>

          <li class="li">
            Hive Metastore - Stores information about the data available to Impala. For example,
            the metastore lets Impala know what databases are available and what the structure
            of those databases is. As you create, drop, and alter schema objects, load data into
            tables, and so on through Impala SQL statements, the relevant metadata changes are
            automatically broadcast to all Impala nodes by the dedicated catalog service
            introduced in Impala 1.2.
          </li>

          <li class="li">
            Impala - This process, which runs on DataNodes, coordinates and executes queries.
            Each instance of Impala can receive, plan, and coordinate queries from Impala
            clients. Queries are distributed among Impala nodes, and these nodes then act as
            workers, executing parallel query fragments.
          </li>

          <li class="li">
            HBase and HDFS - Storage for data to be queried.
          </li>
        </ul>
      </div>

      <div class="p" id="common__query_overview">
        Queries executed using Impala are handled as follows:
        <ol class="ol">
          <li class="li">
            User applications send SQL queries to Impala through ODBC or JDBC, which provide
            standardized querying interfaces. The user application may connect to any
            <code class="ph codeph">impalad</code> in the cluster. This <code class="ph codeph">impalad</code> becomes the
            coordinator for the query.
          </li>

          <li class="li">
            Impala parses the query and analyzes it to determine what tasks need to be performed
            by <code class="ph codeph">impalad</code> instances across the cluster. Execution is planned for
            optimal efficiency.
          </li>

          <li class="li">
            Services such as HDFS and HBase are accessed by local <code class="ph codeph">impalad</code>
            instances to provide data.
          </li>

          <li class="li">
            Each <code class="ph codeph">impalad</code> returns data to the coordinating
            <code class="ph codeph">impalad</code>, which sends these results to the client.
          </li>
        </ol>
      </div>

      <div class="p" id="common__skip_header_lines">
        In <span class="keyword">Impala 2.6</span> and higher, Impala can optionally skip an arbitrary
        number of header lines from text input files on HDFS based on the
        <code class="ph codeph">skip.header.line.count</code> value in the <code class="ph codeph">TBLPROPERTIES</code>
        field of the table metadata. For example:
<pre class="pre codeblock"><code>create table header_line(first_name string, age int)
  row format delimited fields terminated by ',';

-- Back in the shell, load data into the table with commands such as:
-- cat &gt;data.csv
-- Name,Age
-- Alice,25
-- Bob,19
-- hdfs dfs -put data.csv /user/hive/warehouse/header_line

refresh header_line;

-- Initially, the Name,Age header line is treated as a row of the table.
select * from header_line limit 10;
+------------+------+
| first_name | age  |
+------------+------+
| Name       | NULL |
| Alice      | 25   |
| Bob        | 19   |
+------------+------+

alter table header_line set tblproperties('skip.header.line.count'='1');

-- Once the table property is set, queries skip the specified number of lines
-- at the beginning of each text data file. Therefore, all the files in the table
-- should follow the same convention for header lines.
select * from header_line limit 10;
+------------+-----+
| first_name | age |
+------------+-----+
| Alice      | 25  |
| Bob        | 19  |
+------------+-----+
</code></pre>
      </div>



      <div class="p" id="common__feature_list">
        Impala provides support for:
        <ul class="ul">
          <li class="li">
            Most common SQL-92 features of Hive Query Language (HiveQL) including
            <a class="xref" href="../topics/impala_select.html#select">SELECT</a>,
            <a class="xref" href="../topics/impala_joins.html#joins">joins</a>, and
            <a class="xref" href="../topics/impala_aggregate_functions.html#aggregate_functions">aggregate
            functions</a>.
          </li>

          <li class="li">
            HDFS, HBase, <span class="ph">and Amazon Simple Storage System (S3)</span> storage,
            including:
            <ul class="ul">
              <li class="li">
                <a class="xref" href="../topics/impala_file_formats.html#file_formats">HDFS file
                formats</a>: delimited text files, Parquet, Avro, SequenceFile, and RCFile.
              </li>

              <li class="li">
                Compression codecs: Snappy, GZIP, Deflate, BZIP.
              </li>
            </ul>
          </li>

          <li class="li">
            Common data access interfaces including:
            <ul class="ul">
              <li class="li">
                <a class="xref" href="../topics/impala_jdbc.html#impala_jdbc">JDBC driver</a>.
              </li>

              <li class="li">
                <a class="xref" href="../topics/impala_odbc.html#impala_odbc">ODBC driver</a>.
              </li>

              <li class="li">
                Hue Beeswax and the Impala Query UI.
              </li>
            </ul>
          </li>

          <li class="li">
            <a class="xref" href="../topics/impala_impala_shell.html#impala_shell">impala-shell
            command-line interface</a>.
          </li>

          <li class="li">
            <a class="xref" href="../topics/impala_security.html#security">Kerberos authentication</a>.
          </li>
        </ul>
      </div>

      <div class="p" id="common__load_catalog_in_background">
        Use <code class="ph codeph">‑‑load_catalog_in_background</code> option to control when the
        metadata of a table is loaded.
        <ul class="ul">
          <li class="li">
            If set to <code class="ph codeph">false</code>, the metadata of a table is loaded when it is
            referenced for the first time. This means that the first run of a particular query
            can be slower than subsequent runs. Starting in Impala 2.2, the default for
            <code class="ph codeph">‑‑load_catalog_in_background</code> is <code class="ph codeph">false</code>.
          </li>

          <li class="li">
            If set to <code class="ph codeph">true</code>, the catalog service attempts to load metadata for a
            table even if no query needed that metadata. So metadata will possibly be already
            loaded when the first query that would need it is run. However, for the following
            reasons, we recommend not to set the option to <code class="ph codeph">true</code>.
            <ul class="ul">
              <li class="li">
                Background load can interfere with query-specific metadata loading. This can
                happen on startup or after invalidating metadata, with a duration depending on
                the amount of metadata, and can lead to a seemingly random long running queries
                that are difficult to diagnose.
              </li>

              <li class="li">
                Impala may load metadata for tables that are possibly never used, potentially
                increasing catalog size and consequently memory usage for both catalog service
                and Impala Daemon.
              </li>
            </ul>
          </li>
        </ul>
      </div>

      <ul class="ul" id="common__catalogd_xrefs">
        <li class="li">
          <p class="p">
            See <a class="xref" href="../topics/impala_install.html#install">Installing Impala</a>,
            <a class="xref" href="../topics/impala_upgrading.html#upgrading">Upgrading Impala</a> and
            <a class="xref" href="../topics/impala_processes.html#processes">Starting Impala</a>, for usage information for
            the <span class="keyword cmdname">catalogd</span> daemon.
          </p>
        </li>

        <li class="li">
          <p class="p">
            The <code class="ph codeph">REFRESH</code> and <code class="ph codeph">INVALIDATE METADATA</code> statements are
            no longer needed when the <code class="ph codeph">CREATE TABLE</code>, <code class="ph codeph">INSERT</code>, or
            other table-changing or data-changing operation is performed through Impala. These
            statements are still needed if such operations are done through Hive or by
            manipulating data files directly in HDFS, but in those cases the statements only
            need to be issued on one Impala node rather than on all nodes. See
            <a class="xref" href="../topics/impala_refresh.html#refresh">REFRESH Statement</a> and
            <a class="xref" href="../topics/impala_invalidate_metadata.html#invalidate_metadata">INVALIDATE METADATA Statement</a> for the
            latest usage information for those statements.
          </p>
        </li>

        <li class="li">
          <p class="p">
            See <a class="xref" href="../topics/impala_components.html#intro_catalogd">The Impala Catalog Service</a> for background
            information on the <span class="keyword cmdname">catalogd</span> service.
          </p>
        </li>
      </ul>

    </section>

    <section class="section" id="common__install_conrefs"><h2 class="title sectiontitle">Installation</h2>

      

      <p class="p">
        Snippets related to installation, upgrading, prerequisites.
      </p>

      <div class="note note note_note" id="common__core_dump_considerations"><span class="note__title notetitle">Note:</span> 
        <ul class="ul">
          <li class="li">
            <p class="p">
              The location of core dump files may vary according to your operating system
              configuration.
            </p>
          </li>

          <li class="li">
            <p class="p">
              Other security settings may prevent Impala from writing core dumps even when this
              option is enabled.
            </p>
          </li>
        </ul>
      </div>

      <p class="p" id="common__cpu_prereq">
        The prerequisite for CPU architecture has been relaxed in Impala 2.2.0 and higher. From
        this release onward, Impala works on CPUs that have the SSSE3 instruction set. The SSE4
        instruction set is no longer required. This relaxed requirement simplifies the upgrade
        planning from Impala 1.x releases, which also worked on SSSE3-enabled processors.
      </p>

      <div class="p" id="common__rhel5_kerberos">
        On version 5 of Red Hat Enterprise Linux and comparable distributions, some additional
        setup is needed for the <span class="keyword cmdname">impala-shell</span> interpreter to connect to a
        Kerberos-enabled Impala cluster:
<pre class="pre codeblock"><code>sudo yum install python-devel openssl-devel python-pip
sudo pip-python install ssl</code></pre>
      </div>

      <div class="note warning note_warning" id="common__impala_kerberos_ssl_caveat"><span class="note__title warningtitle">Warning:</span> 
        In <span class="keyword"> Impala 2.3.1</span> and lower versions, you could
        enable Kerberos authentication between Impala internal components, or SSL encryption
        between Impala internal components, but not both at the same time. This restriction has
        now been lifted. See <a class="xref" href="https://issues.apache.org/jira/browse/IMPALA-2598" target="_blank">IMPALA-2598</a> to see the
        maintenance releases for different levels of Impala where the fix has been published.
      </div>

      <p class="p" id="common__hive_jdbc_ssl_kerberos_caveat">
        Prior to <span class="keyword">Impala 2.5</span>, the Hive JDBC driver did not support
        connections that use both Kerberos authentication and SSL encryption. If your cluster is
        running an older release that has this restriction, use an alternative JDBC driver that
        supports both of these security features.
      </p>

    </section>

    <section class="section" id="common__performance_conrefs"><h2 class="title sectiontitle">Performance</h2>

      

      <p class="p">
        Snippets from performance configuration, tuning, and so on.
      </p>

      <p class="p" id="common__cookbook_blurb">
        A good source of tips related to scalability and performance tuning is the
        <a class="xref" href="http://www.slideshare.net/cloudera/the-impala-cookbook-42530186" target="_blank">Impala
        Cookbook</a> presentation. These slides are updated periodically as new features come
        out and new benchmarks are performed.
      </p>

      <ul class="ul">
        <li class="li" id="common__copy_config_files">
          Copy the client <code class="ph codeph">core-site.xml</code> and <code class="ph codeph">hdfs-site.xml</code>
          configuration files from the Hadoop configuration directory to the Impala
          configuration directory. The default Impala configuration location is
          <code class="ph codeph">/etc/impala/conf</code>.
        </li>

        <li class="li" id="common__restart_all_datanodes">
          After applying these changes, restart all DataNodes.
        </li>
      </ul>

      <div class="note note note_note" id="common__compute_stats_parquet"><span class="note__title notetitle">Note:</span> 
        Currently, a known issue (<a class="xref" href="https://issues.apache.org/jira/browse/IMPALA-488" target="_blank">IMPALA-488</a>) could cause
        excessive memory usage during a <code class="ph codeph">COMPUTE STATS</code> operation on a Parquet
        table. As a workaround, issue the command <code class="ph codeph">SET NUM_SCANNER_THREADS=2</code> in
        <span class="keyword cmdname">impala-shell</span> before issuing the <code class="ph codeph">COMPUTE STATS</code>
        statement. Then issue <code class="ph codeph">UNSET NUM_SCANNER_THREADS</code> before continuing with
        queries.
      </div>

    </section>

    <section class="section" id="common__admin_conrefs"><h2 class="title sectiontitle">Administration</h2>

      

      <p class="p" id="common__statestored_catalogd_ha_blurb">
        Most considerations for load balancing and high availability apply to the
        <span class="keyword cmdname">impalad</span> daemon. The <span class="keyword cmdname">statestored</span> and
        <span class="keyword cmdname">catalogd</span> daemons do not have special requirements for high
        availability, because problems with those daemons do not result in data loss. If those
        daemons become unavailable due to an outage on a particular host, you can stop the
        Impala service, delete the <span class="ph uicontrol">Impala StateStore</span> and
        <span class="ph uicontrol">Impala Catalog Server</span> roles, add the roles on a different host,
        and restart the Impala service.
      </p>

      <p class="p" id="common__hdfs_caching_encryption_caveat">
        Due to a limitation of HDFS, zero-copy reads are not supported with encryption. Where
        practical, avoid HDFS caching for Impala data files in encryption zones. The queries
        fall back to the normal read path during query execution, which might cause some
        performance overhead.
      </p>

      <div class="note note note_note" id="common__impala_llama_obsolete"><span class="note__title notetitle">Note:</span> 
        <p class="p">
          The use of the Llama component for integrated resource management within YARN is no
          longer supported with <span class="keyword">Impala 2.3</span> and higher. The Llama support
          code is removed entirely in <span class="keyword">Impala 2.8</span> and higher.
        </p>

        <p class="p">
          For clusters running Impala alongside other data management components, you define
          static service pools to define the resources available to Impala and other components.
          Then within the area allocated for Impala, you can create dynamic service pools, each
          with its own settings for the Impala admission control feature.
        </p>
      </div>



      <div class="note note note_note" id="common__max_memory_default_limit_caveat"><span class="note__title notetitle">Note:</span> 
        If you specify Max Memory for an Impala dynamic resource pool, you must also specify the
        Default Query Memory Limit. Max Memory relies on the Default Query Memory Limit to
        produce a reliable estimate of overall memory consumption for a query.
      </div>

      <div class="p" id="common__admission_control_mem_limit_interaction">
        For example, consider the following scenario:
        <ul class="ul">
          <li class="li">
            The cluster is running <code class="ph codeph">impalad</code> daemons on five hosts.
          </li>

          <li class="li">
            A dynamic resource pool has Max Memory set to 100 GB.
          </li>

          <li class="li">
            The Maximum Query Memory Limit for the pool is 10 GB and Minimum Query Memory Limit
            is 2 GB. Therefore, any query running in this pool could use up to 50 GB of memory
            (Maximum Query Memory Limit * number of Impala nodes).
          </li>

          <li class="li">
            Impala will execute varying numbers of queries concurrently because queries may be
            given memory limits anywhere between 2 GB and 10 GB, depending on the estimated
            memory requirements. For example, Impala may execute up to 10 small queries with 2
            GB memory limits or two large queries with 10 GB memory limits because that is what
            will fit in the 100 GB cluster-wide limit when executing on five hosts.
          </li>

          <li class="li">
            The executing queries may use less memory than the per-host memory limit or the Max
            Memory cluster-wide limit if they do not need that much memory. In general this is
            not a problem so long as you are able to execute enough queries concurrently to meet
            your needs.
          </li>
        </ul>
      </div>

      <p class="p" id="common__ignore_file_extensions">
        Impala queries ignore files with extensions commonly used for temporary work files by
        Hadoop tools. Any files with extensions <code class="ph codeph">.tmp</code> or
        <code class="ph codeph">.copying</code> are not considered part of the Impala table. The suffix
        matching is case-insensitive, so for example Impala ignores both
        <code class="ph codeph">.copying</code> and <code class="ph codeph">.COPYING</code> suffixes.
      </p>

      <div class="note note note_note" id="common__proxy_jdbc_caveat"><span class="note__title notetitle">Note:</span> 
        If your JDBC or ODBC application connects to Impala through a load balancer such as
        <code class="ph codeph">haproxy</code>, be cautious about reusing the connections. If the load
        balancer has set up connection timeout values, either check the connection frequently so
        that it never sits idle longer than the load balancer timeout value, or check the
        connection validity before using it and create a new one if the connection has been
        closed.
      </div>

    </section>

    <section class="section" id="common__upstream_conrefs"><h2 class="title sectiontitle">Upstream Cleanup</h2>

      

      <p class="p">
        Snippets related to upstream cleanup work, for example phrase tags that are
        conditionalized in or out of 'integrated' and 'standalone' conditions to provide extra
        context for links that don't work in certain PDF contexts.
      </p>

      <p class="p" id="common__impala231_noop">
        The version of Impala that is included with <span class="keyword">Impala 2.3.1</span> is identical
        to <span class="keyword">Impala 2.3.0</span>. There are no new bug fixes, new features, or
        incompatible changes.
      </p>



      <div class="note note note_note" id="common__admission_compute_stats"><span class="note__title notetitle">Note:</span> 
        Impala relies on the statistics produced by the <code class="ph codeph">COMPUTE STATS</code> statement
        to estimate memory usage for each query. See
        <a class="xref" href="../topics/impala_compute_stats.html#compute_stats">COMPUTE STATS Statement</a> for guidelines about how
        and when to use this statement.
      </div>

    </section>

    <section class="section" id="common__shell_conrefs"><h2 class="title sectiontitle">impala-shell</h2>

      

      <p class="p">
        These reusable snippets are for the <span class="keyword cmdname">impala-shell</span> command and related
        material such as query options.
      </p>

      <p class="p" id="common__num_nodes_tip">
        You might set the <code class="ph codeph">NUM_NODES</code> option to 1 briefly, during
        <code class="ph codeph">INSERT</code> or <code class="ph codeph">CREATE TABLE AS SELECT</code> statements. Normally,
        those statements produce one or more data files per data node. If the write operation
        involves small amounts of data, a Parquet table, and/or a partitioned table, the default
        behavior could produce many small files when intuitively you might expect only a single
        output file. <code class="ph codeph">SET NUM_NODES=1</code> turns off the <span class="q">"distributed"</span> aspect of
        the write operation, making it more likely to produce only one or a few data files.
      </p>

      <div class="note note note_note" id="common__timeout_clock_blurb"><span class="note__title notetitle">Note:</span> 
        <p class="p">
          The timeout clock for queries and sessions only starts ticking when the query or
          session is idle.
        </p>

        <p class="p">
          For queries, this means the query has results ready but is waiting for a client to
          fetch the data. A query can run for an arbitrary time without triggering a timeout,
          because the query is computing results rather than sitting idle waiting for the
          results to be fetched. The timeout period is intended to prevent unclosed queries from
          consuming resources and taking up slots in the admission count of running queries,
          potentially preventing other queries from starting.
        </p>

        <p class="p">
          For sessions, this means that no query has been submitted for some period of time.
        </p>
      </div>

      <p class="p" id="common__obwl_query_options">
        Now that the <code class="ph codeph">ORDER BY</code> clause no longer requires an accompanying
        <code class="ph codeph">LIMIT</code> clause in Impala 1.4.0 and higher, this query option is
        deprecated and has no effect.
      </p>

    </section>

    <section class="section" id="common__relnotes"><h2 class="title sectiontitle">Release Notes</h2>

      

      <p class="p">
        These are notes associated with a particular JIRA issue. They typically will be
        conref'ed both in the release notes and someplace in the main body as a limitation or
        warning or similar.
      </p>

      <div class="p" id="common__IMPALA-3662">
        The initial release of <span class="keyword">Impala 2.5</span> sometimes has a higher peak
        memory usage than in previous releases while reading Parquet files. The following query
        options might help to reduce memory consumption in the Parquet scanner:
        <ul class="ul">
          <li class="li">
            Reduce the number of scanner threads, for example: <code class="ph codeph">set
            num_scanner_threads=30</code>
          </li>

          <li class="li">
            Reduce the batch size, for example: <code class="ph codeph">set batch_size=512</code>
          </li>

          <li class="li">
            Increase the memory limit, for example: <code class="ph codeph">set mem_limit=64g</code>
          </li>
        </ul>
        You can track the status of the fix for this issue at
        <a class="xref" href="https://issues.apache.org/jira/browse/IMPALA-3662" target="_blank">IMPALA-3662</a>.
      </div>

      <div class="p" id="common__increase_catalogd_heap_size">
        For schemas with large numbers of tables, partitions, and data files, the
        <span class="keyword cmdname">catalogd</span> daemon might encounter an out-of-memory error. To increase
        the memory limit for the <span class="keyword cmdname">catalogd</span> daemon:
        <ol class="ol">
          <li class="li">
            <p class="p">
              Check current memory usage for the <span class="keyword cmdname">catalogd</span> daemon by running
              the following commands on the host where that daemon runs on your cluster:
            </p>
<pre class="pre codeblock"><code>
  jcmd <var class="keyword varname">catalogd_pid</var> VM.flags
  jmap -heap <var class="keyword varname">catalogd_pid</var>
  </code></pre>
          </li>

          <li class="li">
            <p class="p">
              Decide on a large enough value for the <span class="keyword cmdname">catalogd</span> heap. You use
              the <code class="ph codeph">JAVA_TOOL_OPTIONS</code> environment variable to set the maximum
              heap size. For example, the following environment variable setting specifies the
              maximum heap size of 8 GB.
            </p>
<pre class="pre codeblock"><code>
  JAVA_TOOL_OPTIONS="-Xmx8g"
  </code></pre>
          </li>

          <li class="li">
            <p class="p">
              On systems not using cluster management software, put this environment variable
              setting into the startup script for the <span class="keyword cmdname">catalogd</span> daemon, then
              restart the <span class="keyword cmdname">catalogd</span> daemon.
            </p>
          </li>

          <li class="li">
            <p class="p">
              Use the same <span class="keyword cmdname">jcmd</span> and <span class="keyword cmdname">jmap</span> commands as
              earlier to verify that the new settings are in effect.
            </p>
          </li>
        </ol>
      </div>

    </section>

    <section class="section" id="common__kudu_common"><h2 class="title sectiontitle">Kudu</h2>

      

      <p class="p">
        Kudu-related content. This category gets its own special area because there could be
        considerations around sharing content between the Impala documentation and the Kudu
        documentation.
      </p>

      <p class="p" id="common__kudu_blurb">
        <strong class="ph b">Kudu considerations:</strong>
      </p>

      <p class="p" id="common__kudu_no_load_data">
        The <code class="ph codeph">LOAD DATA</code> statement cannot be used with Kudu tables.
      </p>

      <p class="p" id="common__kudu_no_truncate_table">
        Currently, the <code class="ph codeph">TRUNCATE TABLE</code> statement cannot be used with Kudu
        tables.
      </p>

      <p class="p" id="common__kudu_no_insert_overwrite">
        Currently, the <code class="ph codeph">INSERT OVERWRITE</code> syntax cannot be used with Kudu tables.
      </p>

      <p class="p" id="common__kudu_unsupported_data_type"> Currently, the data types
        <code class="ph codeph">CHAR</code>, <code class="ph codeph">ARRAY</code>, <code class="ph codeph">MAP</code>, and
          <code class="ph codeph">STRUCT</code> cannot be used with Kudu tables.
      </p>

      <p class="p" id="common__kudu_non_pk_data_type">
        Currently, the data types <code class="ph codeph">BOOLEAN</code>, <code class="ph codeph">FLOAT</code>, and
        <code class="ph codeph">DOUBLE</code> cannot be used for primary key columns in Kudu tables.
      </p>

      <p class="p" id="common__pk_implies_not_null">
        Because all of the primary key columns must have non-null values, specifying a column in
        the <code class="ph codeph">PRIMARY KEY</code> clause implicitly adds the <code class="ph codeph">NOT NULL</code>
        attribute to that column.
      </p>

      <p class="p" id="common__kudu_metadata_intro">By default, much of the metadata
        for Kudu tables is handled by the underlying storage layer. Kudu tables
        have less reliance on the Metastore database, and require less metadata
        caching on the Impala side. For example, information about partitions in
        Kudu tables is managed by Kudu, and Impala does not cache any block
        locality metadata for Kudu tables. If the Kudu service is not integrated
        with the Hive Metastore, Impala will manage Kudu table metadata in the
        Hive Metastore.</p>

      <p class="p" id="common__kudu_metadata_details">
        The <code class="ph codeph">REFRESH</code> and <code class="ph codeph">INVALIDATE METADATA</code> statements are
        needed less frequently for Kudu tables than for HDFS-backed tables. Neither statement is
        needed when data is added to, removed, or updated in a Kudu table, even if the changes
        are made directly to Kudu through a client program using the Kudu API. Run
        <code class="ph codeph">REFRESH <var class="keyword varname">table_name</var></code> or <code class="ph codeph">INVALIDATE METADATA
        <var class="keyword varname">table_name</var></code> for a Kudu table only after making a change to
        the Kudu table schema, such as adding or dropping a column.
      </p>

      <div class="p" id="common__kudu_internal_external_tables"> If the Kudu service is not
        integrated with the Hive Metastore, the distinction between internal and
        external tables has some special details for Kudu tables. Tables created
        entirely through Impala are internal tables. The table name as
        represented within Kudu includes notation such as an
          <code class="ph codeph">impala::</code> prefix and the Impala database name.
        External Kudu tables are those created by a non-Impala mechanism, such
        as a user application calling the Kudu APIs. For these tables, the
          <code class="ph codeph">CREATE EXTERNAL TABLE</code> syntax lets you establish a
        mapping from Impala to the existing Kudu table:
        <pre class="pre codeblock"><code>
CREATE EXTERNAL TABLE impala_name STORED AS KUDU
  TBLPROPERTIES('kudu.table_name' = 'original_kudu_name');
</code></pre>
        External Kudu tables differ in one important way from other external
        tables: adding or dropping a column or range partition changes the data
        in the underlying Kudu table, in contrast to an HDFS-backed external
        table where existing data files are left untouched.</div>

      <div class="p" id="common__kudu_sentry_limitations"> Access to Kudu tables must be granted to
        and revoked from principal with the following considerations: <ul class="ul">
          <li class="li"> Only users with the <code class="ph codeph">ALL</code> privilege on <code class="ph codeph">SERVER</code> can
            create external Kudu tables. </li>
          <li class="li"> The <code class="ph codeph">ALL</code> privileges on <code class="ph codeph">SERVER</code> is required to specify
            the <code class="ph codeph">kudu.master_addresses</code> property in the <code class="ph codeph">CREATE TABLE</code>
            statements for managed tables as well as external tables. </li>
          <li class="li"> Access to Kudu tables is enforced at the table level and at the column level. </li>
          <li class="li"> The <code class="ph codeph">SELECT</code>- and <code class="ph codeph">INSERT</code>-specific permissions are
            supported. </li>
          <li class="li"> The <code class="ph codeph">DELETE</code>, <code class="ph codeph">UPDATE</code>, and <code class="ph codeph">UPSERT</code>
            operations require the <code class="ph codeph">ALL</code> privilege. </li>
        </ul></div>

      <p class="p" id="common__kudu_timestamp_nanoseconds_caveat">
        The nanosecond portion of an Impala <code class="ph codeph">TIMESTAMP</code> value is rounded to the
        nearest microsecond when that value is stored in a Kudu table.
      </p>

      <div class="p" id="common__kudu_timestamp_details">
        In <span class="keyword">Impala 2.9</span> and higher, you can include
        <code class="ph codeph">TIMESTAMP</code> columns in Kudu tables, instead of representing the date and
        time as a <code class="ph codeph">BIGINT</code> value. The behavior of <code class="ph codeph">TIMESTAMP</code> for
        Kudu tables has some special considerations:
        <ul class="ul">
          <li class="li">
            <p class="p">
              Any nanoseconds in the original 96-bit value produced by Impala are not stored,
              because Kudu represents date/time columns using 64-bit values. The nanosecond
              portion of the value is rounded, not truncated. Therefore, a
              <code class="ph codeph">TIMESTAMP</code> value that you store in a Kudu table might not be
              bit-for-bit identical to the value returned by a query.
            </p>
          </li>

          <li class="li">
            <p class="p">
              The conversion between the Impala 96-bit representation and the Kudu 64-bit
              representation introduces some performance overhead when reading or writing
              <code class="ph codeph">TIMESTAMP</code> columns. You can minimize the overhead during writes by
              performing inserts through the Kudu API. Because the overhead during reads applies
              to each query, you might continue to use a <code class="ph codeph">BIGINT</code> column to
              represent date/time values in performance-critical applications.
            </p>
          </li>

          <li class="li">
            <p class="p">
              The Impala <code class="ph codeph">TIMESTAMP</code> type has a narrower range for years than the
              underlying Kudu data type. Impala can represent years 1400-9999. If year values
              outside this range are written to a Kudu table by a non-Impala client, Impala
              returns <code class="ph codeph">NULL</code> by default when reading those
              <code class="ph codeph">TIMESTAMP</code> values during a query. Or, if the
              <code class="ph codeph">ABORT_ON_ERROR</code> query option is enabled, the query fails when it
              encounters a value with an out-of-range year.
            </p>
          </li>
        </ul>
      </div>

      <p class="p" id="common__kudu_hints">
        Starting from <span class="keyword">Impala 2.9</span>, the <code class="ph codeph">INSERT</code> or
        <code class="ph codeph">UPSERT</code> operations into Kudu tables automatically add an exchange and a
        sort node to the plan that partitions and sorts the rows according to the
        partitioning/primary key scheme of the target table (unless the number of rows to be
        inserted is small enough to trigger single node execution). Since Kudu partitions and
        sorts rows on write, pre-partitioning and sorting takes some of the load off of Kudu and
        helps large <code class="ph codeph">INSERT</code> operations to complete without timing out. However,
        this default behavior may slow down the end-to-end performance of the
        <code class="ph codeph">INSERT</code> or <code class="ph codeph">UPSERT</code> operations. Starting
        from<span class="keyword">Impala 2.10</span>, you can use the<code class="ph codeph"> /*
        +NOCLUSTERED */</code> and <code class="ph codeph">/* +NOSHUFFLE */</code> hints together to disable
        partitioning and sorting before the rows are sent to Kudu. Additionally, since sorting
        may consume a large amount of memory, consider setting the <code class="ph codeph">MEM_LIMIT</code>
        query option for those queries.
      </p>

    </section>

  </div>

</article></main></body></html>