<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="copyright" content="(C) Copyright 2024"><meta name="DC.rights.owner" content="(C) Copyright 2024"><meta name="DC.Type" content="concept"><meta name="prodname" content="Impala"><meta name="version" content="Impala 3.4.x"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="impala_iceberg"><link rel="stylesheet" type="text/css" href="../css/commonltr.css"><link rel="stylesheet" type="text/css" href="../css/dita-ot-doc.css"><title>Using Impala with Iceberg Tables</title></head><body id="impala_iceberg"><header role="banner"><!--
The DITA Open Toolkit is licensed for use under the the Apache
Software Foundation License v2.0.

A copy of the Apache Software Foundation License 2.0 is
available at http://opensource.org/licenses/apache2.0.php

This statement must be included in any copies of DITA Open
Toolkit code.
--><div class="header">
  <p>Apache Impala</p>
  <hr>
</div></header><nav role="toc"><ul><li><a href="../topics/impala_intro.html">Introducing Apache Impala</a></li><li><a href="../topics/impala_concepts.html">Concepts and Architecture</a></li><li><a href="../topics/impala_planning.html">Deployment Planning</a></li><li><a href="../topics/impala_install.html">Installing Impala</a></li><li><a href="../topics/impala_config.html">Managing Impala</a></li><li><a href="../topics/impala_upgrading.html">Upgrading Impala</a></li><li><a href="../topics/impala_processes.html">Starting Impala</a></li><li><a href="../topics/impala_tutorial.html">Tutorials</a></li><li><a href="../topics/impala_admin.html">Administration</a></li><li><a href="../topics/impala_security.html">Impala Security</a></li><li><a href="../topics/impala_langref.html">SQL Reference</a></li><li><a href="../topics/impala_performance.html">Performance Tuning</a></li><li><a href="../topics/impala_scalability.html">Scalability Considerations</a></li><li><a href="../topics/impala_resource_management.html">Resource Management</a></li><li><a href="../topics/impala_partitioning.html">Partitioning</a></li><li><a href="../topics/impala_file_formats.html">File Formats</a></li><li><a href="../topics/impala_kudu.html">Using Impala to Query Kudu Tables</a></li><li><a href="../topics/impala_hbase.html">HBase Tables</a></li><li class="active"><a href="../topics/impala_iceberg.html">Iceberg Tables</a></li><li><a href="../topics/impala_s3.html">S3 Tables</a></li><li><a href="../topics/impala_adls.html">ADLS Tables</a></li><li><a href="../topics/impala_isilon.html">Isilon Storage</a></li><li><a href="../topics/impala_ozone.html">Ozone Storage</a></li><li><a href="../topics/impala_logging.html">Logging</a></li><li><a href="../topics/impala_client.html">Client Access</a></li><li><a href="../topics/impala_fault_tolerance.html">Fault Tolerance</a></li><li><a href="../topics/impala_troubleshooting.html">Troubleshooting Impala</a></li><li><a href="../topics/impala_ports.html">Ports Used by Impala</a></li><li><a href="../topics/impala_reserved_words.html">Impala Reserved Words</a></li><li><a href="../topics/impala_faq.html">Impala Frequently Asked Questions</a></li><li><a href="../topics/impala_release_notes.html">Impala Release Notes</a></li></ul></nav><main role="main"><article role="article" aria-labelledby="impala_iceberg__iceberg">

  <h1 class="title topictitle1" id="impala_iceberg__iceberg">Using Impala with Iceberg Tables</h1>
  
  

  <div class="body conbody">

    <p class="p">
      
      Impala now supports Apache Iceberg which is an open table format for huge analytic datasets.
      With this functionality, you can access any existing Iceberg tables using SQL and perform
      analytics over them. Using Impala you can create and write Iceberg tables in different
      Iceberg Catalogs (e.g. HiveCatalog, HadoopCatalog). It also supports location-based
      tables (HadoopTables).
    </p>

    <p class="p">
      For more information on Iceberg, see <a class="xref" href="https://iceberg.apache.org" target="_blank">the Apache Iceberg site</a>.
    </p>

    <p class="p toc inpage"></p>
  </div>

  <article class="topic concept nested1" aria-labelledby="ariaid-title2" id="impala_iceberg__iceberg_features">
    <h2 class="title topictitle2" id="ariaid-title2">Overview of Iceberg features</h2>
  
  <div class="body conbody">
    <ul class="ul">
      <li class="li">
        ACID compliance: DML operations are atomic, queries always read a consistent snapshot.
      </li>
      <li class="li">
        Hidden partitioning: Iceberg produces partition values by taking a column value and
        optionally transforming it. Partition information is stored in the Iceberg metadata
        files. Iceberg is able to TRUNCATE column values or calculate
        a hash of them and use it for partitioning. Readers don't need to be aware of the
        partitioning of the table.
      </li>
      <li class="li">
        Partition layout evolution: When the data volume or the query patterns change you
        can update the layout of a table. Since hidden partitioning is used, you don't need to
        rewrite the data files during partition layout evolution.
      </li>
      <li class="li">
        Schema evolution: supports add, drop, update, or rename schema elements,
        and has no side-effects.
      </li>
      <li class="li">
        Time travel: enables reproducible queries that use exactly the same table
        snapshot, or lets users easily examine changes.
      </li>
      <li class="li">
        Cloning Iceberg tables: create an empty Iceberg table based on the definition of
        another Iceberg table.
      </li>
    </ul>
  </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title3" id="impala_iceberg__iceberg_create">

    <h2 class="title topictitle2" id="ariaid-title3">Creating Iceberg tables with Impala</h2>
  

    <div class="body conbody">
      <p class="p">
        When you have an existing Iceberg table that is not yet present in the Hive Metastore,
        you can use the <code class="ph codeph">CREATE EXTERNAL TABLE</code> command in Impala to add the table to the Hive
        Metastore and make Impala able to interact with this table. Currently Impala supports
        HadoopTables, HadoopCatalog, and HiveCatalog. If you have an existing table in HiveCatalog,
        and you are using the same Hive Metastore, you need no further actions.
      </p>
      <ul class="ul">
        <li class="li">
          <strong class="ph b">HadoopTables</strong>. When the table already exists in a HadoopTable it means there is
          a location on the file system that contains your table. Use the following command
          to add this table to Impala's catalog:
          <pre class="pre codeblock"><code>
CREATE EXTERNAL TABLE ice_hadoop_tbl
STORED AS ICEBERG
LOCATION '/path/to/table'
TBLPROPERTIES('iceberg.catalog'='hadoop.tables');
          </code></pre>
        </li>
        <li class="li">
          <strong class="ph b">HadoopCatalog</strong>. A table in HadoopCatalog means that there is a catalog location
          in the file system under which Iceberg tables are stored. Use the following command
          to add a table in a HadoopCatalog to Impala:
          <pre class="pre codeblock"><code>
CREATE EXTERNAL TABLE ice_hadoop_cat
STORED AS ICEBERG
TBLPROPERTIES('iceberg.catalog'='hadoop.catalog',
              'iceberg.catalog_location'='/path/to/catalog',
              'iceberg.table_identifier'='namespace.table');
          </code></pre>
        </li>
        <li class="li">
          Alternatively, you can also use custom catalogs to use existing tables. It means you need to define
          your catalog in hive-site.xml.
          The advantage of this method is that other engines are more likely to be able to interact with this table.
          Please note that the automatic metadata update will not work for these tables, you will have to manually
          call REFRESH on the table when it changes outside Impala.
          To globally register different catalogs, set the following Hadoop configurations:
          <table class="table" id="iceberg_create__iceberg_custom_catalogs"><caption></caption><colgroup><col><col></colgroup><thead class="thead">
                <tr class="row">
                  <th class="entry cellrowborder colsep-1 rowsep-1" id="iceberg_create__iceberg_custom_catalogs__entry__1">Config Key</th>
                  <th class="entry cellrowborder colsep-1 rowsep-1" id="iceberg_create__iceberg_custom_catalogs__entry__2">Description</th>
                </tr>
              </thead><tbody class="tbody">
                <tr class="row">
                  <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_create__iceberg_custom_catalogs__entry__1 ">iceberg.catalog.&lt;catalog_name&gt;.type</td>
                  <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_create__iceberg_custom_catalogs__entry__2 ">type of catalog: hive, hadoop, or left unset if using a custom catalog</td>
                </tr>
                <tr class="row">
                  <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_create__iceberg_custom_catalogs__entry__1 ">iceberg.catalog.&lt;catalog_name&gt;.catalog-impl</td>
                  <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_create__iceberg_custom_catalogs__entry__2 ">catalog implementation, must not be null if type is empty</td>
                </tr>
                <tr class="row">
                  <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_create__iceberg_custom_catalogs__entry__1 ">iceberg.catalog.&lt;catalog_name&gt;.&lt;key&gt;</td>
                  <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_create__iceberg_custom_catalogs__entry__2 ">any config key and value pairs for the catalog</td>
                </tr>
              </tbody></table>
          <div class="p">
            For example, to register a HadoopCatalog called 'hadoop', set the following properties in hive-site.xml:
            <pre class="pre codeblock"><code>
iceberg.catalog.hadoop.type=hadoop;
iceberg.catalog.hadoop.warehouse=hdfs://example.com:8020/warehouse;
            </code></pre>
          </div>
          <div class="p">
            Then in the CREATE TABLE statement you can just refer to the catalog name:
            <pre class="pre codeblock"><code>
CREATE EXTERNAL TABLE ice_catalogs STORED AS ICEBERG TBLPROPERTIES('iceberg.catalog'='&lt;CATALOG-NAME&gt;');
            </code></pre>
          </div>
        </li>
        <li class="li">
          If the table already exists in HiveCatalog then Impala should be able to see it without any additional
          commands.
        </li>
      </ul>

      <div class="p">
        You can also create new Iceberg tables with Impala. You can use the same commands as above, just
        omit the <code class="ph codeph">EXTERNAL</code> keyword. To create an Iceberg table in HiveCatalog the following
        CREATE TABLE statement can be used:
        <pre class="pre codeblock"><code>
CREATE TABLE ice_t (i INT) STORED AS ICEBERG;
        </code></pre>
      </div>
      <p class="p">
        By default Impala assumes that the Iceberg table uses Parquet data files. ORC and AVRO are also supported,
        but we need to tell Impala via setting the table property 'write.format.default' to e.g. 'ORC'.
      </p>
      <div class="p">
        You can also use <code class="ph codeph">CREATE TABLE AS SELECT</code> to create new Iceberg tables, e.g.:
        <pre class="pre codeblock"><code>
CREATE TABLE ice_ctas STORED AS ICEBERG AS SELECT i, b FROM value_tbl;

CREATE TABLE ice_ctas_part PARTITIONED BY(d) STORED AS ICEBERG AS SELECT s, ts, d FROM value_tbl;

CREATE TABLE ice_ctas_part_spec PARTITIONED BY SPEC (truncate(3, s)) STORED AS ICEBERG AS SELECT cast(t as INT), s, d FROM value_tbl;
        </code></pre>
      </div>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title4" id="impala_iceberg__iceberg_v2">
    <h2 class="title topictitle2" id="ariaid-title4">Iceberg V2 tables</h2>
    <div class="body conbody">
      <div class="p">
        Iceberg V2 tables support row-level modifications (DELETE, UPDATE) via "merge-on-read", which means instead
        of rewriting existing data files, separate so-called delete files are being written that store information
        about the deleted records. There are two kinds of delete files in Iceberg:
        <ul class="ul">
          <li class="li">position deletes</li>
          <li class="li">equality deletes</li>
        </ul>
        Impala only supports position delete files. These files contain the file path and file position of the deleted
        rows.
      </div>
      <div class="p">
        One can create Iceberg V2 tables via the <code class="ph codeph">CREATE TABLE</code> statement, they just need to specify
        the 'format-version' table property:
        <pre class="pre codeblock"><code>
CREATE TABLE ice_v2 (i int) STORED BY ICEBERG TBLPROPERTIES('format-version'='2');
        </code></pre>
      </div>
      <div class="p">
        It is also possible to upgrade existing Iceberg V1 tables to Iceberg V2 tables. One can use the following
        <code class="ph codeph">ALTER TABLE</code> statement to do so:
        <pre class="pre codeblock"><code>
ALTER TABLE ice_v1_to_v2 SET TBLPROPERTIES('format-version'='2');
        </code></pre>
      </div>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title5" id="impala_iceberg__iceberg_drop">
    <h2 class="title topictitle2" id="ariaid-title5">Dropping Iceberg tables</h2>
    <div class="body conbody">
      <div class="p">
        One can use <code class="ph codeph">DROP TABLE</code> statement to remove an Iceberg table:
        <pre class="pre codeblock"><code>
          DROP TABLE ice_t;
        </code></pre>
      </div>
      <p class="p">
        When <code class="ph codeph">external.table.purge</code> table property is set to true, then the
        <code class="ph codeph">DROP TABLE</code> statement will also delete the data files. This property
        is set to true when Impala creates the Iceberg table via <code class="ph codeph">CREATE TABLE</code>.
        When <code class="ph codeph">CREATE EXTERNAL TABLE</code> is used (the table already exists in some
        catalog) then this <code class="ph codeph">external.table.purge</code> is set to false, i.e.
        <code class="ph codeph">DROP TABLE</code> doesn't remove any files, only the table definition
        in HMS.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title6" id="impala_iceberg__iceberg_types">
    <h2 class="title topictitle2" id="ariaid-title6">Supported Data Types for Iceberg Columns</h2>
    <div class="body conbody">

      <p class="p">
        You can get information about the supported Iceberg data types in
        <a class="xref" href="https://iceberg.apache.org/docs/latest/schemas/" target="_blank">
          the Iceberg spec</a>.
      </p>

      <div class="p">
        The Iceberg data types can be mapped to the following SQL types in Impala:
        <table class="table" id="iceberg_types__iceberg_types_sql_types"><caption></caption><colgroup><col><col></colgroup><thead class="thead">
              <tr class="row">
                <th class="entry cellrowborder colsep-1 rowsep-1" id="iceberg_types__iceberg_types_sql_types__entry__1">Iceberg type</th>
                <th class="entry cellrowborder colsep-1 rowsep-1" id="iceberg_types__iceberg_types_sql_types__entry__2">SQL type in Impala</th>
              </tr>
            </thead><tbody class="tbody">
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">boolean</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">BOOLEAN</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">int</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">INTEGER</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">long</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">BIGINT</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">float</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">FLOAT</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">double</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">DOUBLE</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">decimal(P, S)</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">DECIMAL(P, S)</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">date</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">DATE</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">time</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">Not supported</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">timestamp</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">TIMESTAMP</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">timestamptz</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">Only read support via TIMESTAMP</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">string</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">STRING</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">uuid</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">Not supported</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">fixed(L)</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">Not supported</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">binary</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">Not supported</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">struct</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">STRUCT (read only)</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">list</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">ARRAY (read only)</td>
              </tr>
              <tr class="row">
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__1 ">map</td>
                <td class="entry cellrowborder colsep-1 rowsep-1" headers="iceberg_types__iceberg_types_sql_types__entry__2 ">MAP (read only)</td>
              </tr>
            </tbody></table>
      </div>
    </div>
  </article>


  <article class="topic concept nested1" aria-labelledby="ariaid-title7" id="impala_iceberg__iceberg_schema_evolution">
    <h2 class="title topictitle2" id="ariaid-title7">Schema evolution of Iceberg tables</h2>
    <div class="body conbody">
      <div class="p">
        Iceberg assigns unique field ids to schema elements which means it is possible
        to reorder/delete/change columns and still be able to correctly read current and
        old data files. Impala supports the following statements to modify a table's schema:
        <ul class="ul">
          <li class="li"><code class="ph codeph">ALTER TABLE ... RENAME TO ...</code> (renames the table if the Iceberg catalog supports it)</li>
          <li class="li"><code class="ph codeph">ALTER TABLE ... CHANGE COLUMN ...</code> (change name and type of a column iff the new type is compatible with the old type)</li>
          <li class="li"><code class="ph codeph">ALTER TABLE ... ADD COLUMNS ...</code> (adds columns to the end of the table)</li>
          <li class="li"><code class="ph codeph">ALTER TABLE ... DROP COLUMN ...</code></li>
        </ul>
      </div>
      <div class="p">
        Valid type promotions are:
        <ul class="ul">
          <li class="li">int to long</li>
          <li class="li">float to double</li>
          <li class="li">decimal(P, S) to decimal(P', S) if P' &gt; P – widen the precision of decimal types.</li>
        </ul>
      </div>
      <p class="p">
        Impala currently does not support schema evolution for tables with AVRO file format.
      </p>
      <p class="p">
        See
        <a class="xref" href="https://iceberg.apache.org/docs/latest/evolution/#schema-evolution" target="_blank">
        schema evolution </a> for more details.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title8" id="impala_iceberg__iceberg_partitioning">
    <h2 class="title topictitle2" id="ariaid-title8">Partitioning Iceberg tables</h2>
    <div class="body conbody">
      <p class="p">
        <a class="xref" href="https://iceberg.apache.org/docs/latest/partitioning/" target="_blank">
        The Iceberg spec </a> has information about partitioning Iceberg tables. With Iceberg,
        we are not limited to value-based partitioning, we can also partition our tables via
        several partition transforms.
      </p>
      <div class="p">
        Partition transforms are IDENTITY, BUCKET, TRUNCATE, YEAR, MONTH, DAY, HOUR, and VOID.
        Impala supports all of these transforms. To create a partitioned Iceberg table, one
        needs to add a <code class="ph codeph">PARTITIONED BY SPEC</code> clause to the CREATE TABLE statement, e.g.:
        <pre class="pre codeblock"><code>
CREATE TABLE ice_p (i INT, d DATE, s STRING, t TIMESTAMP)
PARTITIONED BY SPEC (BUCKET(5, i), MONTH(d), TRUNCATE(3, s), HOUR(t))
STORED AS ICEBERG;
        </code></pre>
      </div>
      <div class="p">
        Iceberg also supports
        <a class="xref" href="https://iceberg.apache.org/docs/latest/evolution/#partition-evolution" target="_blank">
        partition evolution</a> which means that the partitioning of a table can be changed, even
        without the need of rewriting existing data files. You can change an existing table's
        partitioning via an <code class="ph codeph">ALTER TABLE SET PARTITION SPEC</code> statement, e.g.:
        <pre class="pre codeblock"><code>
ALTER TABLE ice_p SET PARTITION SPEC (VOID(i), VOID(d), TRUNCATE(3, s), HOUR(t), i);
        </code></pre>
      </div>
      <div class="p">
        Please keep in mind that for Iceberg V1 tables:
        <ul class="ul">
          <li class="li">Do not reorder partition fields</li>
          <li class="li">Do not drop partition fields; instead replace the field’s transform with the void transform</li>
          <li class="li">Only add partition fields at the end of the previous partition spec</li>
        </ul>
      </div>
      <div class="p">
        You can also use the legacy syntax to create identity-partitioned Iceberg tables:
        <pre class="pre codeblock"><code>
CREATE TABLE ice_p (i INT, b INT) PARTITIONED BY (p1 INT, p2 STRING) STORED AS ICEBERG;
        </code></pre>
      </div>
      <p class="p">
        One can inspect a table's partition spec by the <code class="ph codeph">SHOW PARTITIONS</code> or
        <code class="ph codeph">SHOW CREATE TABLE</code> commands.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title9" id="impala_iceberg__iceberg_inserts">
    <h2 class="title topictitle2" id="ariaid-title9">Inserting data into Iceberg tables</h2>
    <div class="body conbody">
      <p class="p">
        Impala is also able to insert new data to Iceberg tables. Currently the <code class="ph codeph">INSERT INTO</code>
        and <code class="ph codeph">INSERT OVERWRITE</code> DML statements are supported. One can also remove the
        contents of an Iceberg table via the <code class="ph codeph">TRUNCATE</code> command.
      </p>
      <div class="p">
        Since Iceberg uses hidden partitioning it means you don't need a partition clause in your INSERT
        statements. E.g. insertion to a partitioned table looks like:
        <pre class="pre codeblock"><code>
CREATE TABLE ice_p (i INT, b INT) PARTITIONED BY SPEC (bucket(17, i)) STORED AS ICEBERG;
INSERT INTO ice_p VALUES (1, 2);
        </code></pre>
      </div>
      <p class="p">
        <code class="ph codeph">INSERT OVERWRITE</code> statements can replace data in the table with the result of a query.
        For partitioned tables Impala does a dynamic overwrite, which means partitions that have rows produced
        by the SELECT query will be replaced. And partitions that have no rows produced by the SELECT query
        remain untouched. INSERT OVERWRITE is not allowed for tables that use the BUCKET partition transform
        because dynamic overwrite behavior would be too random in this case. If one needs to replace all
        contents of a table, they can still use <code class="ph codeph">TRUNCATE</code> and <code class="ph codeph">INSERT INTO</code>.
      </p>
      <p class="p">
        Impala can only write Iceberg tables with Parquet data files.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title10" id="impala_iceberg__iceberg_delete">
    <h2 class="title topictitle2" id="ariaid-title10">Delete data from Iceberg tables</h2>
    <div class="body conbody">
      <div class="p">
        Since <span class="keyword">Impala 4.3</span> Impala is able to run <code class="ph codeph">DELETE</code> statements against
        Iceberg V2 tables. E.g.:
        <pre class="pre codeblock"><code>
DELETE FROM ice_t where i = 3;
        </code></pre>
      </div>
      <p class="p">
        More information about the <code class="ph codeph">DELETE</code> statement can be found at <a class="xref" href="impala_delete.html#delete">DELETE Statement (Impala 2.8 or higher only)</a>.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title11" id="impala_iceberg__iceberg_update">
    <h2 class="title topictitle2" id="ariaid-title11">Updating data int Iceberg tables</h2>
    <div class="body conbody">
      <div class="p">
        Since <span class="keyword">Impala 4.4</span> Impala is able to run <code class="ph codeph">UPDATE</code> statements against
        Iceberg V2 tables. E.g.:
        <pre class="pre codeblock"><code>
UPDATE ice_t SET val = val + 1;
UPDATE ice_t SET k = 4 WHERE i = 5;
UPDATE ice_t SET ice_t.k = o.k, ice_t.j = o.j, FROM ice_t, other_table o where ice_t.id = o.id;
        </code></pre>
      </div>
      <p class="p">
        The UPDATE FROM statement can be used to update a target Iceberg table based on a source table (or view) that doesn't need
        to be an Iceberg table. If there are multiple matches on the JOIN condition, Impala will raise an error.
      </p>
      <div class="p">
        Limitations:
        <ul class="ul">
          <li class="li">Only the merge-on-read update mode is supported.</li>
          <li class="li">Only writes position delete files, i.e. no support for writing equality deletes.</li>
          <li class="li">Cannot update tables with complex types.</li>
          <li class="li">
            Can only write data and delete files in Parquet format. This means if table properties 'write.format.default'
            and 'write.delete.format.default' are set, their values must be PARQUET.
          </li>
          <li class="li">
            Updating partitioning column with non-constant expression via the UPDATE FROM statement is not allowed.
            The upcoming MERGE statement will not have this limitation.
          </li>
        </ul>
      </div>
      <p class="p">
        More information about the <code class="ph codeph">UPDATE</code> statement can be found at <a class="xref" href="impala_update.html#update">UPDATE Statement (Impala 2.8 or higher only)</a>.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title12" id="impala_iceberg__iceberg_load">
    <h2 class="title topictitle2" id="ariaid-title12">Loading data into Iceberg tables</h2>
    <div class="body conbody">
      <div class="p">
        <code class="ph codeph">LOAD DATA</code> statement can be used to load a single file or directory into
        an existing Iceberg table. This operation is executed differently compared to HMS tables, the
        data is being inserted into the table via sequentially executed statements, which has
        some limitations:
        <ul class="ul">
          <li class="li">Only Parquet or ORC files can be loaded.</li>
          <li class="li"><code class="ph codeph">PARTITION</code> clause is not supported, but the partition transformations
          are respected.</li>
          <li class="li">The loaded files will be re-written as Parquet files.</li>
        </ul>
      </div>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title13" id="impala_iceberg__iceberg_optimize_table">
    <h2 class="title topictitle2" id="ariaid-title13">Optimizing (Compacting) Iceberg tables</h2>
    <div class="body conbody">
      <div class="p">
        Frequent updates and row-level modifications on Iceberg tables can write many small
        data files and delete files, which have to be merged-on-read.
        This causes read performance to degrade over time.
        The following statement can be used to compact the table and optimize it for reading.
        <pre class="pre codeblock"><code>
OPTIMIZE TABLE [<var class="keyword varname">db_name</var>.]<var class="keyword varname">table_name</var>;
        </code></pre>
      </div>

      <div class="p">
        The current implementation of the <code class="ph codeph">OPTIMIZE TABLE</code> statement rewrites
        the entire table, executing the following tasks:
        <ul class="ul">
          <li class="li">compact small files</li>
          <li class="li">merge delete and update deltas</li>
          <li class="li">rewrite all files, converting them to the latest table schema</li>
          <li class="li">rewrite all partitions according to the latest partition spec</li>
        </ul>
      </div>

      <div class="p">
        To execute table optimization:
        <ul class="ul">
          <li class="li">The user needs ALL privileges on the table.</li>
          <li class="li">The table can conatin any file formats that Impala can read, but <code class="ph codeph">write.format.default</code>
          has to be <code class="ph codeph">parquet</code>.</li>
          <li class="li">The table cannot contain complex types.</li>
        </ul>
      </div>

      <p class="p">
        When a table is optimized, a new snapshot is created. The old table state is still
        accessible by time travel to previous snapshots, because the rewritten data and
        delete files are not removed physically.
      </p>
      <p class="p">
        Note that the current implementation of <code class="ph codeph">OPTIMIZE TABLE</code> rewrites
        the entire table, therefore this operation can take a long time to complete
        depending on the size of the table.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title14" id="impala_iceberg__iceberg_time_travel">
    <h2 class="title topictitle2" id="ariaid-title14">Time travel for Iceberg tables</h2>
    <div class="body conbody">

      <p class="p">
        Iceberg stores the table states in a chain of snapshots. By default, Impala uses the current
        snapshot of the table. But for Iceberg tables, it is also possible to query an earlier state of
        the table.
      </p>

      <div class="p">
        We can use the <code class="ph codeph">FOR SYSTEM_TIME AS OF</code> and <code class="ph codeph">FOR SYSTEM_VERSION AS OF</code>
        clauses in <code class="ph codeph">SELECT</code> queries, e.g.:
        <pre class="pre codeblock"><code>
SELECT * FROM ice_t FOR SYSTEM_TIME AS OF '2022-01-04 10:00:00';
SELECT * FROM ice_t FOR SYSTEM_TIME AS OF now() - interval 5 days;
SELECT * FROM ice_t FOR SYSTEM_VERSION AS OF 123456;
        </code></pre>
      </div>

      <div class="p">
        If one needs to check the available snapshots of a table they can use the <code class="ph codeph">DESCRIBE HISTORY</code>
        statement with the following syntax:
        <pre class="pre codeblock"><code>
DESCRIBE HISTORY [<var class="keyword varname">db_name</var>.]<var class="keyword varname">table_name</var>
  [FROM <var class="keyword varname">timestamp</var>];

DESCRIBE HISTORY [<var class="keyword varname">db_name</var>.]<var class="keyword varname">table_name</var>
  [BETWEEN <var class="keyword varname">timestamp</var> AND <var class="keyword varname">timestamp</var>]
        </code></pre>
        For example:
<pre class="pre codeblock"><code>
DESCRIBE HISTORY ice_t FROM '2022-01-04 10:00:00';
DESCRIBE HISTORY ice_t FROM now() - interval 5 days;
DESCRIBE HISTORY ice_t BETWEEN '2022-01-04 10:00:00' AND '2022-01-05 10:00:00';
</code></pre>
      </div>
      <div class="p">
        The output of the <code class="ph codeph">DESCRIBE HISTORY</code> statement is formed
        of the following columns:
        <ul class="ul">
          <li class="li"><code class="ph codeph">creation_time</code>: the snapshot's creation timestamp.</li>
          <li class="li"><code class="ph codeph">snapshot_id</code>: the snapshot's ID or null.</li>
          <li class="li"><code class="ph codeph">parent_id</code>: the snapshot's parent ID or null.</li>
          <li class="li"><code class="ph codeph">is_current_ancestor</code>: TRUE if the snapshot is a current ancestor of the table.</li>
        </ul>
      </div>

      <p class="p">
        Please note that time travel queries are executed using the old schema of the table
        from the point specified by the time travel parameters.
        Prior to Impala 4.3.0 the current table schema is used to query an older
        snapshot of the table, which might have had a different schema in the past.
      </p>

    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title15" id="impala_iceberg__iceberg_execute_rollback">
    <h2 class="title topictitle2" id="ariaid-title15">Rolling Iceberg tables back to a previous state</h2>
    <div class="body conbody">
      <p class="p">
        Iceberg table modifications cause new table snapshots to be created;
        these snapshots represent an earlier version of the table.
        The <code class="ph codeph">ALTER TABLE [<var class="keyword varname">db_name</var>.]<var class="keyword varname">table_name</var> EXECUTE ROLLBACK</code>
        statement can be used to roll back the table to a previous snapshot.
      </p>

      <div class="p">
        For example, to roll the table back to the snapshot id <code class="ph codeph">123456</code> use:
        <pre class="pre codeblock"><code>
ALTER TABLE ice_tbl EXECUTE ROLLBACK(123456);
        </code></pre>
        To roll the table back to the most recent (newest) snapshot
        that has a creation timestamp that is older than the timestamp '2022-01-04 10:00:00' use:
        <pre class="pre codeblock"><code>
ALTER TABLE ice_tbl EXECUTE ROLLBACK('2022-01-04 10:00:00');
        </code></pre>
        The timestamp is evaluated using the Timezone for the current session.
      </div>

      <p class="p">
        It is only possible to roll back to a snapshot that is a current ancestor of the table.
      </p>
      <p class="p">
        When a table is rolled back to a snapshot, a new snapshot is
        created with the same snapshot id, but with a new creation timestamp.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title16" id="impala_iceberg__iceberg_expire_snapshots">
    <h2 class="title topictitle2" id="ariaid-title16">Expiring snapshots</h2>
    <div class="body conbody">
      <div class="p">
        Iceberg snapshots accumulate until they are deleted by a user action. Snapshots
        can be deleted with <code class="ph codeph">ALTER TABLE ... EXECUTE expire_snapshots(...)</code>
        statement, which will expire snapshots that are older than the specified
        timestamp. For example:
        <pre class="pre codeblock"><code>
ALTER TABLE ice_tbl EXECUTE expire_snapshots('2022-01-04 10:00:00');
ALTER TABLE ice_tbl EXECUTE expire_snapshots(now() - interval 5 days);
        </code></pre>
      </div>
      <div class="p">
        Expire snapshots:
        <ul class="ul">
          <li class="li">does not remove old metadata files by default.</li>
          <li class="li">does not remove orphaned data files.</li>
          <li class="li">respects the minimum number of snapshots to keep:
          <code class="ph codeph">history.expire.min-snapshots-to-keep</code> table property.</li>
        </ul>
      </div>
      <p class="p">
        Old metadata file clean up can be configured with
        <code class="ph codeph">write.metadata.delete-after-commit.enabled=true</code> and
        <code class="ph codeph">write.metadata.previous-versions-max</code> table properties. This
        allows automatic metadata file removal after operations that modify metadata
        such as expiring snapshots or inserting data.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title17" id="impala_iceberg__iceberg_table_cloning">
    <h2 class="title topictitle2" id="ariaid-title17">Cloning Iceberg tables (LIKE clause)</h2>
    <div class="body conbody">
      <div class="p">
        Use <code class="ph codeph">CREATE TABLE ... LIKE ...</code> to create an empty Iceberg table
        based on the definition of another Iceberg table, including any column attributes in
        the original table:
        <pre class="pre codeblock"><code>
          CREATE TABLE new_ice_tbl LIKE orig_ice_tbl;
        </code></pre>
      </div>
      <p class="p">
        Because of the Data Types of Iceberg and Impala do not correspond one by one, Impala
        can only clone between Iceberg tables.
      </p>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title18" id="impala_iceberg__iceberg_table_properties">
    <h2 class="title topictitle2" id="ariaid-title18">Iceberg table properties</h2>
    <div class="body conbody">
      <div class="p">
        We can set the following table properties for Iceberg tables:
        <ul class="ul">
          <li class="li">
            <code class="ph codeph">iceberg.catalog</code>: controls which catalog is used for this Iceberg table.
            It can be 'hive.catalog' (default), 'hadoop.catalog', 'hadoop.tables', or a name that
            identifies a catalog defined in the Hadoop configurations, e.g. hive-site.xml
          </li>
          <li class="li"><code class="ph codeph">iceberg.catalog_location</code>: Iceberg table catalog location when <code class="ph codeph">iceberg.catalog</code> is <code class="ph codeph">'hadoop.catalog'</code></li>
          <li class="li"><code class="ph codeph">iceberg.table_identifier</code>: Iceberg table identifier. We use &lt;database&gt;.&lt;table&gt; instead if this property is not set</li>
          <li class="li"><code class="ph codeph">write.format.default</code>: data file format of the table. Impala can read AVRO, ORC and PARQUET data files in Iceberg tables, and can write PARQUET data files only.</li>
          <li class="li"><code class="ph codeph">write.parquet.compression-codec</code>:
            Parquet compression codec. Supported values are: NONE, GZIP, SNAPPY
            (default value), LZ4, ZSTD. The table property will be ignored if
            <code class="ph codeph">COMPRESSION_CODEC</code> query option is set.
          </li>
          <li class="li"><code class="ph codeph">write.parquet.compression-level</code>:
            Parquet compression level. Used with ZSTD compression only.
            Supported range is [1, 22]. Default value is 3. The table property
            will be ignored if <code class="ph codeph">COMPRESSION_CODEC</code> query option is set.
          </li>
          <li class="li"><code class="ph codeph">write.parquet.row-group-size-bytes</code>:
            Parquet row group size in bytes. Supported range is [8388608,
            2146435072] (8MB - 2047MB). The table property will be ignored if
            <code class="ph codeph">PARQUET_FILE_SIZE</code> query option is set.
            If neither the table property nor the <code class="ph codeph">PARQUET_FILE_SIZE</code> query option
            is set, the way Impala calculates row group size will remain
            unchanged.
          </li>
          <li class="li"><code class="ph codeph">write.parquet.page-size-bytes</code>:
            Parquet page size in bytes. Used for PLAIN encoding. Supported range
            is [65536, 1073741824] (64KB - 1GB).
            If the table property is unset, the way Impala calculates page size
            will remain unchanged.
          </li>
          <li class="li"><code class="ph codeph">write.parquet.dict-size-bytes</code>:
            Parquet dictionary page size in bytes. Used for dictionary encoding.
            Supported range is [65536, 1073741824] (64KB - 1GB).
            If the table property is unset, the way Impala calculates dictionary
            page size will remain unchanged.
          </li>
        </ul>
      </div>
    </div>
  </article>

  <article class="topic concept nested1" aria-labelledby="ariaid-title19" id="impala_iceberg__iceberg_manifest_caching">
    <h2 class="title topictitle2" id="ariaid-title19">Iceberg manifest caching</h2>
    <div class="body conbody">
      <div class="p">
        Starting from version 1.1.0, Apache Iceberg provides a mechanism to cache the
        contents of Iceberg manifest files in memory. This manifest caching feature helps
        to reduce repeated reads of small Iceberg manifest files from remote storage by
        Coordinators and Catalogd. This feature can be enabled for Impala Coordinators and
        Catalogd by setting properties in Hadoop's core-site.xml as in the following:
        <pre class="pre codeblock"><code>
iceberg.io-impl=org.apache.iceberg.hadoop.HadoopFileIO;
iceberg.io.manifest.cache-enabled=true;
iceberg.io.manifest.cache.max-total-bytes=104857600;
iceberg.io.manifest.cache.expiration-interval-ms=3600000;
iceberg.io.manifest.cache.max-content-length=8388608;
        </code></pre>
      </div>
      <div class="p">
        The description of each property is as follows:
        <ul class="ul">
          <li class="li">
            <code class="ph codeph">iceberg.io-impl</code>: custom FileIO implementation to use in a
            catalog. Must be set to enable manifest caching. Impala defaults to
            HadoopFileIO. It is recommended to not change this to other than HadoopFileIO.
          </li>
          <li class="li">
            <code class="ph codeph">iceberg.io.manifest.cache-enabled</code>: enable/disable the
            manifest caching feature.
          </li>
          <li class="li">
            <code class="ph codeph">iceberg.io.manifest.cache.max-total-bytes</code>: maximum total
            amount of bytes to cache in the manifest cache. Must be a positive value.
          </li>
          <li class="li">
            <code class="ph codeph">iceberg.io.manifest.cache.expiration-interval-ms</code>: maximum
            duration for which an entry stays in the manifest cache. Must be a
            non-negative value. Setting zero means cache entries expire only if it gets
            evicted due to memory pressure from
            <code class="ph codeph">iceberg.io.manifest.cache.max-total-bytes</code>.
          </li>
          <li class="li">
            <code class="ph codeph">iceberg.io.manifest.cache.max-content-length</code>: maximum length
            of a manifest file to be considered for caching in bytes. Manifest files with
            a length exceeding this property value will not be cached. Must be set with a
            positive value and lower than
            <code class="ph codeph">iceberg.io.manifest.cache.max-total-bytes</code>.
          </li>
        </ul>
      </div>
      <p class="p">
        Manifest caching only works for tables that are loaded with either of
        HadoopCatalogs or HiveCatalogs. Individual HadoopCatalog and HiveCatalog will have
        separate manifest caches with the same configuration. By default, only 8 catalogs
        can have their manifest cache active in memory. This number can be raised by
        setting a higher value in the java system property
        <code class="ph codeph">iceberg.io.manifest.cache.fileio-max</code>.
      </p>
    </div>
  </article>
</article></main></body></html>