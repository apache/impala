<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<meta name="copyright" content="(C) Copyright 2024" />
<meta name="DC.rights.owner" content="(C) Copyright 2024" />
<meta name="DC.Type" content="concept" />
<meta name="DC.Title" content="NDV Function" />
<meta name="DC.Relation" scheme="URI" content="../topics/impala_aggregate_functions.html" />
<meta name="prodname" content="Impala" />
<meta name="prodname" content="Impala" />
<meta name="version" content="Impala 3.4.x" />
<meta name="version" content="Impala 3.4.x" />
<meta name="DC.Format" content="XHTML" />
<meta name="DC.Identifier" content="ndv" />
<link rel="stylesheet" type="text/css" href="../commonltr.css" />
<title>NDV Function</title>
</head>
<body id="ndv">


  <h1 class="title topictitle1" id="ariaid-title1">NDV Function</h1>

  
  

  <div class="body conbody">

    <p class="p">
      
      An aggregate function that returns an approximate value similar to the result of <code class="ph codeph">COUNT(DISTINCT
      <var class="keyword varname">col</var>)</code>, the <span class="q">"number of distinct values"</span>. It is much faster than the
      combination of <code class="ph codeph">COUNT</code> and <code class="ph codeph">DISTINCT</code>, and uses a constant amount of memory and
      thus is less memory-intensive for columns with high cardinality.
    </p>


    <p class="p">
        <strong class="ph b">Syntax:</strong>
      </p>


<pre class="pre codeblock"><code>NDV([DISTINCT | ALL] <var class="keyword varname">expression</var> [,scale])</code></pre>

    <div class="note note"><span class="notetitle">Note:</span>  The optional argument <code class="ph codeph">scale</code> must be an integer and can be in the range
      from 1 to 10 and maps to a precision used by the HyperLogLog (HLL) algorithm with the
      following mapping formula:</div>


    <div class="p"><pre class="pre codeblock"><code>precision = scale + 8</code></pre></div>


    <p class="p">
      Therefore a scale of 1 is mapped to a precision of 9 and a scale of 10 is mapped to a
      precision of 18.
    </p>


    <p class="p">
      Without the optional argument, the precision which determines the total number
      of different estimators in the HLL algorithm will be still 10.
    </p>


    <p class="p">
      A large precision value generally produces a better estimation with less error than a small
      precision value. This is due to the extra number of estimators involved. The expense is at the
      need of extra memory. For a given precision p, the amount of memory used by the HLL algorithm
      is in the order of 2^p bytes.
    </p>


    <p class="p">
      When provided a scale of 10 against a total of 22 distinct data sets loaded into external
      Impala tables, the error will be computed as
      abs(&lt;true_unique_value&gt; - &lt;estimated_unique_value&gt;) / &lt;true_unique_value&gt;
    </p>


    <p class="p">
      The scale of 10, mapped to the precision of 18, yielded the worst estimation error at 0.42%
      (for one set of 10 million integers), and average error no more than 0.17%. This was at the
      cost of 256Kb of memory for the internal data structure per evaluation of the HLL algorithm.
    </p>


    <p class="p">
        <strong class="ph b">Usage notes:</strong>
      </p>


    <p class="p">
      This is the mechanism used internally by the <code class="ph codeph">COMPUTE STATS</code> statement for computing the
      number of distinct values in a column.
    </p>


    <p class="p">
      Because this number is an estimate, it might not reflect the precise number of different values in the
      column, especially if the cardinality is very low or very high. If the estimated number is higher than the
      number of rows in the table, Impala adjusts the value internally during query planning.
    </p>


    <p class="p">
        <strong class="ph b">Return type:</strong> <code class="ph codeph">DOUBLE</code> in Impala 2.0 and higher;
        <code class="ph codeph">STRING</code> in earlier releases
      </p>




    <p class="p">
        <strong class="ph b">Complex type considerations:</strong>
      </p>


    <p class="p">
        To access a column with a complex type (<code class="ph codeph">ARRAY</code>, <code class="ph codeph">STRUCT</code>,
        or <code class="ph codeph">MAP</code>) in an aggregation function, you unpack the individual elements
        using join notation in the query, and then apply the function to the final scalar item,
        field, key, or value at the bottom of any nested type hierarchy in the column. See
        <a class="xref" href="../shared/../topics/impala_complex_types.html#complex_types">Complex Types (Impala 2.3 or higher only)</a> for details about using
        complex types in Impala.
      </p>


    <div class="p">
        The following example demonstrates calls to several aggregation functions using values
        from a column containing nested complex types (an <code class="ph codeph">ARRAY</code> of
        <code class="ph codeph">STRUCT</code> items). The array is unpacked inside the query using join
        notation. The array elements are referenced using the <code class="ph codeph">ITEM</code>
        pseudocolumn, and the structure fields inside the array elements are referenced using
        dot notation. Numeric values such as <code class="ph codeph">SUM()</code> and <code class="ph codeph">AVG()</code>
        are computed using the numeric <code class="ph codeph">R_NATIONKEY</code> field, and the
        general-purpose <code class="ph codeph">MAX()</code> and <code class="ph codeph">MIN()</code> values are computed
        from the string <code class="ph codeph">N_NAME</code> field.
<pre class="pre codeblock"><code>describe region;
+-------------+-------------------------+---------+
| name        | type                    | comment |
+-------------+-------------------------+---------+
| r_regionkey | smallint                |         |
| r_name      | string                  |         |
| r_comment   | string                  |         |
| r_nations   | array&lt;struct&lt;           |         |
|             |   n_nationkey:smallint, |         |
|             |   n_name:string,        |         |
|             |   n_comment:string      |         |
|             | &gt;&gt;                      |         |
+-------------+-------------------------+---------+

select r_name, r_nations.item.n_nationkey
  from region, region.r_nations as r_nations
order by r_name, r_nations.item.n_nationkey;
+-------------+------------------+
| r_name      | item.n_nationkey |
+-------------+------------------+
| AFRICA      | 0                |
| AFRICA      | 5                |
| AFRICA      | 14               |
| AFRICA      | 15               |
| AFRICA      | 16               |
| AMERICA     | 1                |
| AMERICA     | 2                |
| AMERICA     | 3                |
| AMERICA     | 17               |
| AMERICA     | 24               |
| ASIA        | 8                |
| ASIA        | 9                |
| ASIA        | 12               |
| ASIA        | 18               |
| ASIA        | 21               |
| EUROPE      | 6                |
| EUROPE      | 7                |
| EUROPE      | 19               |
| EUROPE      | 22               |
| EUROPE      | 23               |
| MIDDLE EAST | 4                |
| MIDDLE EAST | 10               |
| MIDDLE EAST | 11               |
| MIDDLE EAST | 13               |
| MIDDLE EAST | 20               |
+-------------+------------------+

select
  r_name,
  count(r_nations.item.n_nationkey) as count,
  sum(r_nations.item.n_nationkey) as sum,
  avg(r_nations.item.n_nationkey) as avg,
  min(r_nations.item.n_name) as minimum,
  max(r_nations.item.n_name) as maximum,
  ndv(r_nations.item.n_nationkey) as distinct_vals
from
  region, region.r_nations as r_nations
group by r_name
order by r_name;
+-------------+-------+-----+------+-----------+----------------+---------------+
| r_name      | count | sum | avg  | minimum   | maximum        | distinct_vals |
+-------------+-------+-----+------+-----------+----------------+---------------+
| AFRICA      | 5     | 50  | 10   | ALGERIA   | MOZAMBIQUE     | 5             |
| AMERICA     | 5     | 47  | 9.4  | ARGENTINA | UNITED STATES  | 5             |
| ASIA        | 5     | 68  | 13.6 | CHINA     | VIETNAM        | 5             |
| EUROPE      | 5     | 77  | 15.4 | FRANCE    | UNITED KINGDOM | 5             |
| MIDDLE EAST | 5     | 58  | 11.6 | EGYPT     | SAUDI ARABIA   | 5             |
+-------------+-------+-----+------+-----------+----------------+---------------+
</code></pre>
      </div>


    <p class="p">
        <strong class="ph b">Restrictions:</strong>
      </p>


    <p class="p">
        This function cannot be used in an analytic context. That is, the
        <code class="ph codeph">OVER()</code> clause is not allowed at all with this function.
      </p>


    <p class="p">
        <strong class="ph b">Examples:</strong>
      </p>


    <p class="p">
      The following example queries a billion-row table to illustrate the relative performance of
      <code class="ph codeph">COUNT(DISTINCT)</code> and <code class="ph codeph">NDV()</code>. It shows how <code class="ph codeph">COUNT(DISTINCT)</code>
      gives a precise answer, but is inefficient for large-scale data where an approximate result is sufficient.
      The <code class="ph codeph">NDV()</code> function gives an approximate result but is much faster.
    </p>


<pre class="pre codeblock"><code>select count(distinct col1) from sample_data;
+---------------------+
| count(distinct col1)|
+---------------------+
| 100000              |
+---------------------+
Fetched 1 row(s) in 20.13s

select cast(ndv(col1) as bigint) as col1 from sample_data;
+----------+
| col1     |
+----------+
| 139017   |
+----------+
Fetched 1 row(s) in 8.91s
</code></pre>

    <p class="p">
      The following example shows how you can code multiple <code class="ph codeph">NDV()</code> calls in a single query, to
      easily learn which columns have substantially more or fewer distinct values. This technique is faster than
      running a sequence of queries with <code class="ph codeph">COUNT(DISTINCT)</code> calls.
    </p>


<pre class="pre codeblock"><code>select cast(ndv(col1) as bigint) as col1, cast(ndv(col2) as bigint) as col2,
    cast(ndv(col3) as bigint) as col3, cast(ndv(col4) as bigint) as col4
  from sample_data;
+----------+-----------+------------+-----------+
| col1     | col2      | col3       | col4      |
+----------+-----------+------------+-----------+
| 139017   | 282       | 46         | 145636240 |
+----------+-----------+------------+-----------+
Fetched 1 row(s) in 34.97s

select count(distinct col1) from sample_data;
+---------------------+
| count(distinct col1)|
+---------------------+
| 100000              |
+---------------------+
Fetched 1 row(s) in 20.13s

select count(distinct col2) from sample_data;
+----------------------+
| count(distinct col2) |
+----------------------+
| 278                  |
+----------------------+
Fetched 1 row(s) in 20.09s

select count(distinct col3) from sample_data;
+-----------------------+
| count(distinct col3)  |
+-----------------------+
| 46                    |
+-----------------------+
Fetched 1 row(s) in 19.12s

select count(distinct col4) from sample_data;
+----------------------+
| count(distinct col4) |
+----------------------+
| 147135880            |
+----------------------+
Fetched 1 row(s) in 266.95s
</code></pre>
  </div>

<div class="related-links">
<div class="familylinks">
<div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../topics/impala_aggregate_functions.html">Impala Aggregate Functions</a></div>
</div>
</div></body>
</html>