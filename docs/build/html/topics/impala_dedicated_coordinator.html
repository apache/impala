<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<meta name="copyright" content="(C) Copyright 2019" />
<meta name="DC.rights.owner" content="(C) Copyright 2019" />
<meta name="DC.Type" content="concept" />
<meta name="DC.Title" content="How to Configure Impala with Dedicated Coordinators" />
<meta name="DC.Relation" scheme="URI" content="../topics/impala_scalability.html" />
<meta name="prodname" content="Impala" />
<meta name="prodname" content="Impala" />
<meta name="version" content="Impala 3.2.x" />
<meta name="version" content="Impala 3.2.x" />
<meta name="DC.Format" content="XHTML" />
<meta name="DC.Identifier" content="scalability" />
<link rel="stylesheet" type="text/css" href="../commonltr.css" />
<title>How to Configure Impala with Dedicated Coordinators</title>
</head>
<body id="scalability">


  <h1 class="title topictitle1" id="ariaid-title1">How to Configure Impala with Dedicated Coordinators</h1>






  <div class="body conbody">

    <p class="p">
      Each host that runs the Impala Daemon acts as both a coordinator and as an executor, by
      default, managing metadata caching, query compilation, and query execution. In this
      configuration, Impala clients can connect to any Impala daemon and send query requests.
    </p>


    <p class="p">
      During highly concurrent workloads for large-scale queries, the dual roles can cause
      scalability issues because:
    </p>


    <ul class="ul">
      <li class="li">
        <p class="p">
          The extra work required for a host to act as the coordinator could interfere with its
          capacity to perform other work for the later phases of the query. For example,
          coordinators can experience significant network and CPU overhead with queries
          containing a large number of query fragments. Each coordinator caches metadata for all
          table partitions and data files, which requires coordinators to be configured with a
          large JVM heap. Executor-only Impala daemons should be configured with the default JVM
          heaps, which leaves more memory available to process joins, aggregations, and other
          operations performed by query executors.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Having a large number of hosts act as coordinators can cause unnecessary network
          overhead, or even timeout errors, as each of those hosts communicates with the
          Statestored daemon for metadata updates.
        </p>

      </li>


      <li class="li">
        <p class="p">
          The "soft limits" imposed by the admission control feature are more likely to be
          exceeded when there are a large number of heavily loaded hosts acting as coordinators.
          Check
          <a class="xref" href="https://issues.apache.org/jira/browse/IMPALA-3649" target="_blank">
          <u class="ph u">IMPALA-3649</u>
          </a> and
          <a class="xref" href="https://issues.apache.org/jira/browse/IMPALA-6437" target="_blank">
          <u class="ph u">IMPALA-6437</u>
          </a> to see the status of the enhancements to mitigate this issue.
        </p>

      </li>

    </ul>


    <p class="p">
      The following factors can further exacerbate the above issues:
    </p>


    <ul class="ul">
      <li class="li">
        <p class="p">
          High number of concurrent query fragments due to query concurrency and/or query
          complexity
        </p>

      </li>


      <li class="li">
        <p class="p">
          Large metadata topic size related to the number of partitions/files/blocks
        </p>

      </li>


      <li class="li">
        <p class="p">
          High number of coordinator nodes
        </p>

      </li>


      <li class="li">
        <p class="p">
          High number of coordinators used in the same resource pool
        </p>

      </li>

    </ul>


    <p class="p"> If such scalability bottlenecks occur, in Impala 2.9 and higher, you can
      assign one dedicated role to each Impala daemon host, either as a
      coordinator or as an executor, to address the issues. </p>


    <ul class="ul">
      <li class="li">
        <p class="p">
          All explicit or load-balanced client connections must go to the coordinator hosts.
          These hosts perform the network communication to keep metadata up-to-date and route
          query results to the appropriate clients. The dedicated coordinator hosts do not
          participate in I/O-intensive operations such as scans, and CPU-intensive operations
          such as aggregations.
        </p>

      </li>


      <li class="li">
        <p class="p">
          The executor hosts perform the intensive I/O, CPU, and memory operations that make up
          the bulk of the work for each query. The executors do communicate with the Statestored
          daemon for membership status, but the dedicated executor hosts do not process the
          final result sets for queries.
        </p>

      </li>

    </ul>


    <p class="p">
      Using dedicated coordinators offers the following benefits:
    </p>


    <ul class="ul">
      <li class="li">
        <p class="p">
          Reduces memory usage by limiting the number of Impala nodes that need to cache
          metadata.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Provides better concurrency by avoiding coordinator bottleneck.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Eliminates query over-admission.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Reduces resource, especially network, utilization on the Statestored daemon by
          limiting metadata broadcast to a subset of nodes.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Improves reliability and performance for highly concurrent workloads by reducing
          workload stress on coordinators. Dedicated coordinators require 50% or fewer
          connections and threads.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Reduces the number of explicit metadata refreshes required.
        </p>

      </li>


      <li class="li">
        <p class="p">
          Improves diagnosability if a bottleneck or other performance issue arises on a
          specific host, you can narrow down the cause more easily because each host is
          dedicated to specific operations within the overall Impala workload.
        </p>

      </li>

    </ul>


    <p class="p">
      In this configuration with dedicated coordinators / executors, you cannot connect to the
      dedicated executor hosts through clients such as impala-shell or business intelligence
      tools as only the coordinator nodes support client connections.
    </p>


  </div>


  <div class="related-links">
<div class="familylinks">
<div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../topics/impala_scalability.html">Scalability Considerations for Impala</a></div>
</div>
</div><div class="topic concept nested1" aria-labelledby="ariaid-title2" id="concept_vhv_4b1_n2b">

    <h2 class="title topictitle2" id="ariaid-title2">Determining the Optimal Number of Dedicated Coordinators</h2>


    <div class="body conbody">

      <p class="p">
        You should have the smallest number of coordinators that will still satisfy your
        workload requirements in a cluster. A rough estimation is 1 coordinator for every 50
        executors.
      </p>


      <p class="p">
        To maintain a healthy state and optimal performance, it is recommended that you keep the
        peak utilization of all resources used by Impala, including CPU, the number of threads,
        the number of connections, and RPCs, under 80%.
      </p>


      <p class="p">
        Consider the following factors to determine the right number of coordinators in your
        cluster:
      </p>


      <ul class="ul">
        <li class="li">
          <p class="p">
            What is the number of concurrent queries?
          </p>

        </li>


        <li class="li">
          <p class="p">
            What percentage of the workload is DDL?
          </p>

        </li>


        <li class="li">
          <p class="p">
            What is the average query resource usage at the various stages (merge, runtime
            filter, result set size, etc.)?
          </p>

        </li>


        <li class="li">
          <p class="p">
            How many Impala Daemons (impalad) is in the cluster?
          </p>

        </li>


        <li class="li">
          <p class="p">
            Is there a high availability requirement?
          </p>

        </li>


        <li class="li">
          <p class="p">
            Compute/storage capacity reduction factor
          </p>

        </li>

      </ul>


      <p class="p">
        Start with the below set of steps to determine the initial number of coordinators:
      </p>


      <ol class="ol">
        <li class="li">
          If your cluster has less than 10 nodes, we recommend that you configure one dedicated
          coordinator. Deploy the dedicated coordinator on a DataNode to avoid losing storage
          capacity. In most of cases, one dedicated coordinator is enough to support all
          workloads on a cluster.
        </li>


        <li class="li">
          Add more coordinators if the dedicated coordinator CPU or network peak utilization is
          80% or higher. You might need 1 coordinator for every 50 executors.
        </li>


        <li class="li">
          If the Impala service is shared by multiple workgroups with a dynamic resource pool
          assigned, use one coordinator per pool to avoid admission control over admission.
        </li>


        <li class="li">
          If high availability is required, double the number of coordinators. One set as an
          active set and the other as a backup set.
        </li>

      </ol>


    </div>


    <div class="topic concept nested2" aria-labelledby="ariaid-title3" id="concept_y4k_rc1_n2b">

      <h3 class="title topictitle3" id="ariaid-title3">Advanced Tuning</h3>


      <div class="body conbody">

        <div class="p">
          Use the following guidelines to further tune the throughput and stability.
          <ol class="ol">
            <li class="li">
              The concurrency of DML statements does not typically depend on the number of
              coordinators or size of the cluster. Queries that return large result sets
              (10,000+ rows) consume more CPU and memory resources on the coordinator. Add one
              or two coordinators if the workload has many such queries.
            </li>


            <li class="li">
              DDL queries, excluding <code class="ph codeph">COMPUTE STATS</code> and <code class="ph codeph">CREATE TABLE AS
              SELECT</code>, are executed only on coordinators. If your workload contains many
              DDL queries running concurrently, you could add one coordinator.
            </li>


            <li class="li">
              The CPU contention on coordinators can slow down query executions when concurrency
              is high, especially for very short queries (&lt;10s). Add more coordinators to
              avoid CPU contention.
            </li>


            <li class="li">
              On a large cluster with 50+ nodes, the number of network connections from a
              coordinator to executors can grow quickly as query complexity increases. The
              growth is much greater on coordinators than executors. Add a few more coordinators
              if workloads are complex, i.e. (an average number of fragments * number of
              Impalad) &gt; 500, but with the low memory/CPU usage to share the load. Watch
              IMPALA-4603 and IMPALA-7213 to track the progress on fixing this issue.
            </li>


            <li class="li">
              When using multiple coordinators for DML statements, divide queries to different
              groups (number of groups = number of coordinators). Configure a separate dynamic
              resource pool for each group and direct each group of query requests to a specific
              coordinator. This is to avoid query over admission.
            </li>


            <li class="li">
              The front-end connection requirement is not a factor in determining the number of
              dedicated coordinators. Consider setting up a connection pool at the client side
              instead of adding coordinators. For a short-term solution, you could increase the
              value of <code class="ph codeph">fe_service_threads</code> on coordinators to allow more client
              connections.
            </li>


            <li class="li">
              In general, you should have a very small number of coordinators so storage
              capacity reduction is not a concern. On a very small cluster (less than 10 nodes),
              deploy a dedicated coordinator on a DataNode to avoid storage capacity reduction.
            </li>

          </ol>

        </div>


      </div>


    </div>


    <div class="topic concept nested2" aria-labelledby="ariaid-title4" id="concept_w51_cd1_n2b">

      <h3 class="title topictitle3" id="ariaid-title4">Estimating Coordinator Resource Usage</h3>


      <div class="body conbody">

        <div class="p">

<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="concept_w51_cd1_n2b__table_kh3_d31_n2b" class="table" frame="border" border="1" rules="all"><colgroup><col /><col /><col /></colgroup><tbody class="tbody">
                <tr class="row">
                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <strong class="ph b">Resource</strong>
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <strong class="ph b">Safe range</strong>
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <strong class="ph b">Notes / CM tsquery to monitor</strong>
                  </td>

                </tr>

                <tr class="row">
                  <td class="entry cellrowborder" style="vertical-align:top;">
                    Memory
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <p class="p">
                      (Max JVM heap setting +
                    </p>




                    <p class="p">
                      query concurrency *
                    </p>




                    <p class="p">
                      query mem_limit)
                    </p>




                    <p class="p">
                      &lt;=
                    </p>




                    <p class="p">
                      80% of Impala process memory allocation
                    </p>

                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <p class="p">
                      <em class="ph i">Memory usage</em>:
                    </p>




                    <p class="p">
                      SELECT mem_rss WHERE entityName = "Coordinator Instance ID" AND category =
                      ROLE
                    </p>




                    <p class="p">
                      <em class="ph i">JVM heap usage (metadata cache)</em>:
                    </p>




                    <p class="p">
                      SELECT impala_jvm_heap_current_usage_bytes WHERE entityName = "Coordinator
                      Instance ID" AND category = ROLE (only in release 5.15 and above)
                    </p>

                  </td>

                </tr>

                <tr class="row">
                  <td class="entry cellrowborder" style="vertical-align:top;">
                    TCP Connection
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    Incoming + outgoing &lt; 16K
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <p class="p">
                      <em class="ph i">Incoming connection usage</em>:
                    </p>




                    <p class="p">
                      SELECT thrift_server_backend_connections_in_use WHERE entityName =
                      "Coordinator Instance ID" AND category = ROLE
                    </p>




                    <p class="p">
                      <em class="ph i">Outgoing connection usage</em>:
                    </p>




                    <p class="p">
                      SELECT backends_client_cache_clients_in_use WHERE entityName =
                      "Coordinator Instance ID" AND category = ROLE
                    </p>

                  </td>

                </tr>

                <tr class="row">
                  <td class="entry cellrowborder" style="vertical-align:top;">
                    Threads
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    &lt; 32K
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    SELECT thread_manager_running_threads WHERE entityName = "Coordinator
                    Instance ID" AND category = ROLE
                  </td>

                </tr>

                <tr class="row">
                  <td class="entry cellrowborder" style="vertical-align:top;">
                    CPU
                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <p class="p">
                      Concurrency =
                    </p>




                    <p class="p">
                      non-DDL query concurrency &lt;=
                    </p>




                    <p class="p">
                      number of virtual cores allocated to Impala per node
                    </p>

                  </td>

                  <td class="entry cellrowborder" style="vertical-align:top;">
                    <p class="p">
                      CPU usage estimation should be based on how many cores are allocated to
                      Impala per node, not a sum of all cores of the cluster.
                    </p>




                    <p class="p">
                      It is recommended that concurrency should not be more than the number of
                      virtual cores allocated to Impala per node.
                    </p>




                    <p class="p"></p>




                    <p class="p">
                      <em class="ph i">Query concurrency:</em>
                    </p>




                    <p class="p">
                      SELECT total_impala_num_queries_registered_across_impalads WHERE
                      entityName = "IMPALA-1" AND category = SERVICE
                    </p>




                    <p class="p"></p>

                  </td>

                </tr>

              </tbody>
</table>
</div>

        </div>


        <p class="p">
          If usage of any of the above resources exceeds the safe range, add one more
          coordinator.
        </p>


      </div>


    </div>


  </div>


  <div class="topic concept nested1" aria-labelledby="ariaid-title5" id="concept_omm_gf1_n2b">

    <h2 class="title topictitle2" id="ariaid-title5">Deploying Dedicated Coordinators and Executors</h2>


    <div class="body conbody">

      <p class="p">
        This section describes the process to configure a dedicated coordinator and a dedicated
        executor roles for Impala.
      </p>


      <ul class="ul">
        <li class="li">
          <p class="p">
            <strong class="ph b">Dedicated coordinator</strong>: They should be on edge node with no other services
            running on it. They donâ€™t need large local disks but still need some that can be
            used for Spilling. They require at least same or even larger memory allocation.
          </p>

        </li>


        <li class="li">
          <p class="p">
            <strong class="ph b">(Dedicated) Executors: </strong>They should be colocated with DataNodes as usual. The
            number of hosts with this setting typically increases as the cluster grows larger
            and handles more table partitions, data files, and concurrent queries.
          </p>

        </li>

      </ul>


      <div class="p">
        To configuring dedicated coordinators/executors, you specify one of the following
        startup flags for the <span class="keyword cmdname">impalad</span> daemon on each host:
        <ul class="ul">
          <li class="li">
            <p class="p">
              <code class="ph codeph">is_executor=false</code> for each host that does not act as an executor
              for Impala queries. These hosts act exclusively as query coordinators. This
              setting typically applies to a relatively small number of hosts, because the most
              common topology is to have nearly all DataNodes doing work for query execution.
            </p>

          </li>


          <li class="li">
            <p class="p">
              <code class="ph codeph">is_coordinator=false</code> for each host that does not act as a
              coordinator for Impala queries. These hosts act exclusively as executors. The
              number of hosts with this setting typically increases as the cluster grows larger
              and handles more table partitions, data files, and concurrent queries. As the
              overhead for query coordination increases, it becomes more important to centralize
              that work on dedicated hosts.
            </p>

          </li>

        </ul>

      </div>


    </div>


  </div>


</body>
</html>
