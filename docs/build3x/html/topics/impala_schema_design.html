<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="copyright" content="(C) Copyright 2018"><meta name="DC.rights.owner" content="(C) Copyright 2018"><meta name="DC.Type" content="concept"><meta name="DC.Relation" scheme="URI" content="../topics/impala_planning.html"><meta name="prodname" content="Impala"><meta name="prodname" content="Impala"><meta name="version" content="Impala 3.0.x"><meta name="version" content="Impala 3.0.x"><meta name="DC.Format" content="XHTML"><meta name="DC.Identifier" content="schema_design"><link rel="stylesheet" type="text/css" href="../commonltr.css"><title>Guidelines for Designing Impala Schemas</title></head><body id="schema_design"><main role="main"><article role="article" aria-labelledby="ariaid-title1">

  <h1 class="title topictitle1" id="ariaid-title1">Guidelines for Designing Impala Schemas</h1>



  <div class="body conbody">

    <p class="p">
      The guidelines in this topic help you to construct an optimized and scalable schema, one that integrates well
      with your existing data management processes. Use these guidelines as a checklist when doing any
      proof-of-concept work, porting exercise, or before deploying to production.
    </p>

    <p class="p">
      If you are adapting an existing database or Hive schema for use with Impala, read the guidelines in this
      section and then see <a class="xref" href="impala_porting.html#porting">Porting SQL from Other Database Systems to Impala</a> for specific porting and compatibility tips.
    </p>

    <p class="p toc inpage"></p>

    <section class="section" id="schema_design__schema_design_text_vs_binary"><h2 class="title sectiontitle">Prefer binary file formats over text-based formats.</h2>



      <p class="p">
        To save space and improve memory usage and query performance, use binary file formats for any large or
        intensively queried tables. Parquet file format is the most efficient for data warehouse-style analytic
        queries. Avro is the other binary file format that Impala supports, that you might already have as part of
        a Hadoop ETL pipeline.
      </p>

      <p class="p">
        Although Impala can create and query tables with the RCFile and SequenceFile file formats, such tables are
        relatively bulky due to the text-based nature of those formats, and are not optimized for data
        warehouse-style queries due to their row-oriented layout. Impala does not support <code class="ph codeph">INSERT</code>
        operations for tables with these file formats.
      </p>

      <p class="p">
        Guidelines:
      </p>

      <ul class="ul">
        <li class="li">
          For an efficient and scalable format for large, performance-critical tables, use the Parquet file format.
        </li>

        <li class="li">
          To deliver intermediate data during the ETL process, in a format that can also be used by other Hadoop
          components, Avro is a reasonable choice.
        </li>

        <li class="li">
          For convenient import of raw data, use a text table instead of RCFile or SequenceFile, and convert to
          Parquet in a later stage of the ETL process.
        </li>
      </ul>
    </section>

    <section class="section" id="schema_design__schema_design_compression"><h2 class="title sectiontitle">Use Snappy compression where practical.</h2>



      <p class="p">
        Snappy compression involves low CPU overhead to decompress, while still providing substantial space
        savings. In cases where you have a choice of compression codecs, such as with the Parquet and Avro file
        formats, use Snappy compression unless you find a compelling reason to use a different codec.
      </p>
    </section>

    <section class="section" id="schema_design__schema_design_numeric_types"><h2 class="title sectiontitle">Prefer numeric types over strings.</h2>



      <p class="p">
        If you have numeric values that you could treat as either strings or numbers (such as
        <code class="ph codeph">YEAR</code>, <code class="ph codeph">MONTH</code>, and <code class="ph codeph">DAY</code> for partition key columns), define
        them as the smallest applicable integer types. For example, <code class="ph codeph">YEAR</code> can be
        <code class="ph codeph">SMALLINT</code>, <code class="ph codeph">MONTH</code> and <code class="ph codeph">DAY</code> can be <code class="ph codeph">TINYINT</code>.
        Although you might not see any difference in the way partitioned tables or text files are laid out on disk,
        using numeric types will save space in binary formats such as Parquet, and in memory when doing queries,
        particularly resource-intensive queries such as joins.
      </p>
    </section>



    <section class="section" id="schema_design__schema_design_partitioning"><h2 class="title sectiontitle">Partition, but do not over-partition.</h2>



      <p class="p">
        Partitioning is an important aspect of performance tuning for Impala. Follow the procedures in
        <a class="xref" href="impala_partitioning.html#partitioning">Partitioning for Impala Tables</a> to set up partitioning for your biggest, most
        intensively queried tables.
      </p>

      <p class="p">
        If you are moving to Impala from a traditional database system, or just getting started in the Big Data
        field, you might not have enough data volume to take advantage of Impala parallel queries with your
        existing partitioning scheme. For example, if you have only a few tens of megabytes of data per day,
        partitioning by <code class="ph codeph">YEAR</code>, <code class="ph codeph">MONTH</code>, and <code class="ph codeph">DAY</code> columns might be
        too granular. Most of your cluster might be sitting idle during queries that target a single day, or each
        node might have very little work to do. Consider reducing the number of partition key columns so that each
        partition directory contains several gigabytes worth of data.
      </p>

      <p class="p">
        For example, consider a Parquet table where each data file is 1 HDFS block, with a maximum block size of 1
        GB. (In Impala 2.0 and later, the default Parquet block size is reduced to 256 MB. For this exercise, let's
        assume you have bumped the size back up to 1 GB by setting the query option
        <code class="ph codeph">PARQUET_FILE_SIZE=1g</code>.) if you have a 10-node cluster, you need 10 data files (up to 10 GB)
        to give each node some work to do for a query. But each core on each machine can process a separate data
        block in parallel. With 16-core machines on a 10-node cluster, a query could process up to 160 GB fully in
        parallel. If there are only a few data files per partition, not only are most cluster nodes sitting idle
        during queries, so are most cores on those machines.
      </p>

      <p class="p">
        You can reduce the Parquet block size to as low as 128 MB or 64 MB to increase the number of files per
        partition and improve parallelism. But also consider reducing the level of partitioning so that analytic
        queries have enough data to work with.
      </p>
    </section>

    <section class="section" id="schema_design__schema_design_compute_stats"><h2 class="title sectiontitle">Always compute stats after loading data.</h2>



      <p class="p">
        Impala makes extensive use of statistics about data in the overall table and in each column, to help plan
        resource-intensive operations such as join queries and inserting into partitioned Parquet tables. Because
        this information is only available after data is loaded, run the <code class="ph codeph">COMPUTE STATS</code> statement
        on a table after loading or replacing data in a table or partition.
      </p>

      <p class="p">
        Having accurate statistics can make the difference between a successful operation, or one that fails due to
        an out-of-memory error or a timeout. When you encounter performance or capacity issues, always use the
        <code class="ph codeph">SHOW STATS</code> statement to check if the statistics are present and up-to-date for all tables
        in the query.
      </p>

      <p class="p">
        When doing a join query, Impala consults the statistics for each joined table to determine their relative
        sizes and to estimate the number of rows produced in each join stage. When doing an <code class="ph codeph">INSERT</code>
        into a Parquet table, Impala consults the statistics for the source table to determine how to distribute
        the work of constructing the data files for each partition.
      </p>

      <p class="p">
        See <a class="xref" href="impala_compute_stats.html#compute_stats">COMPUTE STATS Statement</a> for the syntax of the <code class="ph codeph">COMPUTE
        STATS</code> statement, and <a class="xref" href="impala_perf_stats.html#perf_stats">Table and Column Statistics</a> for all the performance
        considerations for table and column statistics.
      </p>
    </section>

    <section class="section" id="schema_design__schema_design_explain"><h2 class="title sectiontitle">Verify sensible execution plans with EXPLAIN and SUMMARY.</h2>



      <p class="p">
        Before executing a resource-intensive query, use the <code class="ph codeph">EXPLAIN</code> statement to get an overview
        of how Impala intends to parallelize the query and distribute the work. If you see that the query plan is
        inefficient, you can take tuning steps such as changing file formats, using partitioned tables, running the
        <code class="ph codeph">COMPUTE STATS</code> statement, or adding query hints. For information about all of these
        techniques, see <a class="xref" href="impala_performance.html#performance">Tuning Impala for Performance</a>.
      </p>

      <p class="p">
        After you run a query, you can see performance-related information about how it actually ran by issuing the
        <code class="ph codeph">SUMMARY</code> command in <span class="keyword cmdname">impala-shell</span>. Prior to Impala 1.4, you would use
        the <code class="ph codeph">PROFILE</code> command, but its highly technical output was only useful for the most
        experienced users. <code class="ph codeph">SUMMARY</code>, new in Impala 1.4, summarizes the most useful information for
        all stages of execution, for all nodes rather than splitting out figures for each node.
      </p>
    </section>


  </div>
<nav role="navigation" class="related-links"><div class="familylinks"><div class="parentlink"><strong>Parent topic:</strong> <a class="link" href="../topics/impala_planning.html">Planning for Impala Deployment</a></div></div></nav></article></main></body></html>
